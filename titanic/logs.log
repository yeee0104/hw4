2024-12-10 13:55:54,196:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-10 13:55:54,196:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-10 13:55:54,196:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-10 13:55:54,196:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-10 13:56:41,835:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-10 13:56:41,842:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-10 13:56:41,842:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-10 13:56:41,842:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-10 13:56:42,248:INFO:PyCaret ClassificationExperiment
2024-12-10 13:56:42,249:INFO:Logging name: clf-default-name
2024-12-10 13:56:42,249:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-12-10 13:56:42,249:INFO:version 3.3.2
2024-12-10 13:56:42,249:INFO:Initializing setup()
2024-12-10 13:56:42,249:INFO:self.USI: e48b
2024-12-10 13:56:42,249:INFO:self._variable_keys: {'log_plots_param', 'data', 'y_test', 'X_test', 'seed', '_ml_usecase', 'logging_param', 'gpu_param', 'gpu_n_jobs_param', 'exp_name_log', 'fold_groups_param', 'is_multiclass', 'X_train', 'y', 'fix_imbalance', 'USI', 'exp_id', 'pipeline', 'fold_shuffle_param', 'html_param', '_available_plots', 'X', 'memory', 'fold_generator', 'target_param', 'idx', 'n_jobs_param', 'y_train'}
2024-12-10 13:56:42,249:INFO:Checking environment
2024-12-10 13:56:42,249:INFO:python_version: 3.11.10
2024-12-10 13:56:42,249:INFO:python_build: ('main', 'Oct  3 2024 07:22:26')
2024-12-10 13:56:42,249:INFO:machine: AMD64
2024-12-10 13:56:42,265:INFO:platform: Windows-10-10.0.19045-SP0
2024-12-10 13:56:42,267:INFO:Memory: svmem(total=16908595200, available=6127403008, percent=63.8, used=10781192192, free=6127403008)
2024-12-10 13:56:42,267:INFO:Physical Core: 16
2024-12-10 13:56:42,267:INFO:Logical Core: 24
2024-12-10 13:56:42,267:INFO:Checking libraries
2024-12-10 13:56:42,267:INFO:System:
2024-12-10 13:56:42,267:INFO:    python: 3.11.10 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:26) [MSC v.1929 64 bit (AMD64)]
2024-12-10 13:56:42,267:INFO:executable: C:\Users\py\.conda\envs\hw4\python.exe
2024-12-10 13:56:42,267:INFO:   machine: Windows-10-10.0.19045-SP0
2024-12-10 13:56:42,267:INFO:PyCaret required dependencies:
2024-12-10 13:56:42,287:INFO:                 pip: 24.2
2024-12-10 13:56:42,287:INFO:          setuptools: 75.1.0
2024-12-10 13:56:42,287:INFO:             pycaret: 3.3.2
2024-12-10 13:56:42,287:INFO:             IPython: 8.30.0
2024-12-10 13:56:42,287:INFO:          ipywidgets: 8.1.5
2024-12-10 13:56:42,287:INFO:                tqdm: 4.67.1
2024-12-10 13:56:42,287:INFO:               numpy: 1.26.4
2024-12-10 13:56:42,287:INFO:              pandas: 2.1.4
2024-12-10 13:56:42,287:INFO:              jinja2: 3.1.4
2024-12-10 13:56:42,287:INFO:               scipy: 1.11.4
2024-12-10 13:56:42,287:INFO:              joblib: 1.3.2
2024-12-10 13:56:42,287:INFO:             sklearn: 1.4.2
2024-12-10 13:56:42,287:INFO:                pyod: 2.0.2
2024-12-10 13:56:42,287:INFO:            imblearn: 0.12.4
2024-12-10 13:56:42,287:INFO:   category_encoders: 2.6.4
2024-12-10 13:56:42,287:INFO:            lightgbm: 4.5.0
2024-12-10 13:56:42,287:INFO:               numba: 0.60.0
2024-12-10 13:56:42,287:INFO:            requests: 2.32.3
2024-12-10 13:56:42,287:INFO:          matplotlib: 3.7.5
2024-12-10 13:56:42,287:INFO:          scikitplot: 0.3.7
2024-12-10 13:56:42,287:INFO:         yellowbrick: 1.5
2024-12-10 13:56:42,287:INFO:              plotly: 5.24.1
2024-12-10 13:56:42,287:INFO:    plotly-resampler: Not installed
2024-12-10 13:56:42,287:INFO:             kaleido: 0.2.1
2024-12-10 13:56:42,287:INFO:           schemdraw: 0.15
2024-12-10 13:56:42,287:INFO:         statsmodels: 0.14.4
2024-12-10 13:56:42,287:INFO:              sktime: 0.26.0
2024-12-10 13:56:42,287:INFO:               tbats: 1.1.3
2024-12-10 13:56:42,287:INFO:            pmdarima: 2.0.4
2024-12-10 13:56:42,287:INFO:              psutil: 6.1.0
2024-12-10 13:56:42,287:INFO:          markupsafe: 3.0.2
2024-12-10 13:56:42,287:INFO:             pickle5: Not installed
2024-12-10 13:56:42,287:INFO:         cloudpickle: 3.1.0
2024-12-10 13:56:42,287:INFO:         deprecation: 2.1.0
2024-12-10 13:56:42,287:INFO:              xxhash: 3.5.0
2024-12-10 13:56:42,287:INFO:           wurlitzer: Not installed
2024-12-10 13:56:42,287:INFO:PyCaret optional dependencies:
2024-12-10 13:56:42,305:INFO:                shap: Not installed
2024-12-10 13:56:42,305:INFO:           interpret: Not installed
2024-12-10 13:56:42,305:INFO:                umap: Not installed
2024-12-10 13:56:42,305:INFO:     ydata_profiling: Not installed
2024-12-10 13:56:42,305:INFO:  explainerdashboard: Not installed
2024-12-10 13:56:42,305:INFO:             autoviz: Not installed
2024-12-10 13:56:42,305:INFO:           fairlearn: Not installed
2024-12-10 13:56:42,305:INFO:          deepchecks: Not installed
2024-12-10 13:56:42,305:INFO:             xgboost: 2.1.3
2024-12-10 13:56:42,305:INFO:            catboost: 1.2.7
2024-12-10 13:56:42,305:INFO:              kmodes: Not installed
2024-12-10 13:56:42,305:INFO:             mlxtend: Not installed
2024-12-10 13:56:42,305:INFO:       statsforecast: Not installed
2024-12-10 13:56:42,305:INFO:        tune_sklearn: Not installed
2024-12-10 13:56:42,305:INFO:                 ray: Not installed
2024-12-10 13:56:42,305:INFO:            hyperopt: Not installed
2024-12-10 13:56:42,305:INFO:              optuna: Not installed
2024-12-10 13:56:42,305:INFO:               skopt: Not installed
2024-12-10 13:56:42,305:INFO:              mlflow: Not installed
2024-12-10 13:56:42,305:INFO:              gradio: Not installed
2024-12-10 13:56:42,305:INFO:             fastapi: Not installed
2024-12-10 13:56:42,305:INFO:             uvicorn: Not installed
2024-12-10 13:56:42,305:INFO:              m2cgen: Not installed
2024-12-10 13:56:42,305:INFO:           evidently: Not installed
2024-12-10 13:56:42,305:INFO:               fugue: Not installed
2024-12-10 13:56:42,305:INFO:           streamlit: Not installed
2024-12-10 13:56:42,305:INFO:             prophet: Not installed
2024-12-10 13:56:42,305:INFO:None
2024-12-10 13:56:42,305:INFO:Set up data.
2024-12-10 13:56:42,307:INFO:Set up folding strategy.
2024-12-10 13:56:42,307:INFO:Set up train/test split.
2024-12-10 13:56:42,309:INFO:Set up index.
2024-12-10 13:56:42,309:INFO:Assigning column types.
2024-12-10 13:56:42,310:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-10 13:56:42,330:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-10 13:56:42,332:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-10 13:56:42,348:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 13:56:42,349:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 13:56:42,382:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-10 13:56:42,382:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-10 13:56:42,394:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 13:56:42,396:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 13:56:42,396:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-10 13:56:42,416:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-10 13:56:42,428:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 13:56:42,429:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 13:56:42,450:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-10 13:56:42,462:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 13:56:42,463:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 13:56:42,463:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-12-10 13:56:42,496:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 13:56:42,497:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 13:56:42,530:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 13:56:42,532:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 13:56:42,533:INFO:Preparing preprocessing pipeline...
2024-12-10 13:56:42,534:INFO:Set up simple imputation.
2024-12-10 13:56:42,542:INFO:Finished creating preprocessing pipeline.
2024-12-10 13:56:42,544:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\py\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'SibSp',
                                             'Parch', 'Fare', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-12-10 13:56:42,544:INFO:Creating final display dataframe.
2024-12-10 13:56:42,571:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (891, 8)
4        Transformed data shape          (891, 8)
5   Transformed train set shape          (623, 8)
6    Transformed test set shape          (268, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              e48b
2024-12-10 13:56:42,605:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 13:56:42,606:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 13:56:42,640:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 13:56:42,641:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 13:56:42,642:INFO:setup() successfully completed in 0.39s...............
2024-12-10 13:56:42,642:INFO:Initializing compare_models()
2024-12-10 13:56:42,642:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=16, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 16, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-12-10 13:56:42,642:INFO:Checking exceptions
2024-12-10 13:56:42,643:INFO:Preparing display monitor
2024-12-10 13:56:42,646:INFO:Initializing Logistic Regression
2024-12-10 13:56:42,646:INFO:Total runtime is 0.0 minutes
2024-12-10 13:56:42,646:INFO:SubProcess create_model() called ==================================
2024-12-10 13:56:42,646:INFO:Initializing create_model()
2024-12-10 13:56:42,646:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FC5DC7A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:56:42,646:INFO:Checking exceptions
2024-12-10 13:56:42,646:INFO:Importing libraries
2024-12-10 13:56:42,646:INFO:Copying training dataset
2024-12-10 13:56:42,647:INFO:Defining folds
2024-12-10 13:56:42,647:INFO:Declaring metric variables
2024-12-10 13:56:42,647:INFO:Importing untrained model
2024-12-10 13:56:42,648:INFO:Logistic Regression Imported successfully
2024-12-10 13:56:42,648:INFO:Starting cross validation
2024-12-10 13:56:42,648:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:56:44,529:INFO:Calculating mean and std
2024-12-10 13:56:44,530:INFO:Creating metrics dataframe
2024-12-10 13:56:44,533:INFO:Uploading results into container
2024-12-10 13:56:44,533:INFO:Uploading model into container now
2024-12-10 13:56:44,534:INFO:_master_model_container: 1
2024-12-10 13:56:44,534:INFO:_display_container: 2
2024-12-10 13:56:44,534:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-10 13:56:44,534:INFO:create_model() successfully completed......................................
2024-12-10 13:56:44,634:INFO:SubProcess create_model() end ==================================
2024-12-10 13:56:44,634:INFO:Creating metrics dataframe
2024-12-10 13:56:44,635:INFO:Initializing K Neighbors Classifier
2024-12-10 13:56:44,635:INFO:Total runtime is 0.03315579096476237 minutes
2024-12-10 13:56:44,635:INFO:SubProcess create_model() called ==================================
2024-12-10 13:56:44,636:INFO:Initializing create_model()
2024-12-10 13:56:44,636:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FC5DC7A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:56:44,636:INFO:Checking exceptions
2024-12-10 13:56:44,636:INFO:Importing libraries
2024-12-10 13:56:44,636:INFO:Copying training dataset
2024-12-10 13:56:44,637:INFO:Defining folds
2024-12-10 13:56:44,637:INFO:Declaring metric variables
2024-12-10 13:56:44,637:INFO:Importing untrained model
2024-12-10 13:56:44,638:INFO:K Neighbors Classifier Imported successfully
2024-12-10 13:56:44,638:INFO:Starting cross validation
2024-12-10 13:56:44,638:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:56:46,122:INFO:Calculating mean and std
2024-12-10 13:56:46,123:INFO:Creating metrics dataframe
2024-12-10 13:56:46,126:INFO:Uploading results into container
2024-12-10 13:56:46,127:INFO:Uploading model into container now
2024-12-10 13:56:46,128:INFO:_master_model_container: 2
2024-12-10 13:56:46,128:INFO:_display_container: 2
2024-12-10 13:56:46,128:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-10 13:56:46,128:INFO:create_model() successfully completed......................................
2024-12-10 13:56:46,240:INFO:SubProcess create_model() end ==================================
2024-12-10 13:56:46,240:INFO:Creating metrics dataframe
2024-12-10 13:56:46,242:INFO:Initializing Naive Bayes
2024-12-10 13:56:46,242:INFO:Total runtime is 0.05993528366088867 minutes
2024-12-10 13:56:46,242:INFO:SubProcess create_model() called ==================================
2024-12-10 13:56:46,242:INFO:Initializing create_model()
2024-12-10 13:56:46,242:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FC5DC7A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:56:46,242:INFO:Checking exceptions
2024-12-10 13:56:46,242:INFO:Importing libraries
2024-12-10 13:56:46,242:INFO:Copying training dataset
2024-12-10 13:56:46,244:INFO:Defining folds
2024-12-10 13:56:46,244:INFO:Declaring metric variables
2024-12-10 13:56:46,244:INFO:Importing untrained model
2024-12-10 13:56:46,244:INFO:Naive Bayes Imported successfully
2024-12-10 13:56:46,244:INFO:Starting cross validation
2024-12-10 13:56:46,244:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:56:47,268:INFO:Calculating mean and std
2024-12-10 13:56:47,269:INFO:Creating metrics dataframe
2024-12-10 13:56:47,271:INFO:Uploading results into container
2024-12-10 13:56:47,271:INFO:Uploading model into container now
2024-12-10 13:56:47,271:INFO:_master_model_container: 3
2024-12-10 13:56:47,271:INFO:_display_container: 2
2024-12-10 13:56:47,271:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-10 13:56:47,271:INFO:create_model() successfully completed......................................
2024-12-10 13:56:47,349:INFO:SubProcess create_model() end ==================================
2024-12-10 13:56:47,349:INFO:Creating metrics dataframe
2024-12-10 13:56:47,350:INFO:Initializing Decision Tree Classifier
2024-12-10 13:56:47,350:INFO:Total runtime is 0.07839061816533406 minutes
2024-12-10 13:56:47,350:INFO:SubProcess create_model() called ==================================
2024-12-10 13:56:47,350:INFO:Initializing create_model()
2024-12-10 13:56:47,350:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FC5DC7A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:56:47,350:INFO:Checking exceptions
2024-12-10 13:56:47,350:INFO:Importing libraries
2024-12-10 13:56:47,350:INFO:Copying training dataset
2024-12-10 13:56:47,351:INFO:Defining folds
2024-12-10 13:56:47,351:INFO:Declaring metric variables
2024-12-10 13:56:47,351:INFO:Importing untrained model
2024-12-10 13:56:47,351:INFO:Decision Tree Classifier Imported successfully
2024-12-10 13:56:47,351:INFO:Starting cross validation
2024-12-10 13:56:47,352:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:56:47,377:INFO:Calculating mean and std
2024-12-10 13:56:47,377:INFO:Creating metrics dataframe
2024-12-10 13:56:47,378:INFO:Uploading results into container
2024-12-10 13:56:47,378:INFO:Uploading model into container now
2024-12-10 13:56:47,378:INFO:_master_model_container: 4
2024-12-10 13:56:47,378:INFO:_display_container: 2
2024-12-10 13:56:47,379:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-12-10 13:56:47,379:INFO:create_model() successfully completed......................................
2024-12-10 13:56:47,416:INFO:SubProcess create_model() end ==================================
2024-12-10 13:56:47,416:INFO:Creating metrics dataframe
2024-12-10 13:56:47,417:INFO:Initializing SVM - Linear Kernel
2024-12-10 13:56:47,417:INFO:Total runtime is 0.07952017386754354 minutes
2024-12-10 13:56:47,417:INFO:SubProcess create_model() called ==================================
2024-12-10 13:56:47,417:INFO:Initializing create_model()
2024-12-10 13:56:47,418:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FC5DC7A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:56:47,418:INFO:Checking exceptions
2024-12-10 13:56:47,418:INFO:Importing libraries
2024-12-10 13:56:47,418:INFO:Copying training dataset
2024-12-10 13:56:47,419:INFO:Defining folds
2024-12-10 13:56:47,419:INFO:Declaring metric variables
2024-12-10 13:56:47,419:INFO:Importing untrained model
2024-12-10 13:56:47,419:INFO:SVM - Linear Kernel Imported successfully
2024-12-10 13:56:47,419:INFO:Starting cross validation
2024-12-10 13:56:47,420:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:56:47,439:WARNING:C:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 13:56:47,446:INFO:Calculating mean and std
2024-12-10 13:56:47,446:INFO:Creating metrics dataframe
2024-12-10 13:56:47,447:INFO:Uploading results into container
2024-12-10 13:56:47,447:INFO:Uploading model into container now
2024-12-10 13:56:47,447:INFO:_master_model_container: 5
2024-12-10 13:56:47,447:INFO:_display_container: 2
2024-12-10 13:56:47,447:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-10 13:56:47,447:INFO:create_model() successfully completed......................................
2024-12-10 13:56:47,482:INFO:SubProcess create_model() end ==================================
2024-12-10 13:56:47,482:INFO:Creating metrics dataframe
2024-12-10 13:56:47,483:INFO:Initializing Ridge Classifier
2024-12-10 13:56:47,483:INFO:Total runtime is 0.0806165059407552 minutes
2024-12-10 13:56:47,483:INFO:SubProcess create_model() called ==================================
2024-12-10 13:56:47,483:INFO:Initializing create_model()
2024-12-10 13:56:47,483:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FC5DC7A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:56:47,483:INFO:Checking exceptions
2024-12-10 13:56:47,483:INFO:Importing libraries
2024-12-10 13:56:47,483:INFO:Copying training dataset
2024-12-10 13:56:47,485:INFO:Defining folds
2024-12-10 13:56:47,485:INFO:Declaring metric variables
2024-12-10 13:56:47,485:INFO:Importing untrained model
2024-12-10 13:56:47,485:INFO:Ridge Classifier Imported successfully
2024-12-10 13:56:47,485:INFO:Starting cross validation
2024-12-10 13:56:47,485:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:56:47,511:INFO:Calculating mean and std
2024-12-10 13:56:47,511:INFO:Creating metrics dataframe
2024-12-10 13:56:47,512:INFO:Uploading results into container
2024-12-10 13:56:47,512:INFO:Uploading model into container now
2024-12-10 13:56:47,512:INFO:_master_model_container: 6
2024-12-10 13:56:47,512:INFO:_display_container: 2
2024-12-10 13:56:47,512:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-12-10 13:56:47,512:INFO:create_model() successfully completed......................................
2024-12-10 13:56:47,552:INFO:SubProcess create_model() end ==================================
2024-12-10 13:56:47,552:INFO:Creating metrics dataframe
2024-12-10 13:56:47,553:INFO:Initializing Random Forest Classifier
2024-12-10 13:56:47,553:INFO:Total runtime is 0.08178497950236002 minutes
2024-12-10 13:56:47,553:INFO:SubProcess create_model() called ==================================
2024-12-10 13:56:47,553:INFO:Initializing create_model()
2024-12-10 13:56:47,553:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FC5DC7A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:56:47,553:INFO:Checking exceptions
2024-12-10 13:56:47,553:INFO:Importing libraries
2024-12-10 13:56:47,554:INFO:Copying training dataset
2024-12-10 13:56:47,555:INFO:Defining folds
2024-12-10 13:56:47,555:INFO:Declaring metric variables
2024-12-10 13:56:47,555:INFO:Importing untrained model
2024-12-10 13:56:47,555:INFO:Random Forest Classifier Imported successfully
2024-12-10 13:56:47,555:INFO:Starting cross validation
2024-12-10 13:56:47,556:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:56:47,708:INFO:Calculating mean and std
2024-12-10 13:56:47,708:INFO:Creating metrics dataframe
2024-12-10 13:56:47,709:INFO:Uploading results into container
2024-12-10 13:56:47,709:INFO:Uploading model into container now
2024-12-10 13:56:47,709:INFO:_master_model_container: 7
2024-12-10 13:56:47,709:INFO:_display_container: 2
2024-12-10 13:56:47,710:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-12-10 13:56:47,710:INFO:create_model() successfully completed......................................
2024-12-10 13:56:47,748:INFO:SubProcess create_model() end ==================================
2024-12-10 13:56:47,749:INFO:Creating metrics dataframe
2024-12-10 13:56:47,750:INFO:Initializing Quadratic Discriminant Analysis
2024-12-10 13:56:47,750:INFO:Total runtime is 0.08505831956863404 minutes
2024-12-10 13:56:47,750:INFO:SubProcess create_model() called ==================================
2024-12-10 13:56:47,750:INFO:Initializing create_model()
2024-12-10 13:56:47,750:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FC5DC7A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:56:47,750:INFO:Checking exceptions
2024-12-10 13:56:47,750:INFO:Importing libraries
2024-12-10 13:56:47,750:INFO:Copying training dataset
2024-12-10 13:56:47,751:INFO:Defining folds
2024-12-10 13:56:47,752:INFO:Declaring metric variables
2024-12-10 13:56:47,752:INFO:Importing untrained model
2024-12-10 13:56:47,752:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-10 13:56:47,752:INFO:Starting cross validation
2024-12-10 13:56:47,752:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:56:47,776:INFO:Calculating mean and std
2024-12-10 13:56:47,776:INFO:Creating metrics dataframe
2024-12-10 13:56:47,777:INFO:Uploading results into container
2024-12-10 13:56:47,777:INFO:Uploading model into container now
2024-12-10 13:56:47,777:INFO:_master_model_container: 8
2024-12-10 13:56:47,777:INFO:_display_container: 2
2024-12-10 13:56:47,777:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-10 13:56:47,777:INFO:create_model() successfully completed......................................
2024-12-10 13:56:47,815:INFO:SubProcess create_model() end ==================================
2024-12-10 13:56:47,815:INFO:Creating metrics dataframe
2024-12-10 13:56:47,817:INFO:Initializing Ada Boost Classifier
2024-12-10 13:56:47,817:INFO:Total runtime is 0.08618787527084351 minutes
2024-12-10 13:56:47,817:INFO:SubProcess create_model() called ==================================
2024-12-10 13:56:47,817:INFO:Initializing create_model()
2024-12-10 13:56:47,817:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FC5DC7A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:56:47,817:INFO:Checking exceptions
2024-12-10 13:56:47,817:INFO:Importing libraries
2024-12-10 13:56:47,817:INFO:Copying training dataset
2024-12-10 13:56:47,819:INFO:Defining folds
2024-12-10 13:56:47,819:INFO:Declaring metric variables
2024-12-10 13:56:47,819:INFO:Importing untrained model
2024-12-10 13:56:47,819:INFO:Ada Boost Classifier Imported successfully
2024-12-10 13:56:47,819:INFO:Starting cross validation
2024-12-10 13:56:47,819:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:56:47,828:WARNING:C:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:56:47,828:WARNING:C:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:56:47,828:WARNING:C:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:56:47,832:WARNING:C:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:56:47,833:WARNING:C:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:56:47,834:WARNING:C:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:56:47,835:WARNING:C:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:56:47,836:WARNING:C:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:56:47,837:WARNING:C:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:56:47,838:WARNING:C:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:56:47,910:INFO:Calculating mean and std
2024-12-10 13:56:47,910:INFO:Creating metrics dataframe
2024-12-10 13:56:47,911:INFO:Uploading results into container
2024-12-10 13:56:47,911:INFO:Uploading model into container now
2024-12-10 13:56:47,911:INFO:_master_model_container: 9
2024-12-10 13:56:47,911:INFO:_display_container: 2
2024-12-10 13:56:47,911:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-12-10 13:56:47,911:INFO:create_model() successfully completed......................................
2024-12-10 13:56:47,945:INFO:SubProcess create_model() end ==================================
2024-12-10 13:56:47,946:INFO:Creating metrics dataframe
2024-12-10 13:56:47,947:INFO:Initializing Gradient Boosting Classifier
2024-12-10 13:56:47,947:INFO:Total runtime is 0.08834916750590006 minutes
2024-12-10 13:56:47,947:INFO:SubProcess create_model() called ==================================
2024-12-10 13:56:47,947:INFO:Initializing create_model()
2024-12-10 13:56:47,947:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FC5DC7A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:56:47,947:INFO:Checking exceptions
2024-12-10 13:56:47,947:INFO:Importing libraries
2024-12-10 13:56:47,947:INFO:Copying training dataset
2024-12-10 13:56:47,949:INFO:Defining folds
2024-12-10 13:56:47,949:INFO:Declaring metric variables
2024-12-10 13:56:47,949:INFO:Importing untrained model
2024-12-10 13:56:47,949:INFO:Gradient Boosting Classifier Imported successfully
2024-12-10 13:56:47,949:INFO:Starting cross validation
2024-12-10 13:56:47,949:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:56:48,052:INFO:Calculating mean and std
2024-12-10 13:56:48,052:INFO:Creating metrics dataframe
2024-12-10 13:56:48,053:INFO:Uploading results into container
2024-12-10 13:56:48,053:INFO:Uploading model into container now
2024-12-10 13:56:48,053:INFO:_master_model_container: 10
2024-12-10 13:56:48,053:INFO:_display_container: 2
2024-12-10 13:56:48,053:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-10 13:56:48,053:INFO:create_model() successfully completed......................................
2024-12-10 13:56:48,087:INFO:SubProcess create_model() end ==================================
2024-12-10 13:56:48,087:INFO:Creating metrics dataframe
2024-12-10 13:56:48,089:INFO:Initializing Linear Discriminant Analysis
2024-12-10 13:56:48,089:INFO:Total runtime is 0.09072316884994507 minutes
2024-12-10 13:56:48,089:INFO:SubProcess create_model() called ==================================
2024-12-10 13:56:48,089:INFO:Initializing create_model()
2024-12-10 13:56:48,089:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FC5DC7A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:56:48,089:INFO:Checking exceptions
2024-12-10 13:56:48,089:INFO:Importing libraries
2024-12-10 13:56:48,089:INFO:Copying training dataset
2024-12-10 13:56:48,091:INFO:Defining folds
2024-12-10 13:56:48,091:INFO:Declaring metric variables
2024-12-10 13:56:48,091:INFO:Importing untrained model
2024-12-10 13:56:48,091:INFO:Linear Discriminant Analysis Imported successfully
2024-12-10 13:56:48,091:INFO:Starting cross validation
2024-12-10 13:56:48,091:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:56:48,127:INFO:Calculating mean and std
2024-12-10 13:56:48,127:INFO:Creating metrics dataframe
2024-12-10 13:56:48,128:INFO:Uploading results into container
2024-12-10 13:56:48,128:INFO:Uploading model into container now
2024-12-10 13:56:48,128:INFO:_master_model_container: 11
2024-12-10 13:56:48,128:INFO:_display_container: 2
2024-12-10 13:56:48,128:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-10 13:56:48,128:INFO:create_model() successfully completed......................................
2024-12-10 13:56:48,164:INFO:SubProcess create_model() end ==================================
2024-12-10 13:56:48,164:INFO:Creating metrics dataframe
2024-12-10 13:56:48,165:INFO:Initializing Extra Trees Classifier
2024-12-10 13:56:48,165:INFO:Total runtime is 0.09198665618896484 minutes
2024-12-10 13:56:48,165:INFO:SubProcess create_model() called ==================================
2024-12-10 13:56:48,165:INFO:Initializing create_model()
2024-12-10 13:56:48,165:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FC5DC7A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:56:48,165:INFO:Checking exceptions
2024-12-10 13:56:48,165:INFO:Importing libraries
2024-12-10 13:56:48,165:INFO:Copying training dataset
2024-12-10 13:56:48,166:INFO:Defining folds
2024-12-10 13:56:48,167:INFO:Declaring metric variables
2024-12-10 13:56:48,167:INFO:Importing untrained model
2024-12-10 13:56:48,167:INFO:Extra Trees Classifier Imported successfully
2024-12-10 13:56:48,167:INFO:Starting cross validation
2024-12-10 13:56:48,167:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:56:48,310:INFO:Calculating mean and std
2024-12-10 13:56:48,310:INFO:Creating metrics dataframe
2024-12-10 13:56:48,311:INFO:Uploading results into container
2024-12-10 13:56:48,311:INFO:Uploading model into container now
2024-12-10 13:56:48,311:INFO:_master_model_container: 12
2024-12-10 13:56:48,311:INFO:_display_container: 2
2024-12-10 13:56:48,312:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-12-10 13:56:48,312:INFO:create_model() successfully completed......................................
2024-12-10 13:56:48,350:INFO:SubProcess create_model() end ==================================
2024-12-10 13:56:48,350:INFO:Creating metrics dataframe
2024-12-10 13:56:48,351:INFO:Initializing Extreme Gradient Boosting
2024-12-10 13:56:48,351:INFO:Total runtime is 0.09508594671885172 minutes
2024-12-10 13:56:48,351:INFO:SubProcess create_model() called ==================================
2024-12-10 13:56:48,351:INFO:Initializing create_model()
2024-12-10 13:56:48,351:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FC5DC7A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:56:48,351:INFO:Checking exceptions
2024-12-10 13:56:48,351:INFO:Importing libraries
2024-12-10 13:56:48,351:INFO:Copying training dataset
2024-12-10 13:56:48,353:INFO:Defining folds
2024-12-10 13:56:48,353:INFO:Declaring metric variables
2024-12-10 13:56:48,353:INFO:Importing untrained model
2024-12-10 13:56:48,353:INFO:Extreme Gradient Boosting Imported successfully
2024-12-10 13:56:48,353:INFO:Starting cross validation
2024-12-10 13:56:48,353:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:56:48,424:INFO:Calculating mean and std
2024-12-10 13:56:48,424:INFO:Creating metrics dataframe
2024-12-10 13:56:48,425:INFO:Uploading results into container
2024-12-10 13:56:48,425:INFO:Uploading model into container now
2024-12-10 13:56:48,425:INFO:_master_model_container: 13
2024-12-10 13:56:48,425:INFO:_display_container: 2
2024-12-10 13:56:48,426:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-12-10 13:56:48,426:INFO:create_model() successfully completed......................................
2024-12-10 13:56:48,463:INFO:SubProcess create_model() end ==================================
2024-12-10 13:56:48,463:INFO:Creating metrics dataframe
2024-12-10 13:56:48,464:INFO:Initializing Light Gradient Boosting Machine
2024-12-10 13:56:48,464:INFO:Total runtime is 0.09696300427118937 minutes
2024-12-10 13:56:48,464:INFO:SubProcess create_model() called ==================================
2024-12-10 13:56:48,464:INFO:Initializing create_model()
2024-12-10 13:56:48,464:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FC5DC7A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:56:48,464:INFO:Checking exceptions
2024-12-10 13:56:48,464:INFO:Importing libraries
2024-12-10 13:56:48,465:INFO:Copying training dataset
2024-12-10 13:56:48,466:INFO:Defining folds
2024-12-10 13:56:48,466:INFO:Declaring metric variables
2024-12-10 13:56:48,466:INFO:Importing untrained model
2024-12-10 13:56:48,466:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-10 13:56:48,466:INFO:Starting cross validation
2024-12-10 13:56:48,466:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:56:49,150:INFO:Calculating mean and std
2024-12-10 13:56:49,150:INFO:Creating metrics dataframe
2024-12-10 13:56:49,151:INFO:Uploading results into container
2024-12-10 13:56:49,152:INFO:Uploading model into container now
2024-12-10 13:56:49,152:INFO:_master_model_container: 14
2024-12-10 13:56:49,152:INFO:_display_container: 2
2024-12-10 13:56:49,152:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-10 13:56:49,152:INFO:create_model() successfully completed......................................
2024-12-10 13:56:49,200:INFO:SubProcess create_model() end ==================================
2024-12-10 13:56:49,200:INFO:Creating metrics dataframe
2024-12-10 13:56:49,202:INFO:Initializing CatBoost Classifier
2024-12-10 13:56:49,202:INFO:Total runtime is 0.10927183628082275 minutes
2024-12-10 13:56:49,202:INFO:SubProcess create_model() called ==================================
2024-12-10 13:56:49,202:INFO:Initializing create_model()
2024-12-10 13:56:49,202:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FC5DC7A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:56:49,202:INFO:Checking exceptions
2024-12-10 13:56:49,202:INFO:Importing libraries
2024-12-10 13:56:49,202:INFO:Copying training dataset
2024-12-10 13:56:49,204:INFO:Defining folds
2024-12-10 13:56:49,204:INFO:Declaring metric variables
2024-12-10 13:56:49,204:INFO:Importing untrained model
2024-12-10 13:56:49,204:INFO:CatBoost Classifier Imported successfully
2024-12-10 13:56:49,204:INFO:Starting cross validation
2024-12-10 13:56:49,205:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:56:51,056:INFO:Calculating mean and std
2024-12-10 13:56:51,056:INFO:Creating metrics dataframe
2024-12-10 13:56:51,057:INFO:Uploading results into container
2024-12-10 13:56:51,057:INFO:Uploading model into container now
2024-12-10 13:56:51,057:INFO:_master_model_container: 15
2024-12-10 13:56:51,057:INFO:_display_container: 2
2024-12-10 13:56:51,057:INFO:<catboost.core.CatBoostClassifier object at 0x0000024FC63DA150>
2024-12-10 13:56:51,058:INFO:create_model() successfully completed......................................
2024-12-10 13:56:51,097:INFO:SubProcess create_model() end ==================================
2024-12-10 13:56:51,097:INFO:Creating metrics dataframe
2024-12-10 13:56:51,099:INFO:Initializing Dummy Classifier
2024-12-10 13:56:51,099:INFO:Total runtime is 0.14088714917500814 minutes
2024-12-10 13:56:51,099:INFO:SubProcess create_model() called ==================================
2024-12-10 13:56:51,099:INFO:Initializing create_model()
2024-12-10 13:56:51,099:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FC5DC7A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:56:51,099:INFO:Checking exceptions
2024-12-10 13:56:51,099:INFO:Importing libraries
2024-12-10 13:56:51,099:INFO:Copying training dataset
2024-12-10 13:56:51,100:INFO:Defining folds
2024-12-10 13:56:51,100:INFO:Declaring metric variables
2024-12-10 13:56:51,100:INFO:Importing untrained model
2024-12-10 13:56:51,100:INFO:Dummy Classifier Imported successfully
2024-12-10 13:56:51,101:INFO:Starting cross validation
2024-12-10 13:56:51,101:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:56:51,114:WARNING:C:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 13:56:51,114:WARNING:C:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 13:56:51,115:WARNING:C:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 13:56:51,115:WARNING:C:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 13:56:51,116:WARNING:C:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 13:56:51,116:WARNING:C:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 13:56:51,116:WARNING:C:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 13:56:51,118:WARNING:C:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 13:56:51,120:WARNING:C:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 13:56:51,121:WARNING:C:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 13:56:51,126:INFO:Calculating mean and std
2024-12-10 13:56:51,126:INFO:Creating metrics dataframe
2024-12-10 13:56:51,127:INFO:Uploading results into container
2024-12-10 13:56:51,127:INFO:Uploading model into container now
2024-12-10 13:56:51,127:INFO:_master_model_container: 16
2024-12-10 13:56:51,127:INFO:_display_container: 2
2024-12-10 13:56:51,127:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-12-10 13:56:51,127:INFO:create_model() successfully completed......................................
2024-12-10 13:56:51,164:INFO:SubProcess create_model() end ==================================
2024-12-10 13:56:51,165:INFO:Creating metrics dataframe
2024-12-10 13:56:51,167:WARNING:C:\Users\py\.conda\envs\hw4\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-12-10 13:56:51,168:INFO:Initializing create_model()
2024-12-10 13:56:51,168:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:56:51,168:INFO:Checking exceptions
2024-12-10 13:56:51,168:INFO:Importing libraries
2024-12-10 13:56:51,168:INFO:Copying training dataset
2024-12-10 13:56:51,169:INFO:Defining folds
2024-12-10 13:56:51,169:INFO:Declaring metric variables
2024-12-10 13:56:51,169:INFO:Importing untrained model
2024-12-10 13:56:51,169:INFO:Declaring custom model
2024-12-10 13:56:51,170:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-10 13:56:51,170:INFO:Cross validation set to False
2024-12-10 13:56:51,170:INFO:Fitting Model
2024-12-10 13:56:51,176:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-10 13:56:51,177:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000246 seconds.
2024-12-10 13:56:51,177:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-12-10 13:56:51,177:INFO:[LightGBM] [Info] Total Bins 188
2024-12-10 13:56:51,178:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 7
2024-12-10 13:56:51,178:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-10 13:56:51,178:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-10 13:56:51,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:56:51,254:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-10 13:56:51,254:INFO:create_model() successfully completed......................................
2024-12-10 13:56:51,294:INFO:Initializing create_model()
2024-12-10 13:56:51,294:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, estimator=<catboost.core.CatBoostClassifier object at 0x0000024FC63DA150>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:56:51,294:INFO:Checking exceptions
2024-12-10 13:56:51,294:INFO:Importing libraries
2024-12-10 13:56:51,294:INFO:Copying training dataset
2024-12-10 13:56:51,296:INFO:Defining folds
2024-12-10 13:56:51,296:INFO:Declaring metric variables
2024-12-10 13:56:51,296:INFO:Importing untrained model
2024-12-10 13:56:51,296:INFO:Declaring custom model
2024-12-10 13:56:51,296:INFO:CatBoost Classifier Imported successfully
2024-12-10 13:56:51,296:INFO:Cross validation set to False
2024-12-10 13:56:51,296:INFO:Fitting Model
2024-12-10 13:56:52,303:INFO:<catboost.core.CatBoostClassifier object at 0x0000024FC641B450>
2024-12-10 13:56:52,304:INFO:create_model() successfully completed......................................
2024-12-10 13:56:52,349:INFO:Initializing create_model()
2024-12-10 13:56:52,349:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:56:52,349:INFO:Checking exceptions
2024-12-10 13:56:52,350:INFO:Importing libraries
2024-12-10 13:56:52,350:INFO:Copying training dataset
2024-12-10 13:56:52,351:INFO:Defining folds
2024-12-10 13:56:52,351:INFO:Declaring metric variables
2024-12-10 13:56:52,351:INFO:Importing untrained model
2024-12-10 13:56:52,351:INFO:Declaring custom model
2024-12-10 13:56:52,352:INFO:Gradient Boosting Classifier Imported successfully
2024-12-10 13:56:52,352:INFO:Cross validation set to False
2024-12-10 13:56:52,352:INFO:Fitting Model
2024-12-10 13:56:52,411:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-10 13:56:52,411:INFO:create_model() successfully completed......................................
2024-12-10 13:56:52,454:INFO:Initializing create_model()
2024-12-10 13:56:52,454:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:56:52,454:INFO:Checking exceptions
2024-12-10 13:56:52,455:INFO:Importing libraries
2024-12-10 13:56:52,455:INFO:Copying training dataset
2024-12-10 13:56:52,456:INFO:Defining folds
2024-12-10 13:56:52,456:INFO:Declaring metric variables
2024-12-10 13:56:52,456:INFO:Importing untrained model
2024-12-10 13:56:52,456:INFO:Declaring custom model
2024-12-10 13:56:52,457:INFO:Random Forest Classifier Imported successfully
2024-12-10 13:56:52,457:INFO:Cross validation set to False
2024-12-10 13:56:52,457:INFO:Fitting Model
2024-12-10 13:56:52,532:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-12-10 13:56:52,532:INFO:create_model() successfully completed......................................
2024-12-10 13:56:52,569:INFO:Initializing create_model()
2024-12-10 13:56:52,569:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:56:52,569:INFO:Checking exceptions
2024-12-10 13:56:52,570:INFO:Importing libraries
2024-12-10 13:56:52,570:INFO:Copying training dataset
2024-12-10 13:56:52,571:INFO:Defining folds
2024-12-10 13:56:52,572:INFO:Declaring metric variables
2024-12-10 13:56:52,572:INFO:Importing untrained model
2024-12-10 13:56:52,572:INFO:Declaring custom model
2024-12-10 13:56:52,572:INFO:Extreme Gradient Boosting Imported successfully
2024-12-10 13:56:52,573:INFO:Cross validation set to False
2024-12-10 13:56:52,573:INFO:Fitting Model
2024-12-10 13:56:52,633:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-12-10 13:56:52,633:INFO:create_model() successfully completed......................................
2024-12-10 13:56:52,674:INFO:Initializing create_model()
2024-12-10 13:56:52,674:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:56:52,674:INFO:Checking exceptions
2024-12-10 13:56:52,675:INFO:Importing libraries
2024-12-10 13:56:52,675:INFO:Copying training dataset
2024-12-10 13:56:52,676:INFO:Defining folds
2024-12-10 13:56:52,677:INFO:Declaring metric variables
2024-12-10 13:56:52,677:INFO:Importing untrained model
2024-12-10 13:56:52,677:INFO:Declaring custom model
2024-12-10 13:56:52,677:INFO:Ada Boost Classifier Imported successfully
2024-12-10 13:56:52,677:INFO:Cross validation set to False
2024-12-10 13:56:52,677:INFO:Fitting Model
2024-12-10 13:56:52,681:WARNING:C:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:56:52,727:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-12-10 13:56:52,727:INFO:create_model() successfully completed......................................
2024-12-10 13:56:52,780:INFO:Initializing create_model()
2024-12-10 13:56:52,780:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:56:52,780:INFO:Checking exceptions
2024-12-10 13:56:52,780:INFO:Importing libraries
2024-12-10 13:56:52,780:INFO:Copying training dataset
2024-12-10 13:56:52,782:INFO:Defining folds
2024-12-10 13:56:52,782:INFO:Declaring metric variables
2024-12-10 13:56:52,782:INFO:Importing untrained model
2024-12-10 13:56:52,782:INFO:Declaring custom model
2024-12-10 13:56:52,782:INFO:Logistic Regression Imported successfully
2024-12-10 13:56:52,782:INFO:Cross validation set to False
2024-12-10 13:56:52,782:INFO:Fitting Model
2024-12-10 13:56:52,790:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-10 13:56:52,790:INFO:create_model() successfully completed......................................
2024-12-10 13:56:52,825:INFO:Initializing create_model()
2024-12-10 13:56:52,825:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:56:52,825:INFO:Checking exceptions
2024-12-10 13:56:52,826:INFO:Importing libraries
2024-12-10 13:56:52,826:INFO:Copying training dataset
2024-12-10 13:56:52,827:INFO:Defining folds
2024-12-10 13:56:52,827:INFO:Declaring metric variables
2024-12-10 13:56:52,827:INFO:Importing untrained model
2024-12-10 13:56:52,827:INFO:Declaring custom model
2024-12-10 13:56:52,827:INFO:Ridge Classifier Imported successfully
2024-12-10 13:56:52,828:INFO:Cross validation set to False
2024-12-10 13:56:52,828:INFO:Fitting Model
2024-12-10 13:56:52,831:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-12-10 13:56:52,831:INFO:create_model() successfully completed......................................
2024-12-10 13:56:52,880:INFO:Initializing create_model()
2024-12-10 13:56:52,880:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:56:52,880:INFO:Checking exceptions
2024-12-10 13:56:52,880:INFO:Importing libraries
2024-12-10 13:56:52,880:INFO:Copying training dataset
2024-12-10 13:56:52,881:INFO:Defining folds
2024-12-10 13:56:52,881:INFO:Declaring metric variables
2024-12-10 13:56:52,881:INFO:Importing untrained model
2024-12-10 13:56:52,882:INFO:Declaring custom model
2024-12-10 13:56:52,882:INFO:Linear Discriminant Analysis Imported successfully
2024-12-10 13:56:52,882:INFO:Cross validation set to False
2024-12-10 13:56:52,882:INFO:Fitting Model
2024-12-10 13:56:52,884:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-10 13:56:52,884:INFO:create_model() successfully completed......................................
2024-12-10 13:56:52,918:INFO:Initializing create_model()
2024-12-10 13:56:52,918:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:56:52,918:INFO:Checking exceptions
2024-12-10 13:56:52,918:INFO:Importing libraries
2024-12-10 13:56:52,918:INFO:Copying training dataset
2024-12-10 13:56:52,919:INFO:Defining folds
2024-12-10 13:56:52,919:INFO:Declaring metric variables
2024-12-10 13:56:52,920:INFO:Importing untrained model
2024-12-10 13:56:52,920:INFO:Declaring custom model
2024-12-10 13:56:52,920:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-10 13:56:52,920:INFO:Cross validation set to False
2024-12-10 13:56:52,920:INFO:Fitting Model
2024-12-10 13:56:52,923:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-10 13:56:52,923:INFO:create_model() successfully completed......................................
2024-12-10 13:56:52,957:INFO:Initializing create_model()
2024-12-10 13:56:52,957:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:56:52,957:INFO:Checking exceptions
2024-12-10 13:56:52,957:INFO:Importing libraries
2024-12-10 13:56:52,957:INFO:Copying training dataset
2024-12-10 13:56:52,958:INFO:Defining folds
2024-12-10 13:56:52,958:INFO:Declaring metric variables
2024-12-10 13:56:52,959:INFO:Importing untrained model
2024-12-10 13:56:52,959:INFO:Declaring custom model
2024-12-10 13:56:52,959:INFO:Extra Trees Classifier Imported successfully
2024-12-10 13:56:52,959:INFO:Cross validation set to False
2024-12-10 13:56:52,959:INFO:Fitting Model
2024-12-10 13:56:53,014:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-12-10 13:56:53,014:INFO:create_model() successfully completed......................................
2024-12-10 13:56:53,052:INFO:Initializing create_model()
2024-12-10 13:56:53,052:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:56:53,052:INFO:Checking exceptions
2024-12-10 13:56:53,053:INFO:Importing libraries
2024-12-10 13:56:53,053:INFO:Copying training dataset
2024-12-10 13:56:53,055:INFO:Defining folds
2024-12-10 13:56:53,055:INFO:Declaring metric variables
2024-12-10 13:56:53,055:INFO:Importing untrained model
2024-12-10 13:56:53,055:INFO:Declaring custom model
2024-12-10 13:56:53,055:INFO:Naive Bayes Imported successfully
2024-12-10 13:56:53,055:INFO:Cross validation set to False
2024-12-10 13:56:53,055:INFO:Fitting Model
2024-12-10 13:56:53,058:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-10 13:56:53,058:INFO:create_model() successfully completed......................................
2024-12-10 13:56:53,098:INFO:Initializing create_model()
2024-12-10 13:56:53,098:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:56:53,098:INFO:Checking exceptions
2024-12-10 13:56:53,098:INFO:Importing libraries
2024-12-10 13:56:53,098:INFO:Copying training dataset
2024-12-10 13:56:53,099:INFO:Defining folds
2024-12-10 13:56:53,099:INFO:Declaring metric variables
2024-12-10 13:56:53,099:INFO:Importing untrained model
2024-12-10 13:56:53,099:INFO:Declaring custom model
2024-12-10 13:56:53,100:INFO:Decision Tree Classifier Imported successfully
2024-12-10 13:56:53,100:INFO:Cross validation set to False
2024-12-10 13:56:53,100:INFO:Fitting Model
2024-12-10 13:56:53,104:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-12-10 13:56:53,104:INFO:create_model() successfully completed......................................
2024-12-10 13:56:53,142:INFO:Initializing create_model()
2024-12-10 13:56:53,142:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:56:53,142:INFO:Checking exceptions
2024-12-10 13:56:53,142:INFO:Importing libraries
2024-12-10 13:56:53,142:INFO:Copying training dataset
2024-12-10 13:56:53,143:INFO:Defining folds
2024-12-10 13:56:53,143:INFO:Declaring metric variables
2024-12-10 13:56:53,143:INFO:Importing untrained model
2024-12-10 13:56:53,143:INFO:Declaring custom model
2024-12-10 13:56:53,144:INFO:K Neighbors Classifier Imported successfully
2024-12-10 13:56:53,144:INFO:Cross validation set to False
2024-12-10 13:56:53,144:INFO:Fitting Model
2024-12-10 13:56:53,147:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-10 13:56:53,147:INFO:create_model() successfully completed......................................
2024-12-10 13:56:53,181:INFO:Initializing create_model()
2024-12-10 13:56:53,181:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:56:53,181:INFO:Checking exceptions
2024-12-10 13:56:53,182:INFO:Importing libraries
2024-12-10 13:56:53,182:INFO:Copying training dataset
2024-12-10 13:56:53,183:INFO:Defining folds
2024-12-10 13:56:53,183:INFO:Declaring metric variables
2024-12-10 13:56:53,183:INFO:Importing untrained model
2024-12-10 13:56:53,183:INFO:Declaring custom model
2024-12-10 13:56:53,184:INFO:SVM - Linear Kernel Imported successfully
2024-12-10 13:56:53,184:INFO:Cross validation set to False
2024-12-10 13:56:53,184:INFO:Fitting Model
2024-12-10 13:56:53,188:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-10 13:56:53,188:INFO:create_model() successfully completed......................................
2024-12-10 13:56:53,221:INFO:Initializing create_model()
2024-12-10 13:56:53,221:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:56:53,221:INFO:Checking exceptions
2024-12-10 13:56:53,222:INFO:Importing libraries
2024-12-10 13:56:53,222:INFO:Copying training dataset
2024-12-10 13:56:53,223:INFO:Defining folds
2024-12-10 13:56:53,223:INFO:Declaring metric variables
2024-12-10 13:56:53,223:INFO:Importing untrained model
2024-12-10 13:56:53,223:INFO:Declaring custom model
2024-12-10 13:56:53,223:INFO:Dummy Classifier Imported successfully
2024-12-10 13:56:53,223:INFO:Cross validation set to False
2024-12-10 13:56:53,223:INFO:Fitting Model
2024-12-10 13:56:53,226:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-12-10 13:56:53,226:INFO:create_model() successfully completed......................................
2024-12-10 13:56:53,271:INFO:_master_model_container: 16
2024-12-10 13:56:53,271:INFO:_display_container: 2
2024-12-10 13:56:53,272:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), <catboost.core.CatBoostClassifier object at 0x0000024FC641B450>, GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), DummyClassifier(constant=None, random_state=123, strategy='prior')]
2024-12-10 13:56:53,272:INFO:compare_models() successfully completed......................................
2024-12-10 13:56:53,284:INFO:Initializing finalize_model()
2024-12-10 13:56:53,284:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, estimator=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), <catboost.core.CatBoostClassifier object at 0x0000024FC641B450>, GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), DummyClassifier(constant=None, random_state=123, strategy='prior')], fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-12-10 13:56:53,285:INFO:Finalizing [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), <catboost.core.CatBoostClassifier object at 0x0000024FC641B450>, GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), DummyClassifier(constant=None, random_state=123, strategy='prior')]
2024-12-10 13:56:53,288:INFO:Initializing create_model()
2024-12-10 13:56:53,288:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024FC4A46F90>, estimator=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), <catboost.core.CatBoostClassifier object at 0x0000024FC641B450>, GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), DummyClassifier(constant=None, random_state=123, strategy='prior')], fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:56:53,288:INFO:Checking exceptions
2024-12-10 13:58:06,675:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-10 13:58:06,675:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-10 13:58:06,675:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-10 13:58:06,675:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-10 13:58:06,884:INFO:PyCaret ClassificationExperiment
2024-12-10 13:58:06,884:INFO:Logging name: clf-default-name
2024-12-10 13:58:06,884:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-12-10 13:58:06,884:INFO:version 3.3.2
2024-12-10 13:58:06,884:INFO:Initializing setup()
2024-12-10 13:58:06,884:INFO:self.USI: 80c0
2024-12-10 13:58:06,884:INFO:self._variable_keys: {'X', '_ml_usecase', 'data', 'exp_name_log', 'USI', 'target_param', 'exp_id', 'html_param', 'y_test', 'n_jobs_param', 'idx', 'log_plots_param', 'fold_shuffle_param', 'memory', 'pipeline', 'X_test', 'logging_param', 'fix_imbalance', '_available_plots', 'X_train', 'gpu_n_jobs_param', 'y', 'fold_generator', 'gpu_param', 'y_train', 'seed', 'fold_groups_param', 'is_multiclass'}
2024-12-10 13:58:06,884:INFO:Checking environment
2024-12-10 13:58:06,884:INFO:python_version: 3.11.10
2024-12-10 13:58:06,884:INFO:python_build: ('main', 'Oct  3 2024 07:22:26')
2024-12-10 13:58:06,884:INFO:machine: AMD64
2024-12-10 13:58:06,884:INFO:platform: Windows-10-10.0.19045-SP0
2024-12-10 13:58:06,886:INFO:Memory: svmem(total=16908595200, available=6337216512, percent=62.5, used=10571378688, free=6337216512)
2024-12-10 13:58:06,886:INFO:Physical Core: 16
2024-12-10 13:58:06,886:INFO:Logical Core: 24
2024-12-10 13:58:06,886:INFO:Checking libraries
2024-12-10 13:58:06,886:INFO:System:
2024-12-10 13:58:06,886:INFO:    python: 3.11.10 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:26) [MSC v.1929 64 bit (AMD64)]
2024-12-10 13:58:06,886:INFO:executable: c:\Users\py\.conda\envs\hw4\python.exe
2024-12-10 13:58:06,886:INFO:   machine: Windows-10-10.0.19045-SP0
2024-12-10 13:58:06,886:INFO:PyCaret required dependencies:
2024-12-10 13:58:06,909:INFO:                 pip: 24.2
2024-12-10 13:58:06,909:INFO:          setuptools: 75.1.0
2024-12-10 13:58:06,909:INFO:             pycaret: 3.3.2
2024-12-10 13:58:06,909:INFO:             IPython: 8.30.0
2024-12-10 13:58:06,909:INFO:          ipywidgets: 8.1.5
2024-12-10 13:58:06,909:INFO:                tqdm: 4.67.1
2024-12-10 13:58:06,909:INFO:               numpy: 1.26.4
2024-12-10 13:58:06,909:INFO:              pandas: 2.1.4
2024-12-10 13:58:06,909:INFO:              jinja2: 3.1.4
2024-12-10 13:58:06,909:INFO:               scipy: 1.11.4
2024-12-10 13:58:06,909:INFO:              joblib: 1.3.2
2024-12-10 13:58:06,909:INFO:             sklearn: 1.4.2
2024-12-10 13:58:06,909:INFO:                pyod: 2.0.2
2024-12-10 13:58:06,909:INFO:            imblearn: 0.12.4
2024-12-10 13:58:06,909:INFO:   category_encoders: 2.6.4
2024-12-10 13:58:06,909:INFO:            lightgbm: 4.5.0
2024-12-10 13:58:06,909:INFO:               numba: 0.60.0
2024-12-10 13:58:06,909:INFO:            requests: 2.32.3
2024-12-10 13:58:06,909:INFO:          matplotlib: 3.7.5
2024-12-10 13:58:06,909:INFO:          scikitplot: 0.3.7
2024-12-10 13:58:06,909:INFO:         yellowbrick: 1.5
2024-12-10 13:58:06,909:INFO:              plotly: 5.24.1
2024-12-10 13:58:06,909:INFO:    plotly-resampler: Not installed
2024-12-10 13:58:06,909:INFO:             kaleido: 0.2.1
2024-12-10 13:58:06,909:INFO:           schemdraw: 0.15
2024-12-10 13:58:06,909:INFO:         statsmodels: 0.14.4
2024-12-10 13:58:06,909:INFO:              sktime: 0.26.0
2024-12-10 13:58:06,909:INFO:               tbats: 1.1.3
2024-12-10 13:58:06,909:INFO:            pmdarima: 2.0.4
2024-12-10 13:58:06,909:INFO:              psutil: 6.1.0
2024-12-10 13:58:06,909:INFO:          markupsafe: 3.0.2
2024-12-10 13:58:06,909:INFO:             pickle5: Not installed
2024-12-10 13:58:06,909:INFO:         cloudpickle: 3.1.0
2024-12-10 13:58:06,909:INFO:         deprecation: 2.1.0
2024-12-10 13:58:06,909:INFO:              xxhash: 3.5.0
2024-12-10 13:58:06,909:INFO:           wurlitzer: Not installed
2024-12-10 13:58:06,909:INFO:PyCaret optional dependencies:
2024-12-10 13:58:06,928:INFO:                shap: Not installed
2024-12-10 13:58:06,928:INFO:           interpret: Not installed
2024-12-10 13:58:06,928:INFO:                umap: Not installed
2024-12-10 13:58:06,928:INFO:     ydata_profiling: Not installed
2024-12-10 13:58:06,928:INFO:  explainerdashboard: Not installed
2024-12-10 13:58:06,928:INFO:             autoviz: Not installed
2024-12-10 13:58:06,928:INFO:           fairlearn: Not installed
2024-12-10 13:58:06,928:INFO:          deepchecks: Not installed
2024-12-10 13:58:06,928:INFO:             xgboost: 2.1.3
2024-12-10 13:58:06,928:INFO:            catboost: 1.2.7
2024-12-10 13:58:06,928:INFO:              kmodes: Not installed
2024-12-10 13:58:06,928:INFO:             mlxtend: Not installed
2024-12-10 13:58:06,928:INFO:       statsforecast: Not installed
2024-12-10 13:58:06,928:INFO:        tune_sklearn: Not installed
2024-12-10 13:58:06,928:INFO:                 ray: Not installed
2024-12-10 13:58:06,928:INFO:            hyperopt: Not installed
2024-12-10 13:58:06,928:INFO:              optuna: Not installed
2024-12-10 13:58:06,928:INFO:               skopt: Not installed
2024-12-10 13:58:06,928:INFO:              mlflow: Not installed
2024-12-10 13:58:06,928:INFO:              gradio: Not installed
2024-12-10 13:58:06,928:INFO:             fastapi: Not installed
2024-12-10 13:58:06,928:INFO:             uvicorn: Not installed
2024-12-10 13:58:06,928:INFO:              m2cgen: Not installed
2024-12-10 13:58:06,928:INFO:           evidently: Not installed
2024-12-10 13:58:06,928:INFO:               fugue: Not installed
2024-12-10 13:58:06,928:INFO:           streamlit: Not installed
2024-12-10 13:58:06,928:INFO:             prophet: Not installed
2024-12-10 13:58:06,928:INFO:None
2024-12-10 13:58:06,928:INFO:Set up data.
2024-12-10 13:58:06,931:INFO:Set up folding strategy.
2024-12-10 13:58:06,931:INFO:Set up train/test split.
2024-12-10 13:58:06,932:INFO:Set up index.
2024-12-10 13:58:06,933:INFO:Assigning column types.
2024-12-10 13:58:06,934:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-10 13:58:06,954:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-10 13:58:06,956:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-10 13:58:06,972:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 13:58:06,973:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 13:58:07,009:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-10 13:58:07,009:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-10 13:58:07,022:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 13:58:07,023:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 13:58:07,023:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-10 13:58:07,044:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-10 13:58:07,057:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 13:58:07,058:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 13:58:07,079:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-10 13:58:07,091:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 13:58:07,093:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 13:58:07,093:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-12-10 13:58:07,126:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 13:58:07,127:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 13:58:07,161:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 13:58:07,162:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 13:58:07,163:INFO:Preparing preprocessing pipeline...
2024-12-10 13:58:07,163:INFO:Set up simple imputation.
2024-12-10 13:58:07,172:INFO:Finished creating preprocessing pipeline.
2024-12-10 13:58:07,174:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\py\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'SibSp',
                                             'Parch', 'Fare', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-12-10 13:58:07,174:INFO:Creating final display dataframe.
2024-12-10 13:58:07,201:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (891, 8)
4        Transformed data shape          (891, 8)
5   Transformed train set shape          (623, 8)
6    Transformed test set shape          (268, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              80c0
2024-12-10 13:58:07,238:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 13:58:07,239:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 13:58:07,275:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 13:58:07,276:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 13:58:07,277:INFO:setup() successfully completed in 0.39s...............
2024-12-10 13:58:07,277:INFO:Initializing compare_models()
2024-12-10 13:58:07,277:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=16, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 16, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-12-10 13:58:07,277:INFO:Checking exceptions
2024-12-10 13:58:07,279:INFO:Preparing display monitor
2024-12-10 13:58:07,291:INFO:Initializing Logistic Regression
2024-12-10 13:58:07,292:INFO:Total runtime is 1.6585985819498697e-05 minutes
2024-12-10 13:58:07,293:INFO:SubProcess create_model() called ==================================
2024-12-10 13:58:07,293:INFO:Initializing create_model()
2024-12-10 13:58:07,293:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E478883990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:07,294:INFO:Checking exceptions
2024-12-10 13:58:07,294:INFO:Importing libraries
2024-12-10 13:58:07,294:INFO:Copying training dataset
2024-12-10 13:58:07,295:INFO:Defining folds
2024-12-10 13:58:07,295:INFO:Declaring metric variables
2024-12-10 13:58:07,296:INFO:Importing untrained model
2024-12-10 13:58:07,298:INFO:Logistic Regression Imported successfully
2024-12-10 13:58:07,301:INFO:Starting cross validation
2024-12-10 13:58:07,302:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:58:09,433:INFO:Calculating mean and std
2024-12-10 13:58:09,435:INFO:Creating metrics dataframe
2024-12-10 13:58:09,438:INFO:Uploading results into container
2024-12-10 13:58:09,439:INFO:Uploading model into container now
2024-12-10 13:58:09,439:INFO:_master_model_container: 1
2024-12-10 13:58:09,439:INFO:_display_container: 2
2024-12-10 13:58:09,440:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-10 13:58:09,440:INFO:create_model() successfully completed......................................
2024-12-10 13:58:09,557:INFO:SubProcess create_model() end ==================================
2024-12-10 13:58:09,557:INFO:Creating metrics dataframe
2024-12-10 13:58:09,560:INFO:Initializing K Neighbors Classifier
2024-12-10 13:58:09,560:INFO:Total runtime is 0.03780688842137655 minutes
2024-12-10 13:58:09,561:INFO:SubProcess create_model() called ==================================
2024-12-10 13:58:09,561:INFO:Initializing create_model()
2024-12-10 13:58:09,561:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E478883990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:09,561:INFO:Checking exceptions
2024-12-10 13:58:09,562:INFO:Importing libraries
2024-12-10 13:58:09,562:INFO:Copying training dataset
2024-12-10 13:58:09,564:INFO:Defining folds
2024-12-10 13:58:09,564:INFO:Declaring metric variables
2024-12-10 13:58:09,565:INFO:Importing untrained model
2024-12-10 13:58:09,566:INFO:K Neighbors Classifier Imported successfully
2024-12-10 13:58:09,569:INFO:Starting cross validation
2024-12-10 13:58:09,569:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:58:11,402:INFO:Calculating mean and std
2024-12-10 13:58:11,404:INFO:Creating metrics dataframe
2024-12-10 13:58:11,408:INFO:Uploading results into container
2024-12-10 13:58:11,409:INFO:Uploading model into container now
2024-12-10 13:58:11,409:INFO:_master_model_container: 2
2024-12-10 13:58:11,409:INFO:_display_container: 2
2024-12-10 13:58:11,410:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-10 13:58:11,410:INFO:create_model() successfully completed......................................
2024-12-10 13:58:11,533:INFO:SubProcess create_model() end ==================================
2024-12-10 13:58:11,533:INFO:Creating metrics dataframe
2024-12-10 13:58:11,536:INFO:Initializing Naive Bayes
2024-12-10 13:58:11,536:INFO:Total runtime is 0.07074917157491048 minutes
2024-12-10 13:58:11,538:INFO:SubProcess create_model() called ==================================
2024-12-10 13:58:11,538:INFO:Initializing create_model()
2024-12-10 13:58:11,538:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E478883990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:11,538:INFO:Checking exceptions
2024-12-10 13:58:11,538:INFO:Importing libraries
2024-12-10 13:58:11,538:INFO:Copying training dataset
2024-12-10 13:58:11,540:INFO:Defining folds
2024-12-10 13:58:11,540:INFO:Declaring metric variables
2024-12-10 13:58:11,541:INFO:Importing untrained model
2024-12-10 13:58:11,543:INFO:Naive Bayes Imported successfully
2024-12-10 13:58:11,545:INFO:Starting cross validation
2024-12-10 13:58:11,546:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:58:12,645:INFO:Calculating mean and std
2024-12-10 13:58:12,646:INFO:Creating metrics dataframe
2024-12-10 13:58:12,647:INFO:Uploading results into container
2024-12-10 13:58:12,648:INFO:Uploading model into container now
2024-12-10 13:58:12,648:INFO:_master_model_container: 3
2024-12-10 13:58:12,648:INFO:_display_container: 2
2024-12-10 13:58:12,648:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-10 13:58:12,648:INFO:create_model() successfully completed......................................
2024-12-10 13:58:12,737:INFO:SubProcess create_model() end ==================================
2024-12-10 13:58:12,737:INFO:Creating metrics dataframe
2024-12-10 13:58:12,740:INFO:Initializing Decision Tree Classifier
2024-12-10 13:58:12,741:INFO:Total runtime is 0.0908320148785909 minutes
2024-12-10 13:58:12,742:INFO:SubProcess create_model() called ==================================
2024-12-10 13:58:12,742:INFO:Initializing create_model()
2024-12-10 13:58:12,742:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E478883990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:12,742:INFO:Checking exceptions
2024-12-10 13:58:12,742:INFO:Importing libraries
2024-12-10 13:58:12,742:INFO:Copying training dataset
2024-12-10 13:58:12,744:INFO:Defining folds
2024-12-10 13:58:12,744:INFO:Declaring metric variables
2024-12-10 13:58:12,745:INFO:Importing untrained model
2024-12-10 13:58:12,746:INFO:Decision Tree Classifier Imported successfully
2024-12-10 13:58:12,749:INFO:Starting cross validation
2024-12-10 13:58:12,750:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:58:12,787:INFO:Calculating mean and std
2024-12-10 13:58:12,787:INFO:Creating metrics dataframe
2024-12-10 13:58:12,788:INFO:Uploading results into container
2024-12-10 13:58:12,788:INFO:Uploading model into container now
2024-12-10 13:58:12,788:INFO:_master_model_container: 4
2024-12-10 13:58:12,788:INFO:_display_container: 2
2024-12-10 13:58:12,788:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-12-10 13:58:12,789:INFO:create_model() successfully completed......................................
2024-12-10 13:58:12,834:INFO:SubProcess create_model() end ==================================
2024-12-10 13:58:12,834:INFO:Creating metrics dataframe
2024-12-10 13:58:12,837:INFO:Initializing SVM - Linear Kernel
2024-12-10 13:58:12,837:INFO:Total runtime is 0.09242669343948363 minutes
2024-12-10 13:58:12,839:INFO:SubProcess create_model() called ==================================
2024-12-10 13:58:12,839:INFO:Initializing create_model()
2024-12-10 13:58:12,839:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E478883990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:12,839:INFO:Checking exceptions
2024-12-10 13:58:12,839:INFO:Importing libraries
2024-12-10 13:58:12,839:INFO:Copying training dataset
2024-12-10 13:58:12,841:INFO:Defining folds
2024-12-10 13:58:12,841:INFO:Declaring metric variables
2024-12-10 13:58:12,842:INFO:Importing untrained model
2024-12-10 13:58:12,844:INFO:SVM - Linear Kernel Imported successfully
2024-12-10 13:58:12,846:INFO:Starting cross validation
2024-12-10 13:58:12,847:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:58:12,870:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 13:58:12,873:INFO:Calculating mean and std
2024-12-10 13:58:12,874:INFO:Creating metrics dataframe
2024-12-10 13:58:12,875:INFO:Uploading results into container
2024-12-10 13:58:12,876:INFO:Uploading model into container now
2024-12-10 13:58:12,876:INFO:_master_model_container: 5
2024-12-10 13:58:12,876:INFO:_display_container: 2
2024-12-10 13:58:12,876:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-10 13:58:12,876:INFO:create_model() successfully completed......................................
2024-12-10 13:58:12,922:INFO:SubProcess create_model() end ==================================
2024-12-10 13:58:12,922:INFO:Creating metrics dataframe
2024-12-10 13:58:12,926:INFO:Initializing Ridge Classifier
2024-12-10 13:58:12,926:INFO:Total runtime is 0.09390509128570555 minutes
2024-12-10 13:58:12,927:INFO:SubProcess create_model() called ==================================
2024-12-10 13:58:12,927:INFO:Initializing create_model()
2024-12-10 13:58:12,927:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E478883990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:12,927:INFO:Checking exceptions
2024-12-10 13:58:12,928:INFO:Importing libraries
2024-12-10 13:58:12,928:INFO:Copying training dataset
2024-12-10 13:58:12,929:INFO:Defining folds
2024-12-10 13:58:12,929:INFO:Declaring metric variables
2024-12-10 13:58:12,930:INFO:Importing untrained model
2024-12-10 13:58:12,932:INFO:Ridge Classifier Imported successfully
2024-12-10 13:58:12,933:INFO:Starting cross validation
2024-12-10 13:58:12,934:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:58:12,970:INFO:Calculating mean and std
2024-12-10 13:58:12,970:INFO:Creating metrics dataframe
2024-12-10 13:58:12,971:INFO:Uploading results into container
2024-12-10 13:58:12,971:INFO:Uploading model into container now
2024-12-10 13:58:12,971:INFO:_master_model_container: 6
2024-12-10 13:58:12,971:INFO:_display_container: 2
2024-12-10 13:58:12,971:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-12-10 13:58:12,971:INFO:create_model() successfully completed......................................
2024-12-10 13:58:13,016:INFO:SubProcess create_model() end ==================================
2024-12-10 13:58:13,016:INFO:Creating metrics dataframe
2024-12-10 13:58:13,020:INFO:Initializing Random Forest Classifier
2024-12-10 13:58:13,020:INFO:Total runtime is 0.09548314015070596 minutes
2024-12-10 13:58:13,022:INFO:SubProcess create_model() called ==================================
2024-12-10 13:58:13,022:INFO:Initializing create_model()
2024-12-10 13:58:13,022:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E478883990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:13,022:INFO:Checking exceptions
2024-12-10 13:58:13,022:INFO:Importing libraries
2024-12-10 13:58:13,022:INFO:Copying training dataset
2024-12-10 13:58:13,024:INFO:Defining folds
2024-12-10 13:58:13,024:INFO:Declaring metric variables
2024-12-10 13:58:13,026:INFO:Importing untrained model
2024-12-10 13:58:13,027:INFO:Random Forest Classifier Imported successfully
2024-12-10 13:58:13,030:INFO:Starting cross validation
2024-12-10 13:58:13,031:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:58:13,206:INFO:Calculating mean and std
2024-12-10 13:58:13,206:INFO:Creating metrics dataframe
2024-12-10 13:58:13,207:INFO:Uploading results into container
2024-12-10 13:58:13,208:INFO:Uploading model into container now
2024-12-10 13:58:13,208:INFO:_master_model_container: 7
2024-12-10 13:58:13,208:INFO:_display_container: 2
2024-12-10 13:58:13,208:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-12-10 13:58:13,208:INFO:create_model() successfully completed......................................
2024-12-10 13:58:13,251:INFO:SubProcess create_model() end ==================================
2024-12-10 13:58:13,251:INFO:Creating metrics dataframe
2024-12-10 13:58:13,255:INFO:Initializing Quadratic Discriminant Analysis
2024-12-10 13:58:13,255:INFO:Total runtime is 0.09940052429835 minutes
2024-12-10 13:58:13,256:INFO:SubProcess create_model() called ==================================
2024-12-10 13:58:13,257:INFO:Initializing create_model()
2024-12-10 13:58:13,257:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E478883990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:13,257:INFO:Checking exceptions
2024-12-10 13:58:13,257:INFO:Importing libraries
2024-12-10 13:58:13,257:INFO:Copying training dataset
2024-12-10 13:58:13,258:INFO:Defining folds
2024-12-10 13:58:13,258:INFO:Declaring metric variables
2024-12-10 13:58:13,260:INFO:Importing untrained model
2024-12-10 13:58:13,261:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-10 13:58:13,265:INFO:Starting cross validation
2024-12-10 13:58:13,266:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:58:13,306:INFO:Calculating mean and std
2024-12-10 13:58:13,306:INFO:Creating metrics dataframe
2024-12-10 13:58:13,308:INFO:Uploading results into container
2024-12-10 13:58:13,308:INFO:Uploading model into container now
2024-12-10 13:58:13,308:INFO:_master_model_container: 8
2024-12-10 13:58:13,308:INFO:_display_container: 2
2024-12-10 13:58:13,309:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-10 13:58:13,309:INFO:create_model() successfully completed......................................
2024-12-10 13:58:13,351:INFO:SubProcess create_model() end ==================================
2024-12-10 13:58:13,351:INFO:Creating metrics dataframe
2024-12-10 13:58:13,355:INFO:Initializing Ada Boost Classifier
2024-12-10 13:58:13,355:INFO:Total runtime is 0.10106438398361205 minutes
2024-12-10 13:58:13,356:INFO:SubProcess create_model() called ==================================
2024-12-10 13:58:13,356:INFO:Initializing create_model()
2024-12-10 13:58:13,356:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E478883990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:13,357:INFO:Checking exceptions
2024-12-10 13:58:13,357:INFO:Importing libraries
2024-12-10 13:58:13,357:INFO:Copying training dataset
2024-12-10 13:58:13,358:INFO:Defining folds
2024-12-10 13:58:13,358:INFO:Declaring metric variables
2024-12-10 13:58:13,359:INFO:Importing untrained model
2024-12-10 13:58:13,361:INFO:Ada Boost Classifier Imported successfully
2024-12-10 13:58:13,363:INFO:Starting cross validation
2024-12-10 13:58:13,364:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:58:13,372:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:58:13,373:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:58:13,373:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:58:13,374:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:58:13,374:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:58:13,375:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:58:13,375:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:58:13,376:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:58:13,378:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:58:13,378:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:58:13,455:INFO:Calculating mean and std
2024-12-10 13:58:13,455:INFO:Creating metrics dataframe
2024-12-10 13:58:13,456:INFO:Uploading results into container
2024-12-10 13:58:13,457:INFO:Uploading model into container now
2024-12-10 13:58:13,457:INFO:_master_model_container: 9
2024-12-10 13:58:13,457:INFO:_display_container: 2
2024-12-10 13:58:13,457:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-12-10 13:58:13,457:INFO:create_model() successfully completed......................................
2024-12-10 13:58:13,505:INFO:SubProcess create_model() end ==================================
2024-12-10 13:58:13,505:INFO:Creating metrics dataframe
2024-12-10 13:58:13,510:INFO:Initializing Gradient Boosting Classifier
2024-12-10 13:58:13,510:INFO:Total runtime is 0.10364000399907429 minutes
2024-12-10 13:58:13,511:INFO:SubProcess create_model() called ==================================
2024-12-10 13:58:13,511:INFO:Initializing create_model()
2024-12-10 13:58:13,511:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E478883990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:13,511:INFO:Checking exceptions
2024-12-10 13:58:13,511:INFO:Importing libraries
2024-12-10 13:58:13,511:INFO:Copying training dataset
2024-12-10 13:58:13,513:INFO:Defining folds
2024-12-10 13:58:13,513:INFO:Declaring metric variables
2024-12-10 13:58:13,514:INFO:Importing untrained model
2024-12-10 13:58:13,516:INFO:Gradient Boosting Classifier Imported successfully
2024-12-10 13:58:13,518:INFO:Starting cross validation
2024-12-10 13:58:13,519:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:58:13,629:INFO:Calculating mean and std
2024-12-10 13:58:13,629:INFO:Creating metrics dataframe
2024-12-10 13:58:13,630:INFO:Uploading results into container
2024-12-10 13:58:13,630:INFO:Uploading model into container now
2024-12-10 13:58:13,631:INFO:_master_model_container: 10
2024-12-10 13:58:13,631:INFO:_display_container: 2
2024-12-10 13:58:13,631:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-10 13:58:13,631:INFO:create_model() successfully completed......................................
2024-12-10 13:58:13,673:INFO:SubProcess create_model() end ==================================
2024-12-10 13:58:13,673:INFO:Creating metrics dataframe
2024-12-10 13:58:13,677:INFO:Initializing Linear Discriminant Analysis
2024-12-10 13:58:13,677:INFO:Total runtime is 0.1064372142155965 minutes
2024-12-10 13:58:13,679:INFO:SubProcess create_model() called ==================================
2024-12-10 13:58:13,679:INFO:Initializing create_model()
2024-12-10 13:58:13,679:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E478883990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:13,679:INFO:Checking exceptions
2024-12-10 13:58:13,679:INFO:Importing libraries
2024-12-10 13:58:13,679:INFO:Copying training dataset
2024-12-10 13:58:13,680:INFO:Defining folds
2024-12-10 13:58:13,681:INFO:Declaring metric variables
2024-12-10 13:58:13,682:INFO:Importing untrained model
2024-12-10 13:58:13,683:INFO:Linear Discriminant Analysis Imported successfully
2024-12-10 13:58:13,686:INFO:Starting cross validation
2024-12-10 13:58:13,686:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:58:13,723:INFO:Calculating mean and std
2024-12-10 13:58:13,723:INFO:Creating metrics dataframe
2024-12-10 13:58:13,725:INFO:Uploading results into container
2024-12-10 13:58:13,725:INFO:Uploading model into container now
2024-12-10 13:58:13,725:INFO:_master_model_container: 11
2024-12-10 13:58:13,725:INFO:_display_container: 2
2024-12-10 13:58:13,726:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-10 13:58:13,726:INFO:create_model() successfully completed......................................
2024-12-10 13:58:13,770:INFO:SubProcess create_model() end ==================================
2024-12-10 13:58:13,770:INFO:Creating metrics dataframe
2024-12-10 13:58:13,775:INFO:Initializing Extra Trees Classifier
2024-12-10 13:58:13,775:INFO:Total runtime is 0.10806510845820108 minutes
2024-12-10 13:58:13,776:INFO:SubProcess create_model() called ==================================
2024-12-10 13:58:13,776:INFO:Initializing create_model()
2024-12-10 13:58:13,776:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E478883990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:13,776:INFO:Checking exceptions
2024-12-10 13:58:13,777:INFO:Importing libraries
2024-12-10 13:58:13,777:INFO:Copying training dataset
2024-12-10 13:58:13,778:INFO:Defining folds
2024-12-10 13:58:13,778:INFO:Declaring metric variables
2024-12-10 13:58:13,780:INFO:Importing untrained model
2024-12-10 13:58:13,781:INFO:Extra Trees Classifier Imported successfully
2024-12-10 13:58:13,784:INFO:Starting cross validation
2024-12-10 13:58:13,784:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:58:13,937:INFO:Calculating mean and std
2024-12-10 13:58:13,937:INFO:Creating metrics dataframe
2024-12-10 13:58:13,938:INFO:Uploading results into container
2024-12-10 13:58:13,938:INFO:Uploading model into container now
2024-12-10 13:58:13,939:INFO:_master_model_container: 12
2024-12-10 13:58:13,939:INFO:_display_container: 2
2024-12-10 13:58:13,939:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-12-10 13:58:13,939:INFO:create_model() successfully completed......................................
2024-12-10 13:58:13,981:INFO:SubProcess create_model() end ==================================
2024-12-10 13:58:13,981:INFO:Creating metrics dataframe
2024-12-10 13:58:13,986:INFO:Initializing Extreme Gradient Boosting
2024-12-10 13:58:13,986:INFO:Total runtime is 0.11157904465993244 minutes
2024-12-10 13:58:13,987:INFO:SubProcess create_model() called ==================================
2024-12-10 13:58:13,987:INFO:Initializing create_model()
2024-12-10 13:58:13,987:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E478883990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:13,988:INFO:Checking exceptions
2024-12-10 13:58:13,988:INFO:Importing libraries
2024-12-10 13:58:13,988:INFO:Copying training dataset
2024-12-10 13:58:13,989:INFO:Defining folds
2024-12-10 13:58:13,989:INFO:Declaring metric variables
2024-12-10 13:58:13,991:INFO:Importing untrained model
2024-12-10 13:58:13,992:INFO:Extreme Gradient Boosting Imported successfully
2024-12-10 13:58:13,995:INFO:Starting cross validation
2024-12-10 13:58:13,995:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:58:14,077:INFO:Calculating mean and std
2024-12-10 13:58:14,077:INFO:Creating metrics dataframe
2024-12-10 13:58:14,078:INFO:Uploading results into container
2024-12-10 13:58:14,078:INFO:Uploading model into container now
2024-12-10 13:58:14,079:INFO:_master_model_container: 13
2024-12-10 13:58:14,079:INFO:_display_container: 2
2024-12-10 13:58:14,079:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-12-10 13:58:14,079:INFO:create_model() successfully completed......................................
2024-12-10 13:58:14,123:INFO:SubProcess create_model() end ==================================
2024-12-10 13:58:14,124:INFO:Creating metrics dataframe
2024-12-10 13:58:14,127:INFO:Initializing Light Gradient Boosting Machine
2024-12-10 13:58:14,127:INFO:Total runtime is 0.11393782297770182 minutes
2024-12-10 13:58:14,129:INFO:SubProcess create_model() called ==================================
2024-12-10 13:58:14,129:INFO:Initializing create_model()
2024-12-10 13:58:14,129:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E478883990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:14,129:INFO:Checking exceptions
2024-12-10 13:58:14,129:INFO:Importing libraries
2024-12-10 13:58:14,129:INFO:Copying training dataset
2024-12-10 13:58:14,130:INFO:Defining folds
2024-12-10 13:58:14,130:INFO:Declaring metric variables
2024-12-10 13:58:14,132:INFO:Importing untrained model
2024-12-10 13:58:14,133:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-10 13:58:14,136:INFO:Starting cross validation
2024-12-10 13:58:14,136:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:58:14,942:INFO:Calculating mean and std
2024-12-10 13:58:14,942:INFO:Creating metrics dataframe
2024-12-10 13:58:14,943:INFO:Uploading results into container
2024-12-10 13:58:14,944:INFO:Uploading model into container now
2024-12-10 13:58:14,944:INFO:_master_model_container: 14
2024-12-10 13:58:14,944:INFO:_display_container: 2
2024-12-10 13:58:14,944:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-10 13:58:14,945:INFO:create_model() successfully completed......................................
2024-12-10 13:58:14,992:INFO:SubProcess create_model() end ==================================
2024-12-10 13:58:14,992:INFO:Creating metrics dataframe
2024-12-10 13:58:14,999:INFO:Initializing CatBoost Classifier
2024-12-10 13:58:14,999:INFO:Total runtime is 0.12845593293507893 minutes
2024-12-10 13:58:15,001:INFO:SubProcess create_model() called ==================================
2024-12-10 13:58:15,001:INFO:Initializing create_model()
2024-12-10 13:58:15,001:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E478883990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:15,001:INFO:Checking exceptions
2024-12-10 13:58:15,001:INFO:Importing libraries
2024-12-10 13:58:15,001:INFO:Copying training dataset
2024-12-10 13:58:15,003:INFO:Defining folds
2024-12-10 13:58:15,003:INFO:Declaring metric variables
2024-12-10 13:58:15,005:INFO:Importing untrained model
2024-12-10 13:58:15,006:INFO:CatBoost Classifier Imported successfully
2024-12-10 13:58:15,010:INFO:Starting cross validation
2024-12-10 13:58:15,010:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:58:16,810:INFO:Calculating mean and std
2024-12-10 13:58:16,810:INFO:Creating metrics dataframe
2024-12-10 13:58:16,811:INFO:Uploading results into container
2024-12-10 13:58:16,811:INFO:Uploading model into container now
2024-12-10 13:58:16,812:INFO:_master_model_container: 15
2024-12-10 13:58:16,812:INFO:_display_container: 2
2024-12-10 13:58:16,812:INFO:<catboost.core.CatBoostClassifier object at 0x000001E479188510>
2024-12-10 13:58:16,812:INFO:create_model() successfully completed......................................
2024-12-10 13:58:16,853:INFO:SubProcess create_model() end ==================================
2024-12-10 13:58:16,853:INFO:Creating metrics dataframe
2024-12-10 13:58:16,858:INFO:Initializing Dummy Classifier
2024-12-10 13:58:16,858:INFO:Total runtime is 0.1594386021296183 minutes
2024-12-10 13:58:16,860:INFO:SubProcess create_model() called ==================================
2024-12-10 13:58:16,860:INFO:Initializing create_model()
2024-12-10 13:58:16,860:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E478883990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:16,860:INFO:Checking exceptions
2024-12-10 13:58:16,860:INFO:Importing libraries
2024-12-10 13:58:16,860:INFO:Copying training dataset
2024-12-10 13:58:16,861:INFO:Defining folds
2024-12-10 13:58:16,862:INFO:Declaring metric variables
2024-12-10 13:58:16,863:INFO:Importing untrained model
2024-12-10 13:58:16,864:INFO:Dummy Classifier Imported successfully
2024-12-10 13:58:16,867:INFO:Starting cross validation
2024-12-10 13:58:16,867:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:58:16,879:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 13:58:16,880:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 13:58:16,881:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 13:58:16,884:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 13:58:16,886:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 13:58:16,887:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 13:58:16,888:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 13:58:16,888:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 13:58:16,889:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 13:58:16,890:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 13:58:16,903:INFO:Calculating mean and std
2024-12-10 13:58:16,903:INFO:Creating metrics dataframe
2024-12-10 13:58:16,904:INFO:Uploading results into container
2024-12-10 13:58:16,904:INFO:Uploading model into container now
2024-12-10 13:58:16,904:INFO:_master_model_container: 16
2024-12-10 13:58:16,904:INFO:_display_container: 2
2024-12-10 13:58:16,904:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-12-10 13:58:16,904:INFO:create_model() successfully completed......................................
2024-12-10 13:58:16,960:INFO:SubProcess create_model() end ==================================
2024-12-10 13:58:16,961:INFO:Creating metrics dataframe
2024-12-10 13:58:16,967:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-12-10 13:58:16,970:INFO:Initializing create_model()
2024-12-10 13:58:16,970:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:16,971:INFO:Checking exceptions
2024-12-10 13:58:16,971:INFO:Importing libraries
2024-12-10 13:58:16,971:INFO:Copying training dataset
2024-12-10 13:58:16,973:INFO:Defining folds
2024-12-10 13:58:16,973:INFO:Declaring metric variables
2024-12-10 13:58:16,973:INFO:Importing untrained model
2024-12-10 13:58:16,973:INFO:Declaring custom model
2024-12-10 13:58:16,973:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-10 13:58:16,974:INFO:Cross validation set to False
2024-12-10 13:58:16,974:INFO:Fitting Model
2024-12-10 13:58:16,981:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-10 13:58:16,982:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000183 seconds.
2024-12-10 13:58:16,982:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-12-10 13:58:16,982:INFO:[LightGBM] [Info] Total Bins 188
2024-12-10 13:58:16,982:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 7
2024-12-10 13:58:16,982:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-10 13:58:16,983:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-10 13:58:16,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:16,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:16,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:16,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:16,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:16,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:16,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:16,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:16,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:16,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:16,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:16,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:16,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:16,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:16,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:16,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:16,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:16,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:58:17,062:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-10 13:58:17,062:INFO:create_model() successfully completed......................................
2024-12-10 13:58:17,119:INFO:Initializing create_model()
2024-12-10 13:58:17,120:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, estimator=<catboost.core.CatBoostClassifier object at 0x000001E479188510>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:17,120:INFO:Checking exceptions
2024-12-10 13:58:17,121:INFO:Importing libraries
2024-12-10 13:58:17,121:INFO:Copying training dataset
2024-12-10 13:58:17,123:INFO:Defining folds
2024-12-10 13:58:17,123:INFO:Declaring metric variables
2024-12-10 13:58:17,124:INFO:Importing untrained model
2024-12-10 13:58:17,124:INFO:Declaring custom model
2024-12-10 13:58:17,124:INFO:CatBoost Classifier Imported successfully
2024-12-10 13:58:17,125:INFO:Cross validation set to False
2024-12-10 13:58:17,125:INFO:Fitting Model
2024-12-10 13:58:18,227:INFO:<catboost.core.CatBoostClassifier object at 0x000001E478BBA2D0>
2024-12-10 13:58:18,227:INFO:create_model() successfully completed......................................
2024-12-10 13:58:18,274:INFO:Initializing create_model()
2024-12-10 13:58:18,274:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:18,274:INFO:Checking exceptions
2024-12-10 13:58:18,275:INFO:Importing libraries
2024-12-10 13:58:18,275:INFO:Copying training dataset
2024-12-10 13:58:18,277:INFO:Defining folds
2024-12-10 13:58:18,277:INFO:Declaring metric variables
2024-12-10 13:58:18,277:INFO:Importing untrained model
2024-12-10 13:58:18,277:INFO:Declaring custom model
2024-12-10 13:58:18,277:INFO:Gradient Boosting Classifier Imported successfully
2024-12-10 13:58:18,277:INFO:Cross validation set to False
2024-12-10 13:58:18,277:INFO:Fitting Model
2024-12-10 13:58:18,337:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-10 13:58:18,337:INFO:create_model() successfully completed......................................
2024-12-10 13:58:18,383:INFO:Initializing create_model()
2024-12-10 13:58:18,383:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:18,383:INFO:Checking exceptions
2024-12-10 13:58:18,384:INFO:Importing libraries
2024-12-10 13:58:18,384:INFO:Copying training dataset
2024-12-10 13:58:18,386:INFO:Defining folds
2024-12-10 13:58:18,386:INFO:Declaring metric variables
2024-12-10 13:58:18,386:INFO:Importing untrained model
2024-12-10 13:58:18,386:INFO:Declaring custom model
2024-12-10 13:58:18,386:INFO:Random Forest Classifier Imported successfully
2024-12-10 13:58:18,386:INFO:Cross validation set to False
2024-12-10 13:58:18,386:INFO:Fitting Model
2024-12-10 13:58:18,463:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-12-10 13:58:18,463:INFO:create_model() successfully completed......................................
2024-12-10 13:58:18,511:INFO:Initializing create_model()
2024-12-10 13:58:18,512:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:18,512:INFO:Checking exceptions
2024-12-10 13:58:18,512:INFO:Importing libraries
2024-12-10 13:58:18,513:INFO:Copying training dataset
2024-12-10 13:58:18,514:INFO:Defining folds
2024-12-10 13:58:18,514:INFO:Declaring metric variables
2024-12-10 13:58:18,514:INFO:Importing untrained model
2024-12-10 13:58:18,514:INFO:Declaring custom model
2024-12-10 13:58:18,515:INFO:Extreme Gradient Boosting Imported successfully
2024-12-10 13:58:18,515:INFO:Cross validation set to False
2024-12-10 13:58:18,515:INFO:Fitting Model
2024-12-10 13:58:18,588:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-12-10 13:58:18,588:INFO:create_model() successfully completed......................................
2024-12-10 13:58:18,641:INFO:Initializing create_model()
2024-12-10 13:58:18,641:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:18,641:INFO:Checking exceptions
2024-12-10 13:58:18,642:INFO:Importing libraries
2024-12-10 13:58:18,642:INFO:Copying training dataset
2024-12-10 13:58:18,644:INFO:Defining folds
2024-12-10 13:58:18,644:INFO:Declaring metric variables
2024-12-10 13:58:18,644:INFO:Importing untrained model
2024-12-10 13:58:18,644:INFO:Declaring custom model
2024-12-10 13:58:18,644:INFO:Ada Boost Classifier Imported successfully
2024-12-10 13:58:18,645:INFO:Cross validation set to False
2024-12-10 13:58:18,645:INFO:Fitting Model
2024-12-10 13:58:18,648:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:58:18,692:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-12-10 13:58:18,692:INFO:create_model() successfully completed......................................
2024-12-10 13:58:18,738:INFO:Initializing create_model()
2024-12-10 13:58:18,738:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:18,738:INFO:Checking exceptions
2024-12-10 13:58:18,739:INFO:Importing libraries
2024-12-10 13:58:18,739:INFO:Copying training dataset
2024-12-10 13:58:18,741:INFO:Defining folds
2024-12-10 13:58:18,741:INFO:Declaring metric variables
2024-12-10 13:58:18,741:INFO:Importing untrained model
2024-12-10 13:58:18,741:INFO:Declaring custom model
2024-12-10 13:58:18,741:INFO:Logistic Regression Imported successfully
2024-12-10 13:58:18,741:INFO:Cross validation set to False
2024-12-10 13:58:18,741:INFO:Fitting Model
2024-12-10 13:58:18,751:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-10 13:58:18,751:INFO:create_model() successfully completed......................................
2024-12-10 13:58:18,795:INFO:Initializing create_model()
2024-12-10 13:58:18,795:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:18,795:INFO:Checking exceptions
2024-12-10 13:58:18,796:INFO:Importing libraries
2024-12-10 13:58:18,796:INFO:Copying training dataset
2024-12-10 13:58:18,798:INFO:Defining folds
2024-12-10 13:58:18,798:INFO:Declaring metric variables
2024-12-10 13:58:18,798:INFO:Importing untrained model
2024-12-10 13:58:18,798:INFO:Declaring custom model
2024-12-10 13:58:18,798:INFO:Ridge Classifier Imported successfully
2024-12-10 13:58:18,798:INFO:Cross validation set to False
2024-12-10 13:58:18,798:INFO:Fitting Model
2024-12-10 13:58:18,802:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-12-10 13:58:18,802:INFO:create_model() successfully completed......................................
2024-12-10 13:58:18,848:INFO:Initializing create_model()
2024-12-10 13:58:18,848:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:18,848:INFO:Checking exceptions
2024-12-10 13:58:18,849:INFO:Importing libraries
2024-12-10 13:58:18,849:INFO:Copying training dataset
2024-12-10 13:58:18,850:INFO:Defining folds
2024-12-10 13:58:18,850:INFO:Declaring metric variables
2024-12-10 13:58:18,850:INFO:Importing untrained model
2024-12-10 13:58:18,850:INFO:Declaring custom model
2024-12-10 13:58:18,850:INFO:Linear Discriminant Analysis Imported successfully
2024-12-10 13:58:18,851:INFO:Cross validation set to False
2024-12-10 13:58:18,851:INFO:Fitting Model
2024-12-10 13:58:18,854:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-10 13:58:18,854:INFO:create_model() successfully completed......................................
2024-12-10 13:58:18,898:INFO:Initializing create_model()
2024-12-10 13:58:18,898:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:18,898:INFO:Checking exceptions
2024-12-10 13:58:18,899:INFO:Importing libraries
2024-12-10 13:58:18,899:INFO:Copying training dataset
2024-12-10 13:58:18,900:INFO:Defining folds
2024-12-10 13:58:18,900:INFO:Declaring metric variables
2024-12-10 13:58:18,900:INFO:Importing untrained model
2024-12-10 13:58:18,900:INFO:Declaring custom model
2024-12-10 13:58:18,901:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-10 13:58:18,901:INFO:Cross validation set to False
2024-12-10 13:58:18,901:INFO:Fitting Model
2024-12-10 13:58:18,904:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-10 13:58:18,904:INFO:create_model() successfully completed......................................
2024-12-10 13:58:18,947:INFO:Initializing create_model()
2024-12-10 13:58:18,948:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:18,948:INFO:Checking exceptions
2024-12-10 13:58:18,948:INFO:Importing libraries
2024-12-10 13:58:18,948:INFO:Copying training dataset
2024-12-10 13:58:18,950:INFO:Defining folds
2024-12-10 13:58:18,950:INFO:Declaring metric variables
2024-12-10 13:58:18,950:INFO:Importing untrained model
2024-12-10 13:58:18,950:INFO:Declaring custom model
2024-12-10 13:58:18,950:INFO:Extra Trees Classifier Imported successfully
2024-12-10 13:58:18,950:INFO:Cross validation set to False
2024-12-10 13:58:18,950:INFO:Fitting Model
2024-12-10 13:58:19,003:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-12-10 13:58:19,003:INFO:create_model() successfully completed......................................
2024-12-10 13:58:19,047:INFO:Initializing create_model()
2024-12-10 13:58:19,047:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:19,047:INFO:Checking exceptions
2024-12-10 13:58:19,048:INFO:Importing libraries
2024-12-10 13:58:19,048:INFO:Copying training dataset
2024-12-10 13:58:19,050:INFO:Defining folds
2024-12-10 13:58:19,050:INFO:Declaring metric variables
2024-12-10 13:58:19,050:INFO:Importing untrained model
2024-12-10 13:58:19,050:INFO:Declaring custom model
2024-12-10 13:58:19,050:INFO:Naive Bayes Imported successfully
2024-12-10 13:58:19,050:INFO:Cross validation set to False
2024-12-10 13:58:19,050:INFO:Fitting Model
2024-12-10 13:58:19,053:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-10 13:58:19,053:INFO:create_model() successfully completed......................................
2024-12-10 13:58:19,098:INFO:Initializing create_model()
2024-12-10 13:58:19,098:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:19,098:INFO:Checking exceptions
2024-12-10 13:58:19,099:INFO:Importing libraries
2024-12-10 13:58:19,099:INFO:Copying training dataset
2024-12-10 13:58:19,100:INFO:Defining folds
2024-12-10 13:58:19,100:INFO:Declaring metric variables
2024-12-10 13:58:19,101:INFO:Importing untrained model
2024-12-10 13:58:19,101:INFO:Declaring custom model
2024-12-10 13:58:19,101:INFO:Decision Tree Classifier Imported successfully
2024-12-10 13:58:19,101:INFO:Cross validation set to False
2024-12-10 13:58:19,101:INFO:Fitting Model
2024-12-10 13:58:19,105:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-12-10 13:58:19,105:INFO:create_model() successfully completed......................................
2024-12-10 13:58:19,152:INFO:Initializing create_model()
2024-12-10 13:58:19,153:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:19,153:INFO:Checking exceptions
2024-12-10 13:58:19,154:INFO:Importing libraries
2024-12-10 13:58:19,154:INFO:Copying training dataset
2024-12-10 13:58:19,155:INFO:Defining folds
2024-12-10 13:58:19,155:INFO:Declaring metric variables
2024-12-10 13:58:19,155:INFO:Importing untrained model
2024-12-10 13:58:19,155:INFO:Declaring custom model
2024-12-10 13:58:19,155:INFO:K Neighbors Classifier Imported successfully
2024-12-10 13:58:19,156:INFO:Cross validation set to False
2024-12-10 13:58:19,156:INFO:Fitting Model
2024-12-10 13:58:19,159:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-10 13:58:19,159:INFO:create_model() successfully completed......................................
2024-12-10 13:58:19,206:INFO:Initializing create_model()
2024-12-10 13:58:19,206:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:19,207:INFO:Checking exceptions
2024-12-10 13:58:19,207:INFO:Importing libraries
2024-12-10 13:58:19,207:INFO:Copying training dataset
2024-12-10 13:58:19,209:INFO:Defining folds
2024-12-10 13:58:19,209:INFO:Declaring metric variables
2024-12-10 13:58:19,209:INFO:Importing untrained model
2024-12-10 13:58:19,209:INFO:Declaring custom model
2024-12-10 13:58:19,209:INFO:SVM - Linear Kernel Imported successfully
2024-12-10 13:58:19,209:INFO:Cross validation set to False
2024-12-10 13:58:19,210:INFO:Fitting Model
2024-12-10 13:58:19,213:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-10 13:58:19,213:INFO:create_model() successfully completed......................................
2024-12-10 13:58:19,260:INFO:Initializing create_model()
2024-12-10 13:58:19,261:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:19,261:INFO:Checking exceptions
2024-12-10 13:58:19,262:INFO:Importing libraries
2024-12-10 13:58:19,262:INFO:Copying training dataset
2024-12-10 13:58:19,263:INFO:Defining folds
2024-12-10 13:58:19,263:INFO:Declaring metric variables
2024-12-10 13:58:19,263:INFO:Importing untrained model
2024-12-10 13:58:19,263:INFO:Declaring custom model
2024-12-10 13:58:19,263:INFO:Dummy Classifier Imported successfully
2024-12-10 13:58:19,264:INFO:Cross validation set to False
2024-12-10 13:58:19,264:INFO:Fitting Model
2024-12-10 13:58:19,266:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-12-10 13:58:19,266:INFO:create_model() successfully completed......................................
2024-12-10 13:58:19,318:INFO:_master_model_container: 16
2024-12-10 13:58:19,319:INFO:_display_container: 2
2024-12-10 13:58:19,320:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), <catboost.core.CatBoostClassifier object at 0x000001E478BBA2D0>, GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), DummyClassifier(constant=None, random_state=123, strategy='prior')]
2024-12-10 13:58:19,320:INFO:compare_models() successfully completed......................................
2024-12-10 13:58:19,326:INFO:Initializing finalize_model()
2024-12-10 13:58:19,326:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, estimator=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), <catboost.core.CatBoostClassifier object at 0x000001E478BBA2D0>, GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), DummyClassifier(constant=None, random_state=123, strategy='prior')], fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-12-10 13:58:19,327:INFO:Finalizing [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), <catboost.core.CatBoostClassifier object at 0x000001E478BBA2D0>, GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), DummyClassifier(constant=None, random_state=123, strategy='prior')]
2024-12-10 13:58:19,330:INFO:Initializing create_model()
2024-12-10 13:58:19,330:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E476F9C850>, estimator=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), <catboost.core.CatBoostClassifier object at 0x000001E478BBA2D0>, GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), DummyClassifier(constant=None, random_state=123, strategy='prior')], fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:19,330:INFO:Checking exceptions
2024-12-10 13:58:59,085:INFO:PyCaret ClassificationExperiment
2024-12-10 13:58:59,085:INFO:Logging name: clf-default-name
2024-12-10 13:58:59,085:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-12-10 13:58:59,085:INFO:version 3.3.2
2024-12-10 13:58:59,085:INFO:Initializing setup()
2024-12-10 13:58:59,085:INFO:self.USI: f16f
2024-12-10 13:58:59,085:INFO:self._variable_keys: {'X', '_ml_usecase', 'data', 'exp_name_log', 'USI', 'target_param', 'exp_id', 'html_param', 'y_test', 'n_jobs_param', 'idx', 'log_plots_param', 'fold_shuffle_param', 'memory', 'pipeline', 'X_test', 'logging_param', 'fix_imbalance', '_available_plots', 'X_train', 'gpu_n_jobs_param', 'y', 'fold_generator', 'gpu_param', 'y_train', 'seed', 'fold_groups_param', 'is_multiclass'}
2024-12-10 13:58:59,085:INFO:Checking environment
2024-12-10 13:58:59,086:INFO:python_version: 3.11.10
2024-12-10 13:58:59,086:INFO:python_build: ('main', 'Oct  3 2024 07:22:26')
2024-12-10 13:58:59,086:INFO:machine: AMD64
2024-12-10 13:58:59,086:INFO:platform: Windows-10-10.0.19045-SP0
2024-12-10 13:58:59,088:INFO:Memory: svmem(total=16908595200, available=2757459968, percent=83.7, used=14151135232, free=2757459968)
2024-12-10 13:58:59,088:INFO:Physical Core: 16
2024-12-10 13:58:59,088:INFO:Logical Core: 24
2024-12-10 13:58:59,088:INFO:Checking libraries
2024-12-10 13:58:59,088:INFO:System:
2024-12-10 13:58:59,088:INFO:    python: 3.11.10 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:26) [MSC v.1929 64 bit (AMD64)]
2024-12-10 13:58:59,088:INFO:executable: c:\Users\py\.conda\envs\hw4\python.exe
2024-12-10 13:58:59,088:INFO:   machine: Windows-10-10.0.19045-SP0
2024-12-10 13:58:59,088:INFO:PyCaret required dependencies:
2024-12-10 13:58:59,088:INFO:                 pip: 24.2
2024-12-10 13:58:59,088:INFO:          setuptools: 75.1.0
2024-12-10 13:58:59,088:INFO:             pycaret: 3.3.2
2024-12-10 13:58:59,088:INFO:             IPython: 8.30.0
2024-12-10 13:58:59,088:INFO:          ipywidgets: 8.1.5
2024-12-10 13:58:59,088:INFO:                tqdm: 4.67.1
2024-12-10 13:58:59,088:INFO:               numpy: 1.26.4
2024-12-10 13:58:59,088:INFO:              pandas: 2.1.4
2024-12-10 13:58:59,088:INFO:              jinja2: 3.1.4
2024-12-10 13:58:59,088:INFO:               scipy: 1.11.4
2024-12-10 13:58:59,088:INFO:              joblib: 1.3.2
2024-12-10 13:58:59,089:INFO:             sklearn: 1.4.2
2024-12-10 13:58:59,089:INFO:                pyod: 2.0.2
2024-12-10 13:58:59,089:INFO:            imblearn: 0.12.4
2024-12-10 13:58:59,089:INFO:   category_encoders: 2.6.4
2024-12-10 13:58:59,089:INFO:            lightgbm: 4.5.0
2024-12-10 13:58:59,089:INFO:               numba: 0.60.0
2024-12-10 13:58:59,089:INFO:            requests: 2.32.3
2024-12-10 13:58:59,089:INFO:          matplotlib: 3.7.5
2024-12-10 13:58:59,089:INFO:          scikitplot: 0.3.7
2024-12-10 13:58:59,089:INFO:         yellowbrick: 1.5
2024-12-10 13:58:59,089:INFO:              plotly: 5.24.1
2024-12-10 13:58:59,089:INFO:    plotly-resampler: Not installed
2024-12-10 13:58:59,089:INFO:             kaleido: 0.2.1
2024-12-10 13:58:59,089:INFO:           schemdraw: 0.15
2024-12-10 13:58:59,089:INFO:         statsmodels: 0.14.4
2024-12-10 13:58:59,089:INFO:              sktime: 0.26.0
2024-12-10 13:58:59,089:INFO:               tbats: 1.1.3
2024-12-10 13:58:59,089:INFO:            pmdarima: 2.0.4
2024-12-10 13:58:59,089:INFO:              psutil: 6.1.0
2024-12-10 13:58:59,089:INFO:          markupsafe: 3.0.2
2024-12-10 13:58:59,089:INFO:             pickle5: Not installed
2024-12-10 13:58:59,089:INFO:         cloudpickle: 3.1.0
2024-12-10 13:58:59,089:INFO:         deprecation: 2.1.0
2024-12-10 13:58:59,089:INFO:              xxhash: 3.5.0
2024-12-10 13:58:59,089:INFO:           wurlitzer: Not installed
2024-12-10 13:58:59,089:INFO:PyCaret optional dependencies:
2024-12-10 13:58:59,089:INFO:                shap: Not installed
2024-12-10 13:58:59,089:INFO:           interpret: Not installed
2024-12-10 13:58:59,089:INFO:                umap: Not installed
2024-12-10 13:58:59,089:INFO:     ydata_profiling: Not installed
2024-12-10 13:58:59,089:INFO:  explainerdashboard: Not installed
2024-12-10 13:58:59,089:INFO:             autoviz: Not installed
2024-12-10 13:58:59,089:INFO:           fairlearn: Not installed
2024-12-10 13:58:59,089:INFO:          deepchecks: Not installed
2024-12-10 13:58:59,089:INFO:             xgboost: 2.1.3
2024-12-10 13:58:59,089:INFO:            catboost: 1.2.7
2024-12-10 13:58:59,089:INFO:              kmodes: Not installed
2024-12-10 13:58:59,089:INFO:             mlxtend: Not installed
2024-12-10 13:58:59,089:INFO:       statsforecast: Not installed
2024-12-10 13:58:59,089:INFO:        tune_sklearn: Not installed
2024-12-10 13:58:59,089:INFO:                 ray: Not installed
2024-12-10 13:58:59,089:INFO:            hyperopt: Not installed
2024-12-10 13:58:59,089:INFO:              optuna: Not installed
2024-12-10 13:58:59,089:INFO:               skopt: Not installed
2024-12-10 13:58:59,089:INFO:              mlflow: Not installed
2024-12-10 13:58:59,089:INFO:              gradio: Not installed
2024-12-10 13:58:59,089:INFO:             fastapi: Not installed
2024-12-10 13:58:59,089:INFO:             uvicorn: Not installed
2024-12-10 13:58:59,089:INFO:              m2cgen: Not installed
2024-12-10 13:58:59,089:INFO:           evidently: Not installed
2024-12-10 13:58:59,089:INFO:               fugue: Not installed
2024-12-10 13:58:59,089:INFO:           streamlit: Not installed
2024-12-10 13:58:59,089:INFO:             prophet: Not installed
2024-12-10 13:58:59,089:INFO:None
2024-12-10 13:58:59,089:INFO:Set up data.
2024-12-10 13:58:59,092:INFO:Set up folding strategy.
2024-12-10 13:58:59,092:INFO:Set up train/test split.
2024-12-10 13:58:59,093:INFO:Set up index.
2024-12-10 13:58:59,094:INFO:Assigning column types.
2024-12-10 13:58:59,095:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-10 13:58:59,116:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-10 13:58:59,116:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-10 13:58:59,129:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 13:58:59,130:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 13:58:59,150:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-10 13:58:59,150:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-10 13:58:59,163:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 13:58:59,164:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 13:58:59,165:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-10 13:58:59,185:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-10 13:58:59,198:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 13:58:59,199:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 13:58:59,220:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-10 13:58:59,232:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 13:58:59,233:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 13:58:59,234:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-12-10 13:58:59,266:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 13:58:59,268:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 13:58:59,301:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 13:58:59,302:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 13:58:59,302:INFO:Preparing preprocessing pipeline...
2024-12-10 13:58:59,303:INFO:Set up simple imputation.
2024-12-10 13:58:59,311:INFO:Finished creating preprocessing pipeline.
2024-12-10 13:58:59,313:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\py\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'SibSp',
                                             'Parch', 'Fare', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-12-10 13:58:59,313:INFO:Creating final display dataframe.
2024-12-10 13:58:59,338:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (891, 8)
4        Transformed data shape          (891, 8)
5   Transformed train set shape          (623, 8)
6    Transformed test set shape          (268, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              f16f
2024-12-10 13:58:59,386:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 13:58:59,387:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 13:58:59,421:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 13:58:59,422:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 13:58:59,424:INFO:setup() successfully completed in 0.34s...............
2024-12-10 13:58:59,424:INFO:Initializing compare_models()
2024-12-10 13:58:59,424:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E478FF9390>, include=None, exclude=['dummy'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=16, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E478FF9390>, 'include': None, 'exclude': ['dummy'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 16, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-12-10 13:58:59,424:INFO:Checking exceptions
2024-12-10 13:58:59,425:INFO:Preparing display monitor
2024-12-10 13:58:59,435:INFO:Initializing Logistic Regression
2024-12-10 13:58:59,435:INFO:Total runtime is 0.0 minutes
2024-12-10 13:58:59,436:INFO:SubProcess create_model() called ==================================
2024-12-10 13:58:59,436:INFO:Initializing create_model()
2024-12-10 13:58:59,436:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E478FF9390>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E40081BE50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:59,436:INFO:Checking exceptions
2024-12-10 13:58:59,436:INFO:Importing libraries
2024-12-10 13:58:59,436:INFO:Copying training dataset
2024-12-10 13:58:59,438:INFO:Defining folds
2024-12-10 13:58:59,438:INFO:Declaring metric variables
2024-12-10 13:58:59,439:INFO:Importing untrained model
2024-12-10 13:58:59,441:INFO:Logistic Regression Imported successfully
2024-12-10 13:58:59,443:INFO:Starting cross validation
2024-12-10 13:58:59,444:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:58:59,481:INFO:Calculating mean and std
2024-12-10 13:58:59,481:INFO:Creating metrics dataframe
2024-12-10 13:58:59,482:INFO:Uploading results into container
2024-12-10 13:58:59,482:INFO:Uploading model into container now
2024-12-10 13:58:59,482:INFO:_master_model_container: 1
2024-12-10 13:58:59,482:INFO:_display_container: 2
2024-12-10 13:58:59,482:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-10 13:58:59,482:INFO:create_model() successfully completed......................................
2024-12-10 13:58:59,547:INFO:SubProcess create_model() end ==================================
2024-12-10 13:58:59,547:INFO:Creating metrics dataframe
2024-12-10 13:58:59,550:INFO:Initializing K Neighbors Classifier
2024-12-10 13:58:59,550:INFO:Total runtime is 0.0019103566805521647 minutes
2024-12-10 13:58:59,552:INFO:SubProcess create_model() called ==================================
2024-12-10 13:58:59,552:INFO:Initializing create_model()
2024-12-10 13:58:59,552:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E478FF9390>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E40081BE50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:59,552:INFO:Checking exceptions
2024-12-10 13:58:59,552:INFO:Importing libraries
2024-12-10 13:58:59,552:INFO:Copying training dataset
2024-12-10 13:58:59,554:INFO:Defining folds
2024-12-10 13:58:59,554:INFO:Declaring metric variables
2024-12-10 13:58:59,555:INFO:Importing untrained model
2024-12-10 13:58:59,556:INFO:K Neighbors Classifier Imported successfully
2024-12-10 13:58:59,560:INFO:Starting cross validation
2024-12-10 13:58:59,561:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:58:59,630:INFO:Calculating mean and std
2024-12-10 13:58:59,630:INFO:Creating metrics dataframe
2024-12-10 13:58:59,631:INFO:Uploading results into container
2024-12-10 13:58:59,631:INFO:Uploading model into container now
2024-12-10 13:58:59,631:INFO:_master_model_container: 2
2024-12-10 13:58:59,631:INFO:_display_container: 2
2024-12-10 13:58:59,631:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-10 13:58:59,631:INFO:create_model() successfully completed......................................
2024-12-10 13:58:59,692:INFO:SubProcess create_model() end ==================================
2024-12-10 13:58:59,692:INFO:Creating metrics dataframe
2024-12-10 13:58:59,694:INFO:Initializing Naive Bayes
2024-12-10 13:58:59,694:INFO:Total runtime is 0.0043217976888020836 minutes
2024-12-10 13:58:59,696:INFO:SubProcess create_model() called ==================================
2024-12-10 13:58:59,696:INFO:Initializing create_model()
2024-12-10 13:58:59,696:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E478FF9390>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E40081BE50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:59,696:INFO:Checking exceptions
2024-12-10 13:58:59,696:INFO:Importing libraries
2024-12-10 13:58:59,696:INFO:Copying training dataset
2024-12-10 13:58:59,697:INFO:Defining folds
2024-12-10 13:58:59,698:INFO:Declaring metric variables
2024-12-10 13:58:59,699:INFO:Importing untrained model
2024-12-10 13:58:59,700:INFO:Naive Bayes Imported successfully
2024-12-10 13:58:59,702:INFO:Starting cross validation
2024-12-10 13:58:59,703:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:58:59,739:INFO:Calculating mean and std
2024-12-10 13:58:59,740:INFO:Creating metrics dataframe
2024-12-10 13:58:59,741:INFO:Uploading results into container
2024-12-10 13:58:59,741:INFO:Uploading model into container now
2024-12-10 13:58:59,742:INFO:_master_model_container: 3
2024-12-10 13:58:59,742:INFO:_display_container: 2
2024-12-10 13:58:59,742:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-10 13:58:59,742:INFO:create_model() successfully completed......................................
2024-12-10 13:58:59,798:INFO:SubProcess create_model() end ==================================
2024-12-10 13:58:59,798:INFO:Creating metrics dataframe
2024-12-10 13:58:59,802:INFO:Initializing Decision Tree Classifier
2024-12-10 13:58:59,802:INFO:Total runtime is 0.006117276350657145 minutes
2024-12-10 13:58:59,803:INFO:SubProcess create_model() called ==================================
2024-12-10 13:58:59,803:INFO:Initializing create_model()
2024-12-10 13:58:59,803:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E478FF9390>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E40081BE50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:59,804:INFO:Checking exceptions
2024-12-10 13:58:59,804:INFO:Importing libraries
2024-12-10 13:58:59,804:INFO:Copying training dataset
2024-12-10 13:58:59,805:INFO:Defining folds
2024-12-10 13:58:59,805:INFO:Declaring metric variables
2024-12-10 13:58:59,806:INFO:Importing untrained model
2024-12-10 13:58:59,808:INFO:Decision Tree Classifier Imported successfully
2024-12-10 13:58:59,810:INFO:Starting cross validation
2024-12-10 13:58:59,811:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:58:59,836:INFO:Calculating mean and std
2024-12-10 13:58:59,836:INFO:Creating metrics dataframe
2024-12-10 13:58:59,837:INFO:Uploading results into container
2024-12-10 13:58:59,837:INFO:Uploading model into container now
2024-12-10 13:58:59,837:INFO:_master_model_container: 4
2024-12-10 13:58:59,837:INFO:_display_container: 2
2024-12-10 13:58:59,837:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-12-10 13:58:59,837:INFO:create_model() successfully completed......................................
2024-12-10 13:58:59,904:INFO:SubProcess create_model() end ==================================
2024-12-10 13:58:59,904:INFO:Creating metrics dataframe
2024-12-10 13:58:59,908:INFO:Initializing SVM - Linear Kernel
2024-12-10 13:58:59,908:INFO:Total runtime is 0.007878061135609946 minutes
2024-12-10 13:58:59,910:INFO:SubProcess create_model() called ==================================
2024-12-10 13:58:59,910:INFO:Initializing create_model()
2024-12-10 13:58:59,910:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E478FF9390>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E40081BE50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:58:59,910:INFO:Checking exceptions
2024-12-10 13:58:59,911:INFO:Importing libraries
2024-12-10 13:58:59,911:INFO:Copying training dataset
2024-12-10 13:58:59,912:INFO:Defining folds
2024-12-10 13:58:59,912:INFO:Declaring metric variables
2024-12-10 13:58:59,913:INFO:Importing untrained model
2024-12-10 13:58:59,915:INFO:SVM - Linear Kernel Imported successfully
2024-12-10 13:58:59,918:INFO:Starting cross validation
2024-12-10 13:58:59,918:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:58:59,944:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 13:58:59,954:INFO:Calculating mean and std
2024-12-10 13:58:59,954:INFO:Creating metrics dataframe
2024-12-10 13:58:59,955:INFO:Uploading results into container
2024-12-10 13:58:59,955:INFO:Uploading model into container now
2024-12-10 13:58:59,955:INFO:_master_model_container: 5
2024-12-10 13:58:59,955:INFO:_display_container: 2
2024-12-10 13:58:59,955:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-10 13:58:59,956:INFO:create_model() successfully completed......................................
2024-12-10 13:59:00,019:INFO:SubProcess create_model() end ==================================
2024-12-10 13:59:00,019:INFO:Creating metrics dataframe
2024-12-10 13:59:00,024:INFO:Initializing Ridge Classifier
2024-12-10 13:59:00,024:INFO:Total runtime is 0.009806700547536216 minutes
2024-12-10 13:59:00,025:INFO:SubProcess create_model() called ==================================
2024-12-10 13:59:00,025:INFO:Initializing create_model()
2024-12-10 13:59:00,025:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E478FF9390>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E40081BE50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:00,025:INFO:Checking exceptions
2024-12-10 13:59:00,025:INFO:Importing libraries
2024-12-10 13:59:00,025:INFO:Copying training dataset
2024-12-10 13:59:00,026:INFO:Defining folds
2024-12-10 13:59:00,026:INFO:Declaring metric variables
2024-12-10 13:59:00,028:INFO:Importing untrained model
2024-12-10 13:59:00,029:INFO:Ridge Classifier Imported successfully
2024-12-10 13:59:00,031:INFO:Starting cross validation
2024-12-10 13:59:00,032:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:59:00,058:INFO:Calculating mean and std
2024-12-10 13:59:00,058:INFO:Creating metrics dataframe
2024-12-10 13:59:00,059:INFO:Uploading results into container
2024-12-10 13:59:00,059:INFO:Uploading model into container now
2024-12-10 13:59:00,060:INFO:_master_model_container: 6
2024-12-10 13:59:00,060:INFO:_display_container: 2
2024-12-10 13:59:00,060:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-12-10 13:59:00,060:INFO:create_model() successfully completed......................................
2024-12-10 13:59:00,119:INFO:SubProcess create_model() end ==================================
2024-12-10 13:59:00,119:INFO:Creating metrics dataframe
2024-12-10 13:59:00,123:INFO:Initializing Random Forest Classifier
2024-12-10 13:59:00,123:INFO:Total runtime is 0.011464027563730878 minutes
2024-12-10 13:59:00,125:INFO:SubProcess create_model() called ==================================
2024-12-10 13:59:00,125:INFO:Initializing create_model()
2024-12-10 13:59:00,125:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E478FF9390>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E40081BE50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:00,125:INFO:Checking exceptions
2024-12-10 13:59:00,125:INFO:Importing libraries
2024-12-10 13:59:00,125:INFO:Copying training dataset
2024-12-10 13:59:00,126:INFO:Defining folds
2024-12-10 13:59:00,127:INFO:Declaring metric variables
2024-12-10 13:59:00,128:INFO:Importing untrained model
2024-12-10 13:59:00,129:INFO:Random Forest Classifier Imported successfully
2024-12-10 13:59:00,132:INFO:Starting cross validation
2024-12-10 13:59:00,132:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:59:00,382:INFO:Calculating mean and std
2024-12-10 13:59:00,382:INFO:Creating metrics dataframe
2024-12-10 13:59:00,383:INFO:Uploading results into container
2024-12-10 13:59:00,383:INFO:Uploading model into container now
2024-12-10 13:59:00,383:INFO:_master_model_container: 7
2024-12-10 13:59:00,383:INFO:_display_container: 2
2024-12-10 13:59:00,383:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-12-10 13:59:00,383:INFO:create_model() successfully completed......................................
2024-12-10 13:59:00,439:INFO:SubProcess create_model() end ==================================
2024-12-10 13:59:00,439:INFO:Creating metrics dataframe
2024-12-10 13:59:00,443:INFO:Initializing Quadratic Discriminant Analysis
2024-12-10 13:59:00,443:INFO:Total runtime is 0.016796179612477622 minutes
2024-12-10 13:59:00,444:INFO:SubProcess create_model() called ==================================
2024-12-10 13:59:00,445:INFO:Initializing create_model()
2024-12-10 13:59:00,445:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E478FF9390>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E40081BE50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:00,445:INFO:Checking exceptions
2024-12-10 13:59:00,445:INFO:Importing libraries
2024-12-10 13:59:00,445:INFO:Copying training dataset
2024-12-10 13:59:00,446:INFO:Defining folds
2024-12-10 13:59:00,446:INFO:Declaring metric variables
2024-12-10 13:59:00,448:INFO:Importing untrained model
2024-12-10 13:59:00,450:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-10 13:59:00,452:INFO:Starting cross validation
2024-12-10 13:59:00,453:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:59:00,489:INFO:Calculating mean and std
2024-12-10 13:59:00,489:INFO:Creating metrics dataframe
2024-12-10 13:59:00,490:INFO:Uploading results into container
2024-12-10 13:59:00,490:INFO:Uploading model into container now
2024-12-10 13:59:00,490:INFO:_master_model_container: 8
2024-12-10 13:59:00,490:INFO:_display_container: 2
2024-12-10 13:59:00,491:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-10 13:59:00,491:INFO:create_model() successfully completed......................................
2024-12-10 13:59:00,550:INFO:SubProcess create_model() end ==================================
2024-12-10 13:59:00,550:INFO:Creating metrics dataframe
2024-12-10 13:59:00,554:INFO:Initializing Ada Boost Classifier
2024-12-10 13:59:00,554:INFO:Total runtime is 0.018641316890716554 minutes
2024-12-10 13:59:00,556:INFO:SubProcess create_model() called ==================================
2024-12-10 13:59:00,556:INFO:Initializing create_model()
2024-12-10 13:59:00,556:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E478FF9390>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E40081BE50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:00,556:INFO:Checking exceptions
2024-12-10 13:59:00,556:INFO:Importing libraries
2024-12-10 13:59:00,556:INFO:Copying training dataset
2024-12-10 13:59:00,558:INFO:Defining folds
2024-12-10 13:59:00,558:INFO:Declaring metric variables
2024-12-10 13:59:00,560:INFO:Importing untrained model
2024-12-10 13:59:00,562:INFO:Ada Boost Classifier Imported successfully
2024-12-10 13:59:00,565:INFO:Starting cross validation
2024-12-10 13:59:00,565:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:59:00,575:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:59:00,575:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:59:00,576:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:59:00,576:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:59:00,577:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:59:00,579:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:59:00,579:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:59:00,581:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:59:00,581:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:59:00,584:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:59:00,655:INFO:Calculating mean and std
2024-12-10 13:59:00,655:INFO:Creating metrics dataframe
2024-12-10 13:59:00,656:INFO:Uploading results into container
2024-12-10 13:59:00,657:INFO:Uploading model into container now
2024-12-10 13:59:00,657:INFO:_master_model_container: 9
2024-12-10 13:59:00,657:INFO:_display_container: 2
2024-12-10 13:59:00,657:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-12-10 13:59:00,657:INFO:create_model() successfully completed......................................
2024-12-10 13:59:00,712:INFO:SubProcess create_model() end ==================================
2024-12-10 13:59:00,713:INFO:Creating metrics dataframe
2024-12-10 13:59:00,717:INFO:Initializing Gradient Boosting Classifier
2024-12-10 13:59:00,717:INFO:Total runtime is 0.021366759141286214 minutes
2024-12-10 13:59:00,718:INFO:SubProcess create_model() called ==================================
2024-12-10 13:59:00,718:INFO:Initializing create_model()
2024-12-10 13:59:00,719:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E478FF9390>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E40081BE50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:00,719:INFO:Checking exceptions
2024-12-10 13:59:00,719:INFO:Importing libraries
2024-12-10 13:59:00,719:INFO:Copying training dataset
2024-12-10 13:59:00,720:INFO:Defining folds
2024-12-10 13:59:00,720:INFO:Declaring metric variables
2024-12-10 13:59:00,723:INFO:Importing untrained model
2024-12-10 13:59:00,725:INFO:Gradient Boosting Classifier Imported successfully
2024-12-10 13:59:00,728:INFO:Starting cross validation
2024-12-10 13:59:00,728:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:59:00,836:INFO:Calculating mean and std
2024-12-10 13:59:00,836:INFO:Creating metrics dataframe
2024-12-10 13:59:00,837:INFO:Uploading results into container
2024-12-10 13:59:00,837:INFO:Uploading model into container now
2024-12-10 13:59:00,838:INFO:_master_model_container: 10
2024-12-10 13:59:00,838:INFO:_display_container: 2
2024-12-10 13:59:00,838:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-10 13:59:00,838:INFO:create_model() successfully completed......................................
2024-12-10 13:59:00,895:INFO:SubProcess create_model() end ==================================
2024-12-10 13:59:00,895:INFO:Creating metrics dataframe
2024-12-10 13:59:00,899:INFO:Initializing Linear Discriminant Analysis
2024-12-10 13:59:00,899:INFO:Total runtime is 0.024393324057261148 minutes
2024-12-10 13:59:00,901:INFO:SubProcess create_model() called ==================================
2024-12-10 13:59:00,901:INFO:Initializing create_model()
2024-12-10 13:59:00,901:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E478FF9390>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E40081BE50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:00,901:INFO:Checking exceptions
2024-12-10 13:59:00,901:INFO:Importing libraries
2024-12-10 13:59:00,901:INFO:Copying training dataset
2024-12-10 13:59:00,902:INFO:Defining folds
2024-12-10 13:59:00,902:INFO:Declaring metric variables
2024-12-10 13:59:00,904:INFO:Importing untrained model
2024-12-10 13:59:00,905:INFO:Linear Discriminant Analysis Imported successfully
2024-12-10 13:59:00,908:INFO:Starting cross validation
2024-12-10 13:59:00,908:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:59:00,946:INFO:Calculating mean and std
2024-12-10 13:59:00,946:INFO:Creating metrics dataframe
2024-12-10 13:59:00,947:INFO:Uploading results into container
2024-12-10 13:59:00,948:INFO:Uploading model into container now
2024-12-10 13:59:00,948:INFO:_master_model_container: 11
2024-12-10 13:59:00,948:INFO:_display_container: 2
2024-12-10 13:59:00,948:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-10 13:59:00,948:INFO:create_model() successfully completed......................................
2024-12-10 13:59:01,006:INFO:SubProcess create_model() end ==================================
2024-12-10 13:59:01,006:INFO:Creating metrics dataframe
2024-12-10 13:59:01,011:INFO:Initializing Extra Trees Classifier
2024-12-10 13:59:01,011:INFO:Total runtime is 0.026255826155344643 minutes
2024-12-10 13:59:01,012:INFO:SubProcess create_model() called ==================================
2024-12-10 13:59:01,012:INFO:Initializing create_model()
2024-12-10 13:59:01,012:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E478FF9390>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E40081BE50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:01,012:INFO:Checking exceptions
2024-12-10 13:59:01,013:INFO:Importing libraries
2024-12-10 13:59:01,013:INFO:Copying training dataset
2024-12-10 13:59:01,014:INFO:Defining folds
2024-12-10 13:59:01,014:INFO:Declaring metric variables
2024-12-10 13:59:01,015:INFO:Importing untrained model
2024-12-10 13:59:01,017:INFO:Extra Trees Classifier Imported successfully
2024-12-10 13:59:01,019:INFO:Starting cross validation
2024-12-10 13:59:01,020:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:59:01,207:INFO:Calculating mean and std
2024-12-10 13:59:01,207:INFO:Creating metrics dataframe
2024-12-10 13:59:01,208:INFO:Uploading results into container
2024-12-10 13:59:01,209:INFO:Uploading model into container now
2024-12-10 13:59:01,209:INFO:_master_model_container: 12
2024-12-10 13:59:01,209:INFO:_display_container: 2
2024-12-10 13:59:01,209:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-12-10 13:59:01,209:INFO:create_model() successfully completed......................................
2024-12-10 13:59:01,265:INFO:SubProcess create_model() end ==================================
2024-12-10 13:59:01,266:INFO:Creating metrics dataframe
2024-12-10 13:59:01,270:INFO:Initializing Extreme Gradient Boosting
2024-12-10 13:59:01,270:INFO:Total runtime is 0.03058446645736694 minutes
2024-12-10 13:59:01,272:INFO:SubProcess create_model() called ==================================
2024-12-10 13:59:01,272:INFO:Initializing create_model()
2024-12-10 13:59:01,272:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E478FF9390>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E40081BE50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:01,272:INFO:Checking exceptions
2024-12-10 13:59:01,272:INFO:Importing libraries
2024-12-10 13:59:01,273:INFO:Copying training dataset
2024-12-10 13:59:01,274:INFO:Defining folds
2024-12-10 13:59:01,274:INFO:Declaring metric variables
2024-12-10 13:59:01,275:INFO:Importing untrained model
2024-12-10 13:59:01,277:INFO:Extreme Gradient Boosting Imported successfully
2024-12-10 13:59:01,279:INFO:Starting cross validation
2024-12-10 13:59:01,280:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:59:01,350:INFO:Calculating mean and std
2024-12-10 13:59:01,350:INFO:Creating metrics dataframe
2024-12-10 13:59:01,351:INFO:Uploading results into container
2024-12-10 13:59:01,351:INFO:Uploading model into container now
2024-12-10 13:59:01,351:INFO:_master_model_container: 13
2024-12-10 13:59:01,352:INFO:_display_container: 2
2024-12-10 13:59:01,352:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-12-10 13:59:01,352:INFO:create_model() successfully completed......................................
2024-12-10 13:59:01,408:INFO:SubProcess create_model() end ==================================
2024-12-10 13:59:01,408:INFO:Creating metrics dataframe
2024-12-10 13:59:01,413:INFO:Initializing Light Gradient Boosting Machine
2024-12-10 13:59:01,414:INFO:Total runtime is 0.03296290238698323 minutes
2024-12-10 13:59:01,415:INFO:SubProcess create_model() called ==================================
2024-12-10 13:59:01,415:INFO:Initializing create_model()
2024-12-10 13:59:01,415:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E478FF9390>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E40081BE50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:01,415:INFO:Checking exceptions
2024-12-10 13:59:01,415:INFO:Importing libraries
2024-12-10 13:59:01,415:INFO:Copying training dataset
2024-12-10 13:59:01,416:INFO:Defining folds
2024-12-10 13:59:01,417:INFO:Declaring metric variables
2024-12-10 13:59:01,418:INFO:Importing untrained model
2024-12-10 13:59:01,419:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-10 13:59:01,422:INFO:Starting cross validation
2024-12-10 13:59:01,423:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:59:02,162:INFO:Calculating mean and std
2024-12-10 13:59:02,162:INFO:Creating metrics dataframe
2024-12-10 13:59:02,164:INFO:Uploading results into container
2024-12-10 13:59:02,164:INFO:Uploading model into container now
2024-12-10 13:59:02,164:INFO:_master_model_container: 14
2024-12-10 13:59:02,164:INFO:_display_container: 2
2024-12-10 13:59:02,165:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-10 13:59:02,165:INFO:create_model() successfully completed......................................
2024-12-10 13:59:02,229:INFO:SubProcess create_model() end ==================================
2024-12-10 13:59:02,229:INFO:Creating metrics dataframe
2024-12-10 13:59:02,235:INFO:Initializing CatBoost Classifier
2024-12-10 13:59:02,235:INFO:Total runtime is 0.04665570259094238 minutes
2024-12-10 13:59:02,238:INFO:SubProcess create_model() called ==================================
2024-12-10 13:59:02,238:INFO:Initializing create_model()
2024-12-10 13:59:02,238:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E478FF9390>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E40081BE50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:02,238:INFO:Checking exceptions
2024-12-10 13:59:02,238:INFO:Importing libraries
2024-12-10 13:59:02,238:INFO:Copying training dataset
2024-12-10 13:59:02,240:INFO:Defining folds
2024-12-10 13:59:02,240:INFO:Declaring metric variables
2024-12-10 13:59:02,242:INFO:Importing untrained model
2024-12-10 13:59:02,242:INFO:CatBoost Classifier Imported successfully
2024-12-10 13:59:02,246:INFO:Starting cross validation
2024-12-10 13:59:02,247:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:59:04,072:INFO:Calculating mean and std
2024-12-10 13:59:04,072:INFO:Creating metrics dataframe
2024-12-10 13:59:04,073:INFO:Uploading results into container
2024-12-10 13:59:04,074:INFO:Uploading model into container now
2024-12-10 13:59:04,074:INFO:_master_model_container: 15
2024-12-10 13:59:04,074:INFO:_display_container: 2
2024-12-10 13:59:04,074:INFO:<catboost.core.CatBoostClassifier object at 0x000001E415146250>
2024-12-10 13:59:04,074:INFO:create_model() successfully completed......................................
2024-12-10 13:59:04,144:INFO:SubProcess create_model() end ==================================
2024-12-10 13:59:04,144:INFO:Creating metrics dataframe
2024-12-10 13:59:04,149:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-12-10 13:59:04,153:INFO:Initializing create_model()
2024-12-10 13:59:04,153:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E478FF9390>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:04,153:INFO:Checking exceptions
2024-12-10 13:59:04,154:INFO:Importing libraries
2024-12-10 13:59:04,154:INFO:Copying training dataset
2024-12-10 13:59:04,155:INFO:Defining folds
2024-12-10 13:59:04,155:INFO:Declaring metric variables
2024-12-10 13:59:04,155:INFO:Importing untrained model
2024-12-10 13:59:04,155:INFO:Declaring custom model
2024-12-10 13:59:04,156:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-10 13:59:04,156:INFO:Cross validation set to False
2024-12-10 13:59:04,156:INFO:Fitting Model
2024-12-10 13:59:04,161:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-10 13:59:04,162:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000207 seconds.
2024-12-10 13:59:04,162:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-10 13:59:04,162:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-10 13:59:04,162:INFO:[LightGBM] [Info] Total Bins 188
2024-12-10 13:59:04,162:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 7
2024-12-10 13:59:04,162:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-10 13:59:04,162:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-10 13:59:04,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:04,231:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-10 13:59:04,231:INFO:create_model() successfully completed......................................
2024-12-10 13:59:04,296:INFO:Initializing create_model()
2024-12-10 13:59:04,296:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E478FF9390>, estimator=<catboost.core.CatBoostClassifier object at 0x000001E415146250>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:04,296:INFO:Checking exceptions
2024-12-10 13:59:04,297:INFO:Importing libraries
2024-12-10 13:59:04,297:INFO:Copying training dataset
2024-12-10 13:59:04,299:INFO:Defining folds
2024-12-10 13:59:04,299:INFO:Declaring metric variables
2024-12-10 13:59:04,299:INFO:Importing untrained model
2024-12-10 13:59:04,299:INFO:Declaring custom model
2024-12-10 13:59:04,299:INFO:CatBoost Classifier Imported successfully
2024-12-10 13:59:04,300:INFO:Cross validation set to False
2024-12-10 13:59:04,300:INFO:Fitting Model
2024-12-10 13:59:05,140:INFO:<catboost.core.CatBoostClassifier object at 0x000001E400547AD0>
2024-12-10 13:59:05,140:INFO:create_model() successfully completed......................................
2024-12-10 13:59:05,200:INFO:Initializing create_model()
2024-12-10 13:59:05,200:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E478FF9390>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:05,200:INFO:Checking exceptions
2024-12-10 13:59:05,201:INFO:Importing libraries
2024-12-10 13:59:05,201:INFO:Copying training dataset
2024-12-10 13:59:05,202:INFO:Defining folds
2024-12-10 13:59:05,202:INFO:Declaring metric variables
2024-12-10 13:59:05,202:INFO:Importing untrained model
2024-12-10 13:59:05,202:INFO:Declaring custom model
2024-12-10 13:59:05,203:INFO:Gradient Boosting Classifier Imported successfully
2024-12-10 13:59:05,203:INFO:Cross validation set to False
2024-12-10 13:59:05,203:INFO:Fitting Model
2024-12-10 13:59:05,262:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-10 13:59:05,262:INFO:create_model() successfully completed......................................
2024-12-10 13:59:05,319:INFO:Initializing create_model()
2024-12-10 13:59:05,319:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E478FF9390>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:05,319:INFO:Checking exceptions
2024-12-10 13:59:05,319:INFO:Importing libraries
2024-12-10 13:59:05,319:INFO:Copying training dataset
2024-12-10 13:59:05,322:INFO:Defining folds
2024-12-10 13:59:05,322:INFO:Declaring metric variables
2024-12-10 13:59:05,322:INFO:Importing untrained model
2024-12-10 13:59:05,322:INFO:Declaring custom model
2024-12-10 13:59:05,322:INFO:Random Forest Classifier Imported successfully
2024-12-10 13:59:05,322:INFO:Cross validation set to False
2024-12-10 13:59:05,322:INFO:Fitting Model
2024-12-10 13:59:05,404:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-12-10 13:59:05,404:INFO:create_model() successfully completed......................................
2024-12-10 13:59:05,467:INFO:Initializing create_model()
2024-12-10 13:59:05,467:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E478FF9390>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:05,468:INFO:Checking exceptions
2024-12-10 13:59:05,469:INFO:Importing libraries
2024-12-10 13:59:05,469:INFO:Copying training dataset
2024-12-10 13:59:05,470:INFO:Defining folds
2024-12-10 13:59:05,470:INFO:Declaring metric variables
2024-12-10 13:59:05,470:INFO:Importing untrained model
2024-12-10 13:59:05,470:INFO:Declaring custom model
2024-12-10 13:59:05,471:INFO:Extreme Gradient Boosting Imported successfully
2024-12-10 13:59:05,471:INFO:Cross validation set to False
2024-12-10 13:59:05,471:INFO:Fitting Model
2024-12-10 13:59:05,540:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-12-10 13:59:05,540:INFO:create_model() successfully completed......................................
2024-12-10 13:59:05,640:INFO:Initializing create_model()
2024-12-10 13:59:05,640:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E478FF9390>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:05,640:INFO:Checking exceptions
2024-12-10 13:59:05,641:INFO:Importing libraries
2024-12-10 13:59:05,641:INFO:Copying training dataset
2024-12-10 13:59:05,643:INFO:Defining folds
2024-12-10 13:59:05,643:INFO:Declaring metric variables
2024-12-10 13:59:05,643:INFO:Importing untrained model
2024-12-10 13:59:05,643:INFO:Declaring custom model
2024-12-10 13:59:05,643:INFO:Ada Boost Classifier Imported successfully
2024-12-10 13:59:05,643:INFO:Cross validation set to False
2024-12-10 13:59:05,643:INFO:Fitting Model
2024-12-10 13:59:05,646:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:59:05,683:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-12-10 13:59:05,683:INFO:create_model() successfully completed......................................
2024-12-10 13:59:05,746:INFO:Initializing create_model()
2024-12-10 13:59:05,746:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E478FF9390>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:05,746:INFO:Checking exceptions
2024-12-10 13:59:05,746:INFO:Importing libraries
2024-12-10 13:59:05,747:INFO:Copying training dataset
2024-12-10 13:59:05,748:INFO:Defining folds
2024-12-10 13:59:05,748:INFO:Declaring metric variables
2024-12-10 13:59:05,748:INFO:Importing untrained model
2024-12-10 13:59:05,748:INFO:Declaring custom model
2024-12-10 13:59:05,749:INFO:Logistic Regression Imported successfully
2024-12-10 13:59:05,749:INFO:Cross validation set to False
2024-12-10 13:59:05,749:INFO:Fitting Model
2024-12-10 13:59:05,758:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-10 13:59:05,758:INFO:create_model() successfully completed......................................
2024-12-10 13:59:05,816:INFO:Initializing create_model()
2024-12-10 13:59:05,817:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E478FF9390>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:05,817:INFO:Checking exceptions
2024-12-10 13:59:05,817:INFO:Importing libraries
2024-12-10 13:59:05,817:INFO:Copying training dataset
2024-12-10 13:59:05,819:INFO:Defining folds
2024-12-10 13:59:05,819:INFO:Declaring metric variables
2024-12-10 13:59:05,819:INFO:Importing untrained model
2024-12-10 13:59:05,819:INFO:Declaring custom model
2024-12-10 13:59:05,820:INFO:Ridge Classifier Imported successfully
2024-12-10 13:59:05,820:INFO:Cross validation set to False
2024-12-10 13:59:05,820:INFO:Fitting Model
2024-12-10 13:59:05,824:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-12-10 13:59:05,824:INFO:create_model() successfully completed......................................
2024-12-10 13:59:05,881:INFO:Initializing create_model()
2024-12-10 13:59:05,881:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E478FF9390>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:05,881:INFO:Checking exceptions
2024-12-10 13:59:05,882:INFO:Importing libraries
2024-12-10 13:59:05,882:INFO:Copying training dataset
2024-12-10 13:59:05,884:INFO:Defining folds
2024-12-10 13:59:05,884:INFO:Declaring metric variables
2024-12-10 13:59:05,884:INFO:Importing untrained model
2024-12-10 13:59:05,884:INFO:Declaring custom model
2024-12-10 13:59:05,884:INFO:Linear Discriminant Analysis Imported successfully
2024-12-10 13:59:05,885:INFO:Cross validation set to False
2024-12-10 13:59:05,885:INFO:Fitting Model
2024-12-10 13:59:05,888:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-10 13:59:05,888:INFO:create_model() successfully completed......................................
2024-12-10 13:59:05,951:INFO:Initializing create_model()
2024-12-10 13:59:05,951:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E478FF9390>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:05,951:INFO:Checking exceptions
2024-12-10 13:59:05,952:INFO:Importing libraries
2024-12-10 13:59:05,952:INFO:Copying training dataset
2024-12-10 13:59:05,954:INFO:Defining folds
2024-12-10 13:59:05,954:INFO:Declaring metric variables
2024-12-10 13:59:05,954:INFO:Importing untrained model
2024-12-10 13:59:05,954:INFO:Declaring custom model
2024-12-10 13:59:05,954:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-10 13:59:05,954:INFO:Cross validation set to False
2024-12-10 13:59:05,954:INFO:Fitting Model
2024-12-10 13:59:05,958:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-10 13:59:05,958:INFO:create_model() successfully completed......................................
2024-12-10 13:59:06,028:INFO:Initializing create_model()
2024-12-10 13:59:06,028:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E478FF9390>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:06,028:INFO:Checking exceptions
2024-12-10 13:59:06,030:INFO:Importing libraries
2024-12-10 13:59:06,030:INFO:Copying training dataset
2024-12-10 13:59:06,031:INFO:Defining folds
2024-12-10 13:59:06,031:INFO:Declaring metric variables
2024-12-10 13:59:06,031:INFO:Importing untrained model
2024-12-10 13:59:06,032:INFO:Declaring custom model
2024-12-10 13:59:06,032:INFO:Extra Trees Classifier Imported successfully
2024-12-10 13:59:06,032:INFO:Cross validation set to False
2024-12-10 13:59:06,032:INFO:Fitting Model
2024-12-10 13:59:06,088:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-12-10 13:59:06,088:INFO:create_model() successfully completed......................................
2024-12-10 13:59:06,146:INFO:Initializing create_model()
2024-12-10 13:59:06,146:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E478FF9390>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:06,146:INFO:Checking exceptions
2024-12-10 13:59:06,147:INFO:Importing libraries
2024-12-10 13:59:06,147:INFO:Copying training dataset
2024-12-10 13:59:06,149:INFO:Defining folds
2024-12-10 13:59:06,149:INFO:Declaring metric variables
2024-12-10 13:59:06,149:INFO:Importing untrained model
2024-12-10 13:59:06,149:INFO:Declaring custom model
2024-12-10 13:59:06,149:INFO:Naive Bayes Imported successfully
2024-12-10 13:59:06,149:INFO:Cross validation set to False
2024-12-10 13:59:06,149:INFO:Fitting Model
2024-12-10 13:59:06,152:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-10 13:59:06,152:INFO:create_model() successfully completed......................................
2024-12-10 13:59:06,209:INFO:Initializing create_model()
2024-12-10 13:59:06,209:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E478FF9390>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:06,209:INFO:Checking exceptions
2024-12-10 13:59:06,210:INFO:Importing libraries
2024-12-10 13:59:06,210:INFO:Copying training dataset
2024-12-10 13:59:06,211:INFO:Defining folds
2024-12-10 13:59:06,211:INFO:Declaring metric variables
2024-12-10 13:59:06,212:INFO:Importing untrained model
2024-12-10 13:59:06,212:INFO:Declaring custom model
2024-12-10 13:59:06,212:INFO:Decision Tree Classifier Imported successfully
2024-12-10 13:59:06,212:INFO:Cross validation set to False
2024-12-10 13:59:06,212:INFO:Fitting Model
2024-12-10 13:59:06,216:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-12-10 13:59:06,216:INFO:create_model() successfully completed......................................
2024-12-10 13:59:06,273:INFO:Initializing create_model()
2024-12-10 13:59:06,273:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E478FF9390>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:06,273:INFO:Checking exceptions
2024-12-10 13:59:06,274:INFO:Importing libraries
2024-12-10 13:59:06,274:INFO:Copying training dataset
2024-12-10 13:59:06,276:INFO:Defining folds
2024-12-10 13:59:06,276:INFO:Declaring metric variables
2024-12-10 13:59:06,276:INFO:Importing untrained model
2024-12-10 13:59:06,276:INFO:Declaring custom model
2024-12-10 13:59:06,276:INFO:K Neighbors Classifier Imported successfully
2024-12-10 13:59:06,276:INFO:Cross validation set to False
2024-12-10 13:59:06,277:INFO:Fitting Model
2024-12-10 13:59:06,280:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-10 13:59:06,280:INFO:create_model() successfully completed......................................
2024-12-10 13:59:06,351:INFO:Initializing create_model()
2024-12-10 13:59:06,351:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E478FF9390>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:06,352:INFO:Checking exceptions
2024-12-10 13:59:06,353:INFO:Importing libraries
2024-12-10 13:59:06,353:INFO:Copying training dataset
2024-12-10 13:59:06,354:INFO:Defining folds
2024-12-10 13:59:06,354:INFO:Declaring metric variables
2024-12-10 13:59:06,354:INFO:Importing untrained model
2024-12-10 13:59:06,354:INFO:Declaring custom model
2024-12-10 13:59:06,354:INFO:SVM - Linear Kernel Imported successfully
2024-12-10 13:59:06,355:INFO:Cross validation set to False
2024-12-10 13:59:06,355:INFO:Fitting Model
2024-12-10 13:59:06,359:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-10 13:59:06,359:INFO:create_model() successfully completed......................................
2024-12-10 13:59:06,425:INFO:_master_model_container: 15
2024-12-10 13:59:06,425:INFO:_display_container: 2
2024-12-10 13:59:06,427:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), <catboost.core.CatBoostClassifier object at 0x000001E400547AD0>, GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)]
2024-12-10 13:59:06,427:INFO:compare_models() successfully completed......................................
2024-12-10 13:59:06,432:INFO:Initializing finalize_model()
2024-12-10 13:59:06,432:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E478FF9390>, estimator=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), <catboost.core.CatBoostClassifier object at 0x000001E400547AD0>, GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)], fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-12-10 13:59:06,434:INFO:Finalizing [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), <catboost.core.CatBoostClassifier object at 0x000001E400547AD0>, GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)]
2024-12-10 13:59:06,436:INFO:Initializing create_model()
2024-12-10 13:59:06,436:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E478FF9390>, estimator=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), <catboost.core.CatBoostClassifier object at 0x000001E400547AD0>, GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)], fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:06,436:INFO:Checking exceptions
2024-12-10 13:59:16,684:INFO:PyCaret ClassificationExperiment
2024-12-10 13:59:16,684:INFO:Logging name: clf-default-name
2024-12-10 13:59:16,684:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-12-10 13:59:16,684:INFO:version 3.3.2
2024-12-10 13:59:16,684:INFO:Initializing setup()
2024-12-10 13:59:16,684:INFO:self.USI: ca28
2024-12-10 13:59:16,684:INFO:self._variable_keys: {'X', '_ml_usecase', 'data', 'exp_name_log', 'USI', 'target_param', 'exp_id', 'html_param', 'y_test', 'n_jobs_param', 'idx', 'log_plots_param', 'fold_shuffle_param', 'memory', 'pipeline', 'X_test', 'logging_param', 'fix_imbalance', '_available_plots', 'X_train', 'gpu_n_jobs_param', 'y', 'fold_generator', 'gpu_param', 'y_train', 'seed', 'fold_groups_param', 'is_multiclass'}
2024-12-10 13:59:16,684:INFO:Checking environment
2024-12-10 13:59:16,684:INFO:python_version: 3.11.10
2024-12-10 13:59:16,685:INFO:python_build: ('main', 'Oct  3 2024 07:22:26')
2024-12-10 13:59:16,685:INFO:machine: AMD64
2024-12-10 13:59:16,685:INFO:platform: Windows-10-10.0.19045-SP0
2024-12-10 13:59:16,689:INFO:Memory: svmem(total=16908595200, available=2650955776, percent=84.3, used=14257639424, free=2650955776)
2024-12-10 13:59:16,690:INFO:Physical Core: 16
2024-12-10 13:59:16,690:INFO:Logical Core: 24
2024-12-10 13:59:16,690:INFO:Checking libraries
2024-12-10 13:59:16,690:INFO:System:
2024-12-10 13:59:16,690:INFO:    python: 3.11.10 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:26) [MSC v.1929 64 bit (AMD64)]
2024-12-10 13:59:16,690:INFO:executable: c:\Users\py\.conda\envs\hw4\python.exe
2024-12-10 13:59:16,690:INFO:   machine: Windows-10-10.0.19045-SP0
2024-12-10 13:59:16,690:INFO:PyCaret required dependencies:
2024-12-10 13:59:16,690:INFO:                 pip: 24.2
2024-12-10 13:59:16,690:INFO:          setuptools: 75.1.0
2024-12-10 13:59:16,690:INFO:             pycaret: 3.3.2
2024-12-10 13:59:16,690:INFO:             IPython: 8.30.0
2024-12-10 13:59:16,690:INFO:          ipywidgets: 8.1.5
2024-12-10 13:59:16,690:INFO:                tqdm: 4.67.1
2024-12-10 13:59:16,690:INFO:               numpy: 1.26.4
2024-12-10 13:59:16,690:INFO:              pandas: 2.1.4
2024-12-10 13:59:16,691:INFO:              jinja2: 3.1.4
2024-12-10 13:59:16,691:INFO:               scipy: 1.11.4
2024-12-10 13:59:16,691:INFO:              joblib: 1.3.2
2024-12-10 13:59:16,691:INFO:             sklearn: 1.4.2
2024-12-10 13:59:16,691:INFO:                pyod: 2.0.2
2024-12-10 13:59:16,691:INFO:            imblearn: 0.12.4
2024-12-10 13:59:16,691:INFO:   category_encoders: 2.6.4
2024-12-10 13:59:16,691:INFO:            lightgbm: 4.5.0
2024-12-10 13:59:16,691:INFO:               numba: 0.60.0
2024-12-10 13:59:16,691:INFO:            requests: 2.32.3
2024-12-10 13:59:16,691:INFO:          matplotlib: 3.7.5
2024-12-10 13:59:16,691:INFO:          scikitplot: 0.3.7
2024-12-10 13:59:16,691:INFO:         yellowbrick: 1.5
2024-12-10 13:59:16,691:INFO:              plotly: 5.24.1
2024-12-10 13:59:16,691:INFO:    plotly-resampler: Not installed
2024-12-10 13:59:16,691:INFO:             kaleido: 0.2.1
2024-12-10 13:59:16,691:INFO:           schemdraw: 0.15
2024-12-10 13:59:16,691:INFO:         statsmodels: 0.14.4
2024-12-10 13:59:16,691:INFO:              sktime: 0.26.0
2024-12-10 13:59:16,691:INFO:               tbats: 1.1.3
2024-12-10 13:59:16,691:INFO:            pmdarima: 2.0.4
2024-12-10 13:59:16,691:INFO:              psutil: 6.1.0
2024-12-10 13:59:16,691:INFO:          markupsafe: 3.0.2
2024-12-10 13:59:16,691:INFO:             pickle5: Not installed
2024-12-10 13:59:16,691:INFO:         cloudpickle: 3.1.0
2024-12-10 13:59:16,691:INFO:         deprecation: 2.1.0
2024-12-10 13:59:16,691:INFO:              xxhash: 3.5.0
2024-12-10 13:59:16,692:INFO:           wurlitzer: Not installed
2024-12-10 13:59:16,692:INFO:PyCaret optional dependencies:
2024-12-10 13:59:16,692:INFO:                shap: Not installed
2024-12-10 13:59:16,692:INFO:           interpret: Not installed
2024-12-10 13:59:16,692:INFO:                umap: Not installed
2024-12-10 13:59:16,692:INFO:     ydata_profiling: Not installed
2024-12-10 13:59:16,692:INFO:  explainerdashboard: Not installed
2024-12-10 13:59:16,692:INFO:             autoviz: Not installed
2024-12-10 13:59:16,692:INFO:           fairlearn: Not installed
2024-12-10 13:59:16,692:INFO:          deepchecks: Not installed
2024-12-10 13:59:16,692:INFO:             xgboost: 2.1.3
2024-12-10 13:59:16,692:INFO:            catboost: 1.2.7
2024-12-10 13:59:16,692:INFO:              kmodes: Not installed
2024-12-10 13:59:16,692:INFO:             mlxtend: Not installed
2024-12-10 13:59:16,692:INFO:       statsforecast: Not installed
2024-12-10 13:59:16,692:INFO:        tune_sklearn: Not installed
2024-12-10 13:59:16,692:INFO:                 ray: Not installed
2024-12-10 13:59:16,692:INFO:            hyperopt: Not installed
2024-12-10 13:59:16,692:INFO:              optuna: Not installed
2024-12-10 13:59:16,692:INFO:               skopt: Not installed
2024-12-10 13:59:16,692:INFO:              mlflow: Not installed
2024-12-10 13:59:16,692:INFO:              gradio: Not installed
2024-12-10 13:59:16,692:INFO:             fastapi: Not installed
2024-12-10 13:59:16,692:INFO:             uvicorn: Not installed
2024-12-10 13:59:16,692:INFO:              m2cgen: Not installed
2024-12-10 13:59:16,692:INFO:           evidently: Not installed
2024-12-10 13:59:16,692:INFO:               fugue: Not installed
2024-12-10 13:59:16,692:INFO:           streamlit: Not installed
2024-12-10 13:59:16,692:INFO:             prophet: Not installed
2024-12-10 13:59:16,692:INFO:None
2024-12-10 13:59:16,692:INFO:Set up data.
2024-12-10 13:59:16,695:INFO:Set up folding strategy.
2024-12-10 13:59:16,695:INFO:Set up train/test split.
2024-12-10 13:59:16,697:INFO:Set up index.
2024-12-10 13:59:16,697:INFO:Assigning column types.
2024-12-10 13:59:16,699:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-10 13:59:16,719:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-10 13:59:16,719:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-10 13:59:16,733:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 13:59:16,734:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 13:59:16,755:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-10 13:59:16,755:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-10 13:59:16,767:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 13:59:16,769:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 13:59:16,769:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-10 13:59:16,790:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-10 13:59:16,802:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 13:59:16,803:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 13:59:16,824:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-10 13:59:16,837:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 13:59:16,838:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 13:59:16,838:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-12-10 13:59:16,870:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 13:59:16,871:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 13:59:16,906:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 13:59:16,907:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 13:59:16,908:INFO:Preparing preprocessing pipeline...
2024-12-10 13:59:16,909:INFO:Set up simple imputation.
2024-12-10 13:59:16,917:INFO:Finished creating preprocessing pipeline.
2024-12-10 13:59:16,918:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\py\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'SibSp',
                                             'Parch', 'Fare', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-12-10 13:59:16,918:INFO:Creating final display dataframe.
2024-12-10 13:59:16,943:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (891, 8)
4        Transformed data shape          (891, 8)
5   Transformed train set shape          (623, 8)
6    Transformed test set shape          (268, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              ca28
2024-12-10 13:59:16,986:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 13:59:16,988:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 13:59:17,022:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 13:59:17,024:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 13:59:17,025:INFO:setup() successfully completed in 0.34s...............
2024-12-10 13:59:17,025:INFO:Initializing compare_models()
2024-12-10 13:59:17,025:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E415143E50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E415143E50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-12-10 13:59:17,025:INFO:Checking exceptions
2024-12-10 13:59:17,027:INFO:Preparing display monitor
2024-12-10 13:59:17,037:INFO:Initializing Logistic Regression
2024-12-10 13:59:17,037:INFO:Total runtime is 0.0 minutes
2024-12-10 13:59:17,038:INFO:SubProcess create_model() called ==================================
2024-12-10 13:59:17,038:INFO:Initializing create_model()
2024-12-10 13:59:17,038:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E415143E50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E400397190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:17,038:INFO:Checking exceptions
2024-12-10 13:59:17,038:INFO:Importing libraries
2024-12-10 13:59:17,039:INFO:Copying training dataset
2024-12-10 13:59:17,040:INFO:Defining folds
2024-12-10 13:59:17,040:INFO:Declaring metric variables
2024-12-10 13:59:17,042:INFO:Importing untrained model
2024-12-10 13:59:17,043:INFO:Logistic Regression Imported successfully
2024-12-10 13:59:17,046:INFO:Starting cross validation
2024-12-10 13:59:17,047:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:59:17,084:INFO:Calculating mean and std
2024-12-10 13:59:17,084:INFO:Creating metrics dataframe
2024-12-10 13:59:17,085:INFO:Uploading results into container
2024-12-10 13:59:17,085:INFO:Uploading model into container now
2024-12-10 13:59:17,085:INFO:_master_model_container: 1
2024-12-10 13:59:17,085:INFO:_display_container: 2
2024-12-10 13:59:17,085:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-10 13:59:17,085:INFO:create_model() successfully completed......................................
2024-12-10 13:59:17,154:INFO:SubProcess create_model() end ==================================
2024-12-10 13:59:17,154:INFO:Creating metrics dataframe
2024-12-10 13:59:17,157:INFO:Initializing K Neighbors Classifier
2024-12-10 13:59:17,158:INFO:Total runtime is 0.0019933541615804037 minutes
2024-12-10 13:59:17,159:INFO:SubProcess create_model() called ==================================
2024-12-10 13:59:17,159:INFO:Initializing create_model()
2024-12-10 13:59:17,159:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E415143E50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E400397190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:17,159:INFO:Checking exceptions
2024-12-10 13:59:17,159:INFO:Importing libraries
2024-12-10 13:59:17,160:INFO:Copying training dataset
2024-12-10 13:59:17,161:INFO:Defining folds
2024-12-10 13:59:17,161:INFO:Declaring metric variables
2024-12-10 13:59:17,162:INFO:Importing untrained model
2024-12-10 13:59:17,164:INFO:K Neighbors Classifier Imported successfully
2024-12-10 13:59:17,166:INFO:Starting cross validation
2024-12-10 13:59:17,167:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:59:17,234:INFO:Calculating mean and std
2024-12-10 13:59:17,234:INFO:Creating metrics dataframe
2024-12-10 13:59:17,235:INFO:Uploading results into container
2024-12-10 13:59:17,235:INFO:Uploading model into container now
2024-12-10 13:59:17,235:INFO:_master_model_container: 2
2024-12-10 13:59:17,235:INFO:_display_container: 2
2024-12-10 13:59:17,235:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-10 13:59:17,235:INFO:create_model() successfully completed......................................
2024-12-10 13:59:17,292:INFO:SubProcess create_model() end ==================================
2024-12-10 13:59:17,292:INFO:Creating metrics dataframe
2024-12-10 13:59:17,295:INFO:Initializing Naive Bayes
2024-12-10 13:59:17,295:INFO:Total runtime is 0.004299489657084148 minutes
2024-12-10 13:59:17,296:INFO:SubProcess create_model() called ==================================
2024-12-10 13:59:17,297:INFO:Initializing create_model()
2024-12-10 13:59:17,297:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E415143E50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E400397190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:17,297:INFO:Checking exceptions
2024-12-10 13:59:17,297:INFO:Importing libraries
2024-12-10 13:59:17,297:INFO:Copying training dataset
2024-12-10 13:59:17,298:INFO:Defining folds
2024-12-10 13:59:17,298:INFO:Declaring metric variables
2024-12-10 13:59:17,299:INFO:Importing untrained model
2024-12-10 13:59:17,301:INFO:Naive Bayes Imported successfully
2024-12-10 13:59:17,303:INFO:Starting cross validation
2024-12-10 13:59:17,304:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:59:17,329:INFO:Calculating mean and std
2024-12-10 13:59:17,329:INFO:Creating metrics dataframe
2024-12-10 13:59:17,330:INFO:Uploading results into container
2024-12-10 13:59:17,330:INFO:Uploading model into container now
2024-12-10 13:59:17,330:INFO:_master_model_container: 3
2024-12-10 13:59:17,330:INFO:_display_container: 2
2024-12-10 13:59:17,330:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-10 13:59:17,330:INFO:create_model() successfully completed......................................
2024-12-10 13:59:17,387:INFO:SubProcess create_model() end ==================================
2024-12-10 13:59:17,387:INFO:Creating metrics dataframe
2024-12-10 13:59:17,391:INFO:Initializing Decision Tree Classifier
2024-12-10 13:59:17,391:INFO:Total runtime is 0.005894156297047933 minutes
2024-12-10 13:59:17,392:INFO:SubProcess create_model() called ==================================
2024-12-10 13:59:17,392:INFO:Initializing create_model()
2024-12-10 13:59:17,392:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E415143E50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E400397190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:17,392:INFO:Checking exceptions
2024-12-10 13:59:17,392:INFO:Importing libraries
2024-12-10 13:59:17,393:INFO:Copying training dataset
2024-12-10 13:59:17,394:INFO:Defining folds
2024-12-10 13:59:17,394:INFO:Declaring metric variables
2024-12-10 13:59:17,395:INFO:Importing untrained model
2024-12-10 13:59:17,397:INFO:Decision Tree Classifier Imported successfully
2024-12-10 13:59:17,399:INFO:Starting cross validation
2024-12-10 13:59:17,400:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:59:17,425:INFO:Calculating mean and std
2024-12-10 13:59:17,425:INFO:Creating metrics dataframe
2024-12-10 13:59:17,426:INFO:Uploading results into container
2024-12-10 13:59:17,426:INFO:Uploading model into container now
2024-12-10 13:59:17,426:INFO:_master_model_container: 4
2024-12-10 13:59:17,426:INFO:_display_container: 2
2024-12-10 13:59:17,427:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-12-10 13:59:17,427:INFO:create_model() successfully completed......................................
2024-12-10 13:59:17,483:INFO:SubProcess create_model() end ==================================
2024-12-10 13:59:17,483:INFO:Creating metrics dataframe
2024-12-10 13:59:17,487:INFO:Initializing SVM - Linear Kernel
2024-12-10 13:59:17,487:INFO:Total runtime is 0.007488822937011719 minutes
2024-12-10 13:59:17,488:INFO:SubProcess create_model() called ==================================
2024-12-10 13:59:17,488:INFO:Initializing create_model()
2024-12-10 13:59:17,488:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E415143E50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E400397190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:17,489:INFO:Checking exceptions
2024-12-10 13:59:17,489:INFO:Importing libraries
2024-12-10 13:59:17,489:INFO:Copying training dataset
2024-12-10 13:59:17,490:INFO:Defining folds
2024-12-10 13:59:17,490:INFO:Declaring metric variables
2024-12-10 13:59:17,491:INFO:Importing untrained model
2024-12-10 13:59:17,493:INFO:SVM - Linear Kernel Imported successfully
2024-12-10 13:59:17,496:INFO:Starting cross validation
2024-12-10 13:59:17,496:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:59:17,521:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 13:59:17,532:INFO:Calculating mean and std
2024-12-10 13:59:17,532:INFO:Creating metrics dataframe
2024-12-10 13:59:17,533:INFO:Uploading results into container
2024-12-10 13:59:17,533:INFO:Uploading model into container now
2024-12-10 13:59:17,533:INFO:_master_model_container: 5
2024-12-10 13:59:17,533:INFO:_display_container: 2
2024-12-10 13:59:17,534:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-10 13:59:17,534:INFO:create_model() successfully completed......................................
2024-12-10 13:59:17,600:INFO:SubProcess create_model() end ==================================
2024-12-10 13:59:17,600:INFO:Creating metrics dataframe
2024-12-10 13:59:17,604:INFO:Initializing Ridge Classifier
2024-12-10 13:59:17,604:INFO:Total runtime is 0.0094513734181722 minutes
2024-12-10 13:59:17,605:INFO:SubProcess create_model() called ==================================
2024-12-10 13:59:17,606:INFO:Initializing create_model()
2024-12-10 13:59:17,606:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E415143E50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E400397190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:17,606:INFO:Checking exceptions
2024-12-10 13:59:17,606:INFO:Importing libraries
2024-12-10 13:59:17,606:INFO:Copying training dataset
2024-12-10 13:59:17,607:INFO:Defining folds
2024-12-10 13:59:17,607:INFO:Declaring metric variables
2024-12-10 13:59:17,609:INFO:Importing untrained model
2024-12-10 13:59:17,610:INFO:Ridge Classifier Imported successfully
2024-12-10 13:59:17,613:INFO:Starting cross validation
2024-12-10 13:59:17,613:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:59:17,650:INFO:Calculating mean and std
2024-12-10 13:59:17,650:INFO:Creating metrics dataframe
2024-12-10 13:59:17,651:INFO:Uploading results into container
2024-12-10 13:59:17,651:INFO:Uploading model into container now
2024-12-10 13:59:17,651:INFO:_master_model_container: 6
2024-12-10 13:59:17,651:INFO:_display_container: 2
2024-12-10 13:59:17,652:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-12-10 13:59:17,652:INFO:create_model() successfully completed......................................
2024-12-10 13:59:17,711:INFO:SubProcess create_model() end ==================================
2024-12-10 13:59:17,711:INFO:Creating metrics dataframe
2024-12-10 13:59:17,715:INFO:Initializing Random Forest Classifier
2024-12-10 13:59:17,715:INFO:Total runtime is 0.011295207341512044 minutes
2024-12-10 13:59:17,716:INFO:SubProcess create_model() called ==================================
2024-12-10 13:59:17,717:INFO:Initializing create_model()
2024-12-10 13:59:17,717:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E415143E50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E400397190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:17,717:INFO:Checking exceptions
2024-12-10 13:59:17,717:INFO:Importing libraries
2024-12-10 13:59:17,717:INFO:Copying training dataset
2024-12-10 13:59:17,718:INFO:Defining folds
2024-12-10 13:59:17,718:INFO:Declaring metric variables
2024-12-10 13:59:17,720:INFO:Importing untrained model
2024-12-10 13:59:17,721:INFO:Random Forest Classifier Imported successfully
2024-12-10 13:59:17,724:INFO:Starting cross validation
2024-12-10 13:59:17,724:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:59:17,986:INFO:Calculating mean and std
2024-12-10 13:59:17,986:INFO:Creating metrics dataframe
2024-12-10 13:59:17,987:INFO:Uploading results into container
2024-12-10 13:59:17,987:INFO:Uploading model into container now
2024-12-10 13:59:17,987:INFO:_master_model_container: 7
2024-12-10 13:59:17,987:INFO:_display_container: 2
2024-12-10 13:59:17,987:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-12-10 13:59:17,987:INFO:create_model() successfully completed......................................
2024-12-10 13:59:18,042:INFO:SubProcess create_model() end ==================================
2024-12-10 13:59:18,042:INFO:Creating metrics dataframe
2024-12-10 13:59:18,046:INFO:Initializing Quadratic Discriminant Analysis
2024-12-10 13:59:18,046:INFO:Total runtime is 0.01681953271230062 minutes
2024-12-10 13:59:18,049:INFO:SubProcess create_model() called ==================================
2024-12-10 13:59:18,049:INFO:Initializing create_model()
2024-12-10 13:59:18,049:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E415143E50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E400397190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:18,049:INFO:Checking exceptions
2024-12-10 13:59:18,049:INFO:Importing libraries
2024-12-10 13:59:18,049:INFO:Copying training dataset
2024-12-10 13:59:18,051:INFO:Defining folds
2024-12-10 13:59:18,051:INFO:Declaring metric variables
2024-12-10 13:59:18,052:INFO:Importing untrained model
2024-12-10 13:59:18,054:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-10 13:59:18,057:INFO:Starting cross validation
2024-12-10 13:59:18,057:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:59:18,093:INFO:Calculating mean and std
2024-12-10 13:59:18,093:INFO:Creating metrics dataframe
2024-12-10 13:59:18,095:INFO:Uploading results into container
2024-12-10 13:59:18,095:INFO:Uploading model into container now
2024-12-10 13:59:18,095:INFO:_master_model_container: 8
2024-12-10 13:59:18,095:INFO:_display_container: 2
2024-12-10 13:59:18,095:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-10 13:59:18,095:INFO:create_model() successfully completed......................................
2024-12-10 13:59:18,164:INFO:SubProcess create_model() end ==================================
2024-12-10 13:59:18,164:INFO:Creating metrics dataframe
2024-12-10 13:59:18,168:INFO:Initializing Ada Boost Classifier
2024-12-10 13:59:18,168:INFO:Total runtime is 0.01883976459503174 minutes
2024-12-10 13:59:18,169:INFO:SubProcess create_model() called ==================================
2024-12-10 13:59:18,170:INFO:Initializing create_model()
2024-12-10 13:59:18,170:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E415143E50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E400397190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:18,170:INFO:Checking exceptions
2024-12-10 13:59:18,170:INFO:Importing libraries
2024-12-10 13:59:18,170:INFO:Copying training dataset
2024-12-10 13:59:18,172:INFO:Defining folds
2024-12-10 13:59:18,172:INFO:Declaring metric variables
2024-12-10 13:59:18,173:INFO:Importing untrained model
2024-12-10 13:59:18,175:INFO:Ada Boost Classifier Imported successfully
2024-12-10 13:59:18,178:INFO:Starting cross validation
2024-12-10 13:59:18,178:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:59:18,187:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:59:18,187:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:59:18,187:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:59:18,188:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:59:18,189:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:59:18,189:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:59:18,189:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:59:18,190:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:59:18,195:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:59:18,196:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 13:59:18,269:INFO:Calculating mean and std
2024-12-10 13:59:18,269:INFO:Creating metrics dataframe
2024-12-10 13:59:18,270:INFO:Uploading results into container
2024-12-10 13:59:18,270:INFO:Uploading model into container now
2024-12-10 13:59:18,270:INFO:_master_model_container: 9
2024-12-10 13:59:18,270:INFO:_display_container: 2
2024-12-10 13:59:18,270:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-12-10 13:59:18,270:INFO:create_model() successfully completed......................................
2024-12-10 13:59:18,329:INFO:SubProcess create_model() end ==================================
2024-12-10 13:59:18,330:INFO:Creating metrics dataframe
2024-12-10 13:59:18,334:INFO:Initializing Gradient Boosting Classifier
2024-12-10 13:59:18,334:INFO:Total runtime is 0.021614030996958418 minutes
2024-12-10 13:59:18,335:INFO:SubProcess create_model() called ==================================
2024-12-10 13:59:18,335:INFO:Initializing create_model()
2024-12-10 13:59:18,336:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E415143E50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E400397190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:18,336:INFO:Checking exceptions
2024-12-10 13:59:18,336:INFO:Importing libraries
2024-12-10 13:59:18,336:INFO:Copying training dataset
2024-12-10 13:59:18,337:INFO:Defining folds
2024-12-10 13:59:18,338:INFO:Declaring metric variables
2024-12-10 13:59:18,339:INFO:Importing untrained model
2024-12-10 13:59:18,341:INFO:Gradient Boosting Classifier Imported successfully
2024-12-10 13:59:18,344:INFO:Starting cross validation
2024-12-10 13:59:18,345:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:59:18,458:INFO:Calculating mean and std
2024-12-10 13:59:18,458:INFO:Creating metrics dataframe
2024-12-10 13:59:18,459:INFO:Uploading results into container
2024-12-10 13:59:18,459:INFO:Uploading model into container now
2024-12-10 13:59:18,460:INFO:_master_model_container: 10
2024-12-10 13:59:18,460:INFO:_display_container: 2
2024-12-10 13:59:18,460:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-10 13:59:18,460:INFO:create_model() successfully completed......................................
2024-12-10 13:59:18,517:INFO:SubProcess create_model() end ==================================
2024-12-10 13:59:18,518:INFO:Creating metrics dataframe
2024-12-10 13:59:18,522:INFO:Initializing Linear Discriminant Analysis
2024-12-10 13:59:18,522:INFO:Total runtime is 0.02473782300949097 minutes
2024-12-10 13:59:18,524:INFO:SubProcess create_model() called ==================================
2024-12-10 13:59:18,524:INFO:Initializing create_model()
2024-12-10 13:59:18,524:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E415143E50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E400397190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:18,524:INFO:Checking exceptions
2024-12-10 13:59:18,524:INFO:Importing libraries
2024-12-10 13:59:18,524:INFO:Copying training dataset
2024-12-10 13:59:18,526:INFO:Defining folds
2024-12-10 13:59:18,526:INFO:Declaring metric variables
2024-12-10 13:59:18,527:INFO:Importing untrained model
2024-12-10 13:59:18,529:INFO:Linear Discriminant Analysis Imported successfully
2024-12-10 13:59:18,531:INFO:Starting cross validation
2024-12-10 13:59:18,532:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:59:18,568:INFO:Calculating mean and std
2024-12-10 13:59:18,568:INFO:Creating metrics dataframe
2024-12-10 13:59:18,569:INFO:Uploading results into container
2024-12-10 13:59:18,570:INFO:Uploading model into container now
2024-12-10 13:59:18,570:INFO:_master_model_container: 11
2024-12-10 13:59:18,570:INFO:_display_container: 2
2024-12-10 13:59:18,570:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-10 13:59:18,570:INFO:create_model() successfully completed......................................
2024-12-10 13:59:18,627:INFO:SubProcess create_model() end ==================================
2024-12-10 13:59:18,627:INFO:Creating metrics dataframe
2024-12-10 13:59:18,632:INFO:Initializing Extra Trees Classifier
2024-12-10 13:59:18,632:INFO:Total runtime is 0.02658277750015259 minutes
2024-12-10 13:59:18,634:INFO:SubProcess create_model() called ==================================
2024-12-10 13:59:18,634:INFO:Initializing create_model()
2024-12-10 13:59:18,634:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E415143E50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E400397190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:18,634:INFO:Checking exceptions
2024-12-10 13:59:18,634:INFO:Importing libraries
2024-12-10 13:59:18,634:INFO:Copying training dataset
2024-12-10 13:59:18,636:INFO:Defining folds
2024-12-10 13:59:18,636:INFO:Declaring metric variables
2024-12-10 13:59:18,637:INFO:Importing untrained model
2024-12-10 13:59:18,638:INFO:Extra Trees Classifier Imported successfully
2024-12-10 13:59:18,641:INFO:Starting cross validation
2024-12-10 13:59:18,642:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:59:18,827:INFO:Calculating mean and std
2024-12-10 13:59:18,827:INFO:Creating metrics dataframe
2024-12-10 13:59:18,828:INFO:Uploading results into container
2024-12-10 13:59:18,829:INFO:Uploading model into container now
2024-12-10 13:59:18,829:INFO:_master_model_container: 12
2024-12-10 13:59:18,829:INFO:_display_container: 2
2024-12-10 13:59:18,829:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-12-10 13:59:18,829:INFO:create_model() successfully completed......................................
2024-12-10 13:59:18,886:INFO:SubProcess create_model() end ==================================
2024-12-10 13:59:18,886:INFO:Creating metrics dataframe
2024-12-10 13:59:18,891:INFO:Initializing Extreme Gradient Boosting
2024-12-10 13:59:18,891:INFO:Total runtime is 0.030891466140747073 minutes
2024-12-10 13:59:18,893:INFO:SubProcess create_model() called ==================================
2024-12-10 13:59:18,893:INFO:Initializing create_model()
2024-12-10 13:59:18,893:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E415143E50>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E400397190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:18,893:INFO:Checking exceptions
2024-12-10 13:59:18,893:INFO:Importing libraries
2024-12-10 13:59:18,893:INFO:Copying training dataset
2024-12-10 13:59:18,895:INFO:Defining folds
2024-12-10 13:59:18,895:INFO:Declaring metric variables
2024-12-10 13:59:18,896:INFO:Importing untrained model
2024-12-10 13:59:18,897:INFO:Extreme Gradient Boosting Imported successfully
2024-12-10 13:59:18,900:INFO:Starting cross validation
2024-12-10 13:59:18,900:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:59:18,971:INFO:Calculating mean and std
2024-12-10 13:59:18,971:INFO:Creating metrics dataframe
2024-12-10 13:59:18,972:INFO:Uploading results into container
2024-12-10 13:59:18,973:INFO:Uploading model into container now
2024-12-10 13:59:18,973:INFO:_master_model_container: 13
2024-12-10 13:59:18,973:INFO:_display_container: 2
2024-12-10 13:59:18,973:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-12-10 13:59:18,974:INFO:create_model() successfully completed......................................
2024-12-10 13:59:19,030:INFO:SubProcess create_model() end ==================================
2024-12-10 13:59:19,030:INFO:Creating metrics dataframe
2024-12-10 13:59:19,035:INFO:Initializing Light Gradient Boosting Machine
2024-12-10 13:59:19,035:INFO:Total runtime is 0.03330113490422567 minutes
2024-12-10 13:59:19,037:INFO:SubProcess create_model() called ==================================
2024-12-10 13:59:19,037:INFO:Initializing create_model()
2024-12-10 13:59:19,037:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E415143E50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E400397190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:19,037:INFO:Checking exceptions
2024-12-10 13:59:19,037:INFO:Importing libraries
2024-12-10 13:59:19,037:INFO:Copying training dataset
2024-12-10 13:59:19,038:INFO:Defining folds
2024-12-10 13:59:19,038:INFO:Declaring metric variables
2024-12-10 13:59:19,040:INFO:Importing untrained model
2024-12-10 13:59:19,041:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-10 13:59:19,044:INFO:Starting cross validation
2024-12-10 13:59:19,044:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:59:19,805:INFO:Calculating mean and std
2024-12-10 13:59:19,806:INFO:Creating metrics dataframe
2024-12-10 13:59:19,807:INFO:Uploading results into container
2024-12-10 13:59:19,808:INFO:Uploading model into container now
2024-12-10 13:59:19,808:INFO:_master_model_container: 14
2024-12-10 13:59:19,808:INFO:_display_container: 2
2024-12-10 13:59:19,808:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-10 13:59:19,808:INFO:create_model() successfully completed......................................
2024-12-10 13:59:19,872:INFO:SubProcess create_model() end ==================================
2024-12-10 13:59:19,872:INFO:Creating metrics dataframe
2024-12-10 13:59:19,878:INFO:Initializing CatBoost Classifier
2024-12-10 13:59:19,878:INFO:Total runtime is 0.04733755985895793 minutes
2024-12-10 13:59:19,880:INFO:SubProcess create_model() called ==================================
2024-12-10 13:59:19,880:INFO:Initializing create_model()
2024-12-10 13:59:19,880:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E415143E50>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E400397190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:19,880:INFO:Checking exceptions
2024-12-10 13:59:19,881:INFO:Importing libraries
2024-12-10 13:59:19,881:INFO:Copying training dataset
2024-12-10 13:59:19,882:INFO:Defining folds
2024-12-10 13:59:19,883:INFO:Declaring metric variables
2024-12-10 13:59:19,884:INFO:Importing untrained model
2024-12-10 13:59:19,886:INFO:CatBoost Classifier Imported successfully
2024-12-10 13:59:19,889:INFO:Starting cross validation
2024-12-10 13:59:19,890:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:59:21,768:INFO:Calculating mean and std
2024-12-10 13:59:21,768:INFO:Creating metrics dataframe
2024-12-10 13:59:21,769:INFO:Uploading results into container
2024-12-10 13:59:21,770:INFO:Uploading model into container now
2024-12-10 13:59:21,770:INFO:_master_model_container: 15
2024-12-10 13:59:21,770:INFO:_display_container: 2
2024-12-10 13:59:21,770:INFO:<catboost.core.CatBoostClassifier object at 0x000001E400584B50>
2024-12-10 13:59:21,770:INFO:create_model() successfully completed......................................
2024-12-10 13:59:21,847:INFO:SubProcess create_model() end ==================================
2024-12-10 13:59:21,847:INFO:Creating metrics dataframe
2024-12-10 13:59:21,851:INFO:Initializing Dummy Classifier
2024-12-10 13:59:21,852:INFO:Total runtime is 0.08025322357813516 minutes
2024-12-10 13:59:21,853:INFO:SubProcess create_model() called ==================================
2024-12-10 13:59:21,854:INFO:Initializing create_model()
2024-12-10 13:59:21,854:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E415143E50>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E400397190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:21,854:INFO:Checking exceptions
2024-12-10 13:59:21,854:INFO:Importing libraries
2024-12-10 13:59:21,854:INFO:Copying training dataset
2024-12-10 13:59:21,856:INFO:Defining folds
2024-12-10 13:59:21,856:INFO:Declaring metric variables
2024-12-10 13:59:21,858:INFO:Importing untrained model
2024-12-10 13:59:21,859:INFO:Dummy Classifier Imported successfully
2024-12-10 13:59:21,862:INFO:Starting cross validation
2024-12-10 13:59:21,863:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 13:59:21,878:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 13:59:21,883:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 13:59:21,883:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 13:59:21,884:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 13:59:21,885:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 13:59:21,886:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 13:59:21,886:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 13:59:21,887:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 13:59:21,887:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 13:59:21,888:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 13:59:21,899:INFO:Calculating mean and std
2024-12-10 13:59:21,899:INFO:Creating metrics dataframe
2024-12-10 13:59:21,900:INFO:Uploading results into container
2024-12-10 13:59:21,901:INFO:Uploading model into container now
2024-12-10 13:59:21,901:INFO:_master_model_container: 16
2024-12-10 13:59:21,901:INFO:_display_container: 2
2024-12-10 13:59:21,901:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-12-10 13:59:21,901:INFO:create_model() successfully completed......................................
2024-12-10 13:59:21,966:INFO:SubProcess create_model() end ==================================
2024-12-10 13:59:21,966:INFO:Creating metrics dataframe
2024-12-10 13:59:21,971:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-12-10 13:59:21,975:INFO:Initializing create_model()
2024-12-10 13:59:21,975:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E415143E50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:21,975:INFO:Checking exceptions
2024-12-10 13:59:21,976:INFO:Importing libraries
2024-12-10 13:59:21,976:INFO:Copying training dataset
2024-12-10 13:59:21,978:INFO:Defining folds
2024-12-10 13:59:21,978:INFO:Declaring metric variables
2024-12-10 13:59:21,978:INFO:Importing untrained model
2024-12-10 13:59:21,978:INFO:Declaring custom model
2024-12-10 13:59:21,978:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-10 13:59:21,978:INFO:Cross validation set to False
2024-12-10 13:59:21,978:INFO:Fitting Model
2024-12-10 13:59:21,984:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-10 13:59:21,985:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000224 seconds.
2024-12-10 13:59:21,985:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-10 13:59:21,985:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-10 13:59:21,985:INFO:[LightGBM] [Info] Total Bins 188
2024-12-10 13:59:21,985:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 7
2024-12-10 13:59:21,985:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-10 13:59:21,985:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-10 13:59:21,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:21,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:21,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:21,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:21,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,070:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-10 13:59:22,070:INFO:create_model() successfully completed......................................
2024-12-10 13:59:22,149:INFO:_master_model_container: 16
2024-12-10 13:59:22,149:INFO:_display_container: 2
2024-12-10 13:59:22,150:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-10 13:59:22,150:INFO:compare_models() successfully completed......................................
2024-12-10 13:59:22,154:INFO:Initializing finalize_model()
2024-12-10 13:59:22,154:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E415143E50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-12-10 13:59:22,154:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-10 13:59:22,155:INFO:Initializing create_model()
2024-12-10 13:59:22,156:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E415143E50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 13:59:22,156:INFO:Checking exceptions
2024-12-10 13:59:22,157:INFO:Importing libraries
2024-12-10 13:59:22,157:INFO:Copying training dataset
2024-12-10 13:59:22,157:INFO:Defining folds
2024-12-10 13:59:22,157:INFO:Declaring metric variables
2024-12-10 13:59:22,157:INFO:Importing untrained model
2024-12-10 13:59:22,157:INFO:Declaring custom model
2024-12-10 13:59:22,158:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-10 13:59:22,158:INFO:Cross validation set to False
2024-12-10 13:59:22,158:INFO:Fitting Model
2024-12-10 13:59:22,162:INFO:[LightGBM] [Info] Number of positive: 342, number of negative: 549
2024-12-10 13:59:22,163:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000117 seconds.
2024-12-10 13:59:22,163:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-10 13:59:22,163:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-10 13:59:22,163:INFO:[LightGBM] [Info] Total Bins 221
2024-12-10 13:59:22,163:INFO:[LightGBM] [Info] Number of data points in the train set: 891, number of used features: 7
2024-12-10 13:59:22,163:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383838 -> initscore=-0.473288
2024-12-10 13:59:22,163:INFO:[LightGBM] [Info] Start training from score -0.473288
2024-12-10 13:59:22,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 13:59:22,235:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'SibSp',
                                             'Parch', 'Fare', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=N...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-12-10 13:59:22,235:INFO:create_model() successfully completed......................................
2024-12-10 13:59:22,302:INFO:_master_model_container: 16
2024-12-10 13:59:22,303:INFO:_display_container: 2
2024-12-10 13:59:22,305:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'SibSp',
                                             'Parch', 'Fare', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=N...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-12-10 13:59:22,306:INFO:finalize_model() successfully completed......................................
2024-12-10 13:59:22,376:INFO:Initializing predict_model()
2024-12-10 13:59:22,376:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E415143E50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'SibSp',
                                             'Parch', 'Fare', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=N...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E400408360>)
2024-12-10 13:59:22,377:INFO:Checking exceptions
2024-12-10 13:59:22,377:INFO:Preloading libraries
2024-12-10 13:59:22,378:INFO:Set up data.
2024-12-10 13:59:22,379:INFO:Set up index.
2024-12-10 14:00:51,944:INFO:PyCaret ClassificationExperiment
2024-12-10 14:00:51,944:INFO:Logging name: clf-default-name
2024-12-10 14:00:51,944:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-12-10 14:00:51,944:INFO:version 3.3.2
2024-12-10 14:00:51,944:INFO:Initializing setup()
2024-12-10 14:00:51,944:INFO:self.USI: e5f5
2024-12-10 14:00:51,944:INFO:self._variable_keys: {'X', '_ml_usecase', 'data', 'exp_name_log', 'USI', 'target_param', 'exp_id', 'html_param', 'y_test', 'n_jobs_param', 'idx', 'log_plots_param', 'fold_shuffle_param', 'memory', 'pipeline', 'X_test', 'logging_param', 'fix_imbalance', '_available_plots', 'X_train', 'gpu_n_jobs_param', 'y', 'fold_generator', 'gpu_param', 'y_train', 'seed', 'fold_groups_param', 'is_multiclass'}
2024-12-10 14:00:51,944:INFO:Checking environment
2024-12-10 14:00:51,944:INFO:python_version: 3.11.10
2024-12-10 14:00:51,944:INFO:python_build: ('main', 'Oct  3 2024 07:22:26')
2024-12-10 14:00:51,944:INFO:machine: AMD64
2024-12-10 14:00:51,944:INFO:platform: Windows-10-10.0.19045-SP0
2024-12-10 14:00:51,947:INFO:Memory: svmem(total=16908595200, available=2402709504, percent=85.8, used=14505885696, free=2402709504)
2024-12-10 14:00:51,947:INFO:Physical Core: 16
2024-12-10 14:00:51,947:INFO:Logical Core: 24
2024-12-10 14:00:51,947:INFO:Checking libraries
2024-12-10 14:00:51,947:INFO:System:
2024-12-10 14:00:51,947:INFO:    python: 3.11.10 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:26) [MSC v.1929 64 bit (AMD64)]
2024-12-10 14:00:51,947:INFO:executable: c:\Users\py\.conda\envs\hw4\python.exe
2024-12-10 14:00:51,947:INFO:   machine: Windows-10-10.0.19045-SP0
2024-12-10 14:00:51,947:INFO:PyCaret required dependencies:
2024-12-10 14:00:51,947:INFO:                 pip: 24.2
2024-12-10 14:00:51,947:INFO:          setuptools: 75.1.0
2024-12-10 14:00:51,947:INFO:             pycaret: 3.3.2
2024-12-10 14:00:51,947:INFO:             IPython: 8.30.0
2024-12-10 14:00:51,947:INFO:          ipywidgets: 8.1.5
2024-12-10 14:00:51,947:INFO:                tqdm: 4.67.1
2024-12-10 14:00:51,947:INFO:               numpy: 1.26.4
2024-12-10 14:00:51,947:INFO:              pandas: 2.1.4
2024-12-10 14:00:51,947:INFO:              jinja2: 3.1.4
2024-12-10 14:00:51,947:INFO:               scipy: 1.11.4
2024-12-10 14:00:51,947:INFO:              joblib: 1.3.2
2024-12-10 14:00:51,947:INFO:             sklearn: 1.4.2
2024-12-10 14:00:51,947:INFO:                pyod: 2.0.2
2024-12-10 14:00:51,947:INFO:            imblearn: 0.12.4
2024-12-10 14:00:51,947:INFO:   category_encoders: 2.6.4
2024-12-10 14:00:51,947:INFO:            lightgbm: 4.5.0
2024-12-10 14:00:51,947:INFO:               numba: 0.60.0
2024-12-10 14:00:51,947:INFO:            requests: 2.32.3
2024-12-10 14:00:51,947:INFO:          matplotlib: 3.7.5
2024-12-10 14:00:51,947:INFO:          scikitplot: 0.3.7
2024-12-10 14:00:51,947:INFO:         yellowbrick: 1.5
2024-12-10 14:00:51,947:INFO:              plotly: 5.24.1
2024-12-10 14:00:51,947:INFO:    plotly-resampler: Not installed
2024-12-10 14:00:51,947:INFO:             kaleido: 0.2.1
2024-12-10 14:00:51,947:INFO:           schemdraw: 0.15
2024-12-10 14:00:51,947:INFO:         statsmodels: 0.14.4
2024-12-10 14:00:51,947:INFO:              sktime: 0.26.0
2024-12-10 14:00:51,948:INFO:               tbats: 1.1.3
2024-12-10 14:00:51,948:INFO:            pmdarima: 2.0.4
2024-12-10 14:00:51,948:INFO:              psutil: 6.1.0
2024-12-10 14:00:51,948:INFO:          markupsafe: 3.0.2
2024-12-10 14:00:51,948:INFO:             pickle5: Not installed
2024-12-10 14:00:51,948:INFO:         cloudpickle: 3.1.0
2024-12-10 14:00:51,948:INFO:         deprecation: 2.1.0
2024-12-10 14:00:51,948:INFO:              xxhash: 3.5.0
2024-12-10 14:00:51,948:INFO:           wurlitzer: Not installed
2024-12-10 14:00:51,948:INFO:PyCaret optional dependencies:
2024-12-10 14:00:51,948:INFO:                shap: Not installed
2024-12-10 14:00:51,948:INFO:           interpret: Not installed
2024-12-10 14:00:51,948:INFO:                umap: Not installed
2024-12-10 14:00:51,948:INFO:     ydata_profiling: Not installed
2024-12-10 14:00:51,948:INFO:  explainerdashboard: Not installed
2024-12-10 14:00:51,948:INFO:             autoviz: Not installed
2024-12-10 14:00:51,948:INFO:           fairlearn: Not installed
2024-12-10 14:00:51,948:INFO:          deepchecks: Not installed
2024-12-10 14:00:51,948:INFO:             xgboost: 2.1.3
2024-12-10 14:00:51,948:INFO:            catboost: 1.2.7
2024-12-10 14:00:51,948:INFO:              kmodes: Not installed
2024-12-10 14:00:51,948:INFO:             mlxtend: Not installed
2024-12-10 14:00:51,948:INFO:       statsforecast: Not installed
2024-12-10 14:00:51,948:INFO:        tune_sklearn: Not installed
2024-12-10 14:00:51,948:INFO:                 ray: Not installed
2024-12-10 14:00:51,948:INFO:            hyperopt: Not installed
2024-12-10 14:00:51,948:INFO:              optuna: Not installed
2024-12-10 14:00:51,948:INFO:               skopt: Not installed
2024-12-10 14:00:51,948:INFO:              mlflow: Not installed
2024-12-10 14:00:51,948:INFO:              gradio: Not installed
2024-12-10 14:00:51,948:INFO:             fastapi: Not installed
2024-12-10 14:00:51,948:INFO:             uvicorn: Not installed
2024-12-10 14:00:51,948:INFO:              m2cgen: Not installed
2024-12-10 14:00:51,948:INFO:           evidently: Not installed
2024-12-10 14:00:51,948:INFO:               fugue: Not installed
2024-12-10 14:00:51,948:INFO:           streamlit: Not installed
2024-12-10 14:00:51,948:INFO:             prophet: Not installed
2024-12-10 14:00:51,948:INFO:None
2024-12-10 14:00:51,948:INFO:Set up data.
2024-12-10 14:00:51,950:INFO:Set up folding strategy.
2024-12-10 14:00:51,950:INFO:Set up train/test split.
2024-12-10 14:00:51,952:INFO:Set up index.
2024-12-10 14:00:51,952:INFO:Assigning column types.
2024-12-10 14:00:51,953:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-10 14:00:51,974:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-10 14:00:51,974:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-10 14:00:51,987:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 14:00:51,988:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 14:00:52,009:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-10 14:00:52,010:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-10 14:00:52,022:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 14:00:52,024:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 14:00:52,024:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-10 14:00:52,044:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-10 14:00:52,057:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 14:00:52,058:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 14:00:52,079:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-10 14:00:52,091:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 14:00:52,093:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 14:00:52,093:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-12-10 14:00:52,126:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 14:00:52,127:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 14:00:52,159:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 14:00:52,161:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 14:00:52,161:INFO:Preparing preprocessing pipeline...
2024-12-10 14:00:52,162:INFO:Set up simple imputation.
2024-12-10 14:00:52,170:INFO:Finished creating preprocessing pipeline.
2024-12-10 14:00:52,172:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\py\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'SibSp',
                                             'Parch', 'Fare', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-12-10 14:00:52,172:INFO:Creating final display dataframe.
2024-12-10 14:00:52,199:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (891, 8)
4        Transformed data shape          (891, 8)
5   Transformed train set shape          (623, 8)
6    Transformed test set shape          (268, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              e5f5
2024-12-10 14:00:52,235:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 14:00:52,237:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 14:00:52,270:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 14:00:52,271:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 14:00:52,272:INFO:setup() successfully completed in 0.33s...............
2024-12-10 14:00:52,273:INFO:Initializing compare_models()
2024-12-10 14:00:52,273:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4003B1AD0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E4003B1AD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-12-10 14:00:52,273:INFO:Checking exceptions
2024-12-10 14:00:52,274:INFO:Preparing display monitor
2024-12-10 14:00:52,284:INFO:Initializing Logistic Regression
2024-12-10 14:00:52,284:INFO:Total runtime is 0.0 minutes
2024-12-10 14:00:52,285:INFO:SubProcess create_model() called ==================================
2024-12-10 14:00:52,285:INFO:Initializing create_model()
2024-12-10 14:00:52,285:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4003B1AD0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E478BB82D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:00:52,285:INFO:Checking exceptions
2024-12-10 14:00:52,286:INFO:Importing libraries
2024-12-10 14:00:52,286:INFO:Copying training dataset
2024-12-10 14:00:52,287:INFO:Defining folds
2024-12-10 14:00:52,287:INFO:Declaring metric variables
2024-12-10 14:00:52,288:INFO:Importing untrained model
2024-12-10 14:00:52,290:INFO:Logistic Regression Imported successfully
2024-12-10 14:00:52,293:INFO:Starting cross validation
2024-12-10 14:00:52,294:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:00:52,343:INFO:Calculating mean and std
2024-12-10 14:00:52,343:INFO:Creating metrics dataframe
2024-12-10 14:00:52,345:INFO:Uploading results into container
2024-12-10 14:00:52,346:INFO:Uploading model into container now
2024-12-10 14:00:52,347:INFO:_master_model_container: 1
2024-12-10 14:00:52,347:INFO:_display_container: 2
2024-12-10 14:00:52,347:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-10 14:00:52,347:INFO:create_model() successfully completed......................................
2024-12-10 14:00:52,417:INFO:SubProcess create_model() end ==================================
2024-12-10 14:00:52,417:INFO:Creating metrics dataframe
2024-12-10 14:00:52,420:INFO:Initializing K Neighbors Classifier
2024-12-10 14:00:52,420:INFO:Total runtime is 0.0022757291793823243 minutes
2024-12-10 14:00:52,422:INFO:SubProcess create_model() called ==================================
2024-12-10 14:00:52,422:INFO:Initializing create_model()
2024-12-10 14:00:52,422:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4003B1AD0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E478BB82D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:00:52,422:INFO:Checking exceptions
2024-12-10 14:00:52,422:INFO:Importing libraries
2024-12-10 14:00:52,422:INFO:Copying training dataset
2024-12-10 14:00:52,424:INFO:Defining folds
2024-12-10 14:00:52,424:INFO:Declaring metric variables
2024-12-10 14:00:52,425:INFO:Importing untrained model
2024-12-10 14:00:52,427:INFO:K Neighbors Classifier Imported successfully
2024-12-10 14:00:52,429:INFO:Starting cross validation
2024-12-10 14:00:52,430:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:00:52,498:INFO:Calculating mean and std
2024-12-10 14:00:52,498:INFO:Creating metrics dataframe
2024-12-10 14:00:52,499:INFO:Uploading results into container
2024-12-10 14:00:52,499:INFO:Uploading model into container now
2024-12-10 14:00:52,499:INFO:_master_model_container: 2
2024-12-10 14:00:52,499:INFO:_display_container: 2
2024-12-10 14:00:52,499:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-10 14:00:52,500:INFO:create_model() successfully completed......................................
2024-12-10 14:00:52,572:INFO:SubProcess create_model() end ==================================
2024-12-10 14:00:52,572:INFO:Creating metrics dataframe
2024-12-10 14:00:52,576:INFO:Initializing Naive Bayes
2024-12-10 14:00:52,576:INFO:Total runtime is 0.004866099357604981 minutes
2024-12-10 14:00:52,577:INFO:SubProcess create_model() called ==================================
2024-12-10 14:00:52,578:INFO:Initializing create_model()
2024-12-10 14:00:52,578:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4003B1AD0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E478BB82D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:00:52,578:INFO:Checking exceptions
2024-12-10 14:00:52,578:INFO:Importing libraries
2024-12-10 14:00:52,578:INFO:Copying training dataset
2024-12-10 14:00:52,579:INFO:Defining folds
2024-12-10 14:00:52,579:INFO:Declaring metric variables
2024-12-10 14:00:52,581:INFO:Importing untrained model
2024-12-10 14:00:52,582:INFO:Naive Bayes Imported successfully
2024-12-10 14:00:52,585:INFO:Starting cross validation
2024-12-10 14:00:52,585:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:00:52,624:INFO:Calculating mean and std
2024-12-10 14:00:52,624:INFO:Creating metrics dataframe
2024-12-10 14:00:52,625:INFO:Uploading results into container
2024-12-10 14:00:52,625:INFO:Uploading model into container now
2024-12-10 14:00:52,626:INFO:_master_model_container: 3
2024-12-10 14:00:52,626:INFO:_display_container: 2
2024-12-10 14:00:52,626:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-10 14:00:52,626:INFO:create_model() successfully completed......................................
2024-12-10 14:00:52,685:INFO:SubProcess create_model() end ==================================
2024-12-10 14:00:52,686:INFO:Creating metrics dataframe
2024-12-10 14:00:52,689:INFO:Initializing Decision Tree Classifier
2024-12-10 14:00:52,689:INFO:Total runtime is 0.006744587421417237 minutes
2024-12-10 14:00:52,691:INFO:SubProcess create_model() called ==================================
2024-12-10 14:00:52,691:INFO:Initializing create_model()
2024-12-10 14:00:52,691:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4003B1AD0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E478BB82D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:00:52,691:INFO:Checking exceptions
2024-12-10 14:00:52,692:INFO:Importing libraries
2024-12-10 14:00:52,692:INFO:Copying training dataset
2024-12-10 14:00:52,693:INFO:Defining folds
2024-12-10 14:00:52,693:INFO:Declaring metric variables
2024-12-10 14:00:52,695:INFO:Importing untrained model
2024-12-10 14:00:52,696:INFO:Decision Tree Classifier Imported successfully
2024-12-10 14:00:52,699:INFO:Starting cross validation
2024-12-10 14:00:52,699:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:00:52,735:INFO:Calculating mean and std
2024-12-10 14:00:52,735:INFO:Creating metrics dataframe
2024-12-10 14:00:52,736:INFO:Uploading results into container
2024-12-10 14:00:52,736:INFO:Uploading model into container now
2024-12-10 14:00:52,736:INFO:_master_model_container: 4
2024-12-10 14:00:52,736:INFO:_display_container: 2
2024-12-10 14:00:52,736:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-12-10 14:00:52,736:INFO:create_model() successfully completed......................................
2024-12-10 14:00:52,799:INFO:SubProcess create_model() end ==================================
2024-12-10 14:00:52,799:INFO:Creating metrics dataframe
2024-12-10 14:00:52,803:INFO:Initializing SVM - Linear Kernel
2024-12-10 14:00:52,803:INFO:Total runtime is 0.008657220999399822 minutes
2024-12-10 14:00:52,805:INFO:SubProcess create_model() called ==================================
2024-12-10 14:00:52,805:INFO:Initializing create_model()
2024-12-10 14:00:52,805:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4003B1AD0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E478BB82D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:00:52,805:INFO:Checking exceptions
2024-12-10 14:00:52,805:INFO:Importing libraries
2024-12-10 14:00:52,805:INFO:Copying training dataset
2024-12-10 14:00:52,807:INFO:Defining folds
2024-12-10 14:00:52,807:INFO:Declaring metric variables
2024-12-10 14:00:52,808:INFO:Importing untrained model
2024-12-10 14:00:52,810:INFO:SVM - Linear Kernel Imported successfully
2024-12-10 14:00:52,813:INFO:Starting cross validation
2024-12-10 14:00:52,813:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:00:52,835:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 14:00:52,850:INFO:Calculating mean and std
2024-12-10 14:00:52,850:INFO:Creating metrics dataframe
2024-12-10 14:00:52,851:INFO:Uploading results into container
2024-12-10 14:00:52,851:INFO:Uploading model into container now
2024-12-10 14:00:52,851:INFO:_master_model_container: 5
2024-12-10 14:00:52,851:INFO:_display_container: 2
2024-12-10 14:00:52,852:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-10 14:00:52,852:INFO:create_model() successfully completed......................................
2024-12-10 14:00:52,908:INFO:SubProcess create_model() end ==================================
2024-12-10 14:00:52,908:INFO:Creating metrics dataframe
2024-12-10 14:00:52,912:INFO:Initializing Ridge Classifier
2024-12-10 14:00:52,912:INFO:Total runtime is 0.010465669631958009 minutes
2024-12-10 14:00:52,914:INFO:SubProcess create_model() called ==================================
2024-12-10 14:00:52,914:INFO:Initializing create_model()
2024-12-10 14:00:52,914:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4003B1AD0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E478BB82D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:00:52,914:INFO:Checking exceptions
2024-12-10 14:00:52,914:INFO:Importing libraries
2024-12-10 14:00:52,914:INFO:Copying training dataset
2024-12-10 14:00:52,916:INFO:Defining folds
2024-12-10 14:00:52,916:INFO:Declaring metric variables
2024-12-10 14:00:52,917:INFO:Importing untrained model
2024-12-10 14:00:52,918:INFO:Ridge Classifier Imported successfully
2024-12-10 14:00:52,921:INFO:Starting cross validation
2024-12-10 14:00:52,921:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:00:52,991:INFO:Calculating mean and std
2024-12-10 14:00:52,991:INFO:Creating metrics dataframe
2024-12-10 14:00:52,992:INFO:Uploading results into container
2024-12-10 14:00:52,992:INFO:Uploading model into container now
2024-12-10 14:00:52,993:INFO:_master_model_container: 6
2024-12-10 14:00:52,993:INFO:_display_container: 2
2024-12-10 14:00:52,993:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-12-10 14:00:52,993:INFO:create_model() successfully completed......................................
2024-12-10 14:00:53,060:INFO:SubProcess create_model() end ==================================
2024-12-10 14:00:53,060:INFO:Creating metrics dataframe
2024-12-10 14:00:53,064:INFO:Initializing Random Forest Classifier
2024-12-10 14:00:53,064:INFO:Total runtime is 0.013007084528605144 minutes
2024-12-10 14:00:53,066:INFO:SubProcess create_model() called ==================================
2024-12-10 14:00:53,066:INFO:Initializing create_model()
2024-12-10 14:00:53,066:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4003B1AD0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E478BB82D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:00:53,066:INFO:Checking exceptions
2024-12-10 14:00:53,066:INFO:Importing libraries
2024-12-10 14:00:53,066:INFO:Copying training dataset
2024-12-10 14:00:53,067:INFO:Defining folds
2024-12-10 14:00:53,067:INFO:Declaring metric variables
2024-12-10 14:00:53,069:INFO:Importing untrained model
2024-12-10 14:00:53,070:INFO:Random Forest Classifier Imported successfully
2024-12-10 14:00:53,073:INFO:Starting cross validation
2024-12-10 14:00:53,073:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:00:53,333:INFO:Calculating mean and std
2024-12-10 14:00:53,333:INFO:Creating metrics dataframe
2024-12-10 14:00:53,334:INFO:Uploading results into container
2024-12-10 14:00:53,335:INFO:Uploading model into container now
2024-12-10 14:00:53,335:INFO:_master_model_container: 7
2024-12-10 14:00:53,335:INFO:_display_container: 2
2024-12-10 14:00:53,335:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-12-10 14:00:53,335:INFO:create_model() successfully completed......................................
2024-12-10 14:00:53,401:INFO:SubProcess create_model() end ==================================
2024-12-10 14:00:53,401:INFO:Creating metrics dataframe
2024-12-10 14:00:53,405:INFO:Initializing Quadratic Discriminant Analysis
2024-12-10 14:00:53,405:INFO:Total runtime is 0.018687852223714194 minutes
2024-12-10 14:00:53,407:INFO:SubProcess create_model() called ==================================
2024-12-10 14:00:53,407:INFO:Initializing create_model()
2024-12-10 14:00:53,407:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4003B1AD0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E478BB82D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:00:53,407:INFO:Checking exceptions
2024-12-10 14:00:53,407:INFO:Importing libraries
2024-12-10 14:00:53,407:INFO:Copying training dataset
2024-12-10 14:00:53,409:INFO:Defining folds
2024-12-10 14:00:53,409:INFO:Declaring metric variables
2024-12-10 14:00:53,411:INFO:Importing untrained model
2024-12-10 14:00:53,412:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-10 14:00:53,415:INFO:Starting cross validation
2024-12-10 14:00:53,415:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:00:53,452:INFO:Calculating mean and std
2024-12-10 14:00:53,452:INFO:Creating metrics dataframe
2024-12-10 14:00:53,453:INFO:Uploading results into container
2024-12-10 14:00:53,453:INFO:Uploading model into container now
2024-12-10 14:00:53,454:INFO:_master_model_container: 8
2024-12-10 14:00:53,454:INFO:_display_container: 2
2024-12-10 14:00:53,454:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-10 14:00:53,454:INFO:create_model() successfully completed......................................
2024-12-10 14:00:53,514:INFO:SubProcess create_model() end ==================================
2024-12-10 14:00:53,514:INFO:Creating metrics dataframe
2024-12-10 14:00:53,518:INFO:Initializing Ada Boost Classifier
2024-12-10 14:00:53,518:INFO:Total runtime is 0.02057618300120036 minutes
2024-12-10 14:00:53,520:INFO:SubProcess create_model() called ==================================
2024-12-10 14:00:53,520:INFO:Initializing create_model()
2024-12-10 14:00:53,520:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4003B1AD0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E478BB82D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:00:53,520:INFO:Checking exceptions
2024-12-10 14:00:53,520:INFO:Importing libraries
2024-12-10 14:00:53,520:INFO:Copying training dataset
2024-12-10 14:00:53,521:INFO:Defining folds
2024-12-10 14:00:53,521:INFO:Declaring metric variables
2024-12-10 14:00:53,523:INFO:Importing untrained model
2024-12-10 14:00:53,524:INFO:Ada Boost Classifier Imported successfully
2024-12-10 14:00:53,527:INFO:Starting cross validation
2024-12-10 14:00:53,527:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:00:53,536:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 14:00:53,536:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 14:00:53,536:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 14:00:53,537:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 14:00:53,537:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 14:00:53,543:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 14:00:53,543:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 14:00:53,543:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 14:00:53,544:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 14:00:53,546:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 14:00:53,618:INFO:Calculating mean and std
2024-12-10 14:00:53,618:INFO:Creating metrics dataframe
2024-12-10 14:00:53,619:INFO:Uploading results into container
2024-12-10 14:00:53,619:INFO:Uploading model into container now
2024-12-10 14:00:53,620:INFO:_master_model_container: 9
2024-12-10 14:00:53,620:INFO:_display_container: 2
2024-12-10 14:00:53,620:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-12-10 14:00:53,620:INFO:create_model() successfully completed......................................
2024-12-10 14:00:53,678:INFO:SubProcess create_model() end ==================================
2024-12-10 14:00:53,678:INFO:Creating metrics dataframe
2024-12-10 14:00:53,683:INFO:Initializing Gradient Boosting Classifier
2024-12-10 14:00:53,683:INFO:Total runtime is 0.023318262894948327 minutes
2024-12-10 14:00:53,685:INFO:SubProcess create_model() called ==================================
2024-12-10 14:00:53,685:INFO:Initializing create_model()
2024-12-10 14:00:53,685:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4003B1AD0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E478BB82D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:00:53,685:INFO:Checking exceptions
2024-12-10 14:00:53,685:INFO:Importing libraries
2024-12-10 14:00:53,685:INFO:Copying training dataset
2024-12-10 14:00:53,686:INFO:Defining folds
2024-12-10 14:00:53,686:INFO:Declaring metric variables
2024-12-10 14:00:53,688:INFO:Importing untrained model
2024-12-10 14:00:53,690:INFO:Gradient Boosting Classifier Imported successfully
2024-12-10 14:00:53,692:INFO:Starting cross validation
2024-12-10 14:00:53,693:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:00:53,832:INFO:Calculating mean and std
2024-12-10 14:00:53,832:INFO:Creating metrics dataframe
2024-12-10 14:00:53,833:INFO:Uploading results into container
2024-12-10 14:00:53,834:INFO:Uploading model into container now
2024-12-10 14:00:53,834:INFO:_master_model_container: 10
2024-12-10 14:00:53,834:INFO:_display_container: 2
2024-12-10 14:00:53,834:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-10 14:00:53,834:INFO:create_model() successfully completed......................................
2024-12-10 14:00:53,894:INFO:SubProcess create_model() end ==================================
2024-12-10 14:00:53,895:INFO:Creating metrics dataframe
2024-12-10 14:00:53,899:INFO:Initializing Linear Discriminant Analysis
2024-12-10 14:00:53,899:INFO:Total runtime is 0.026926326751708987 minutes
2024-12-10 14:00:53,901:INFO:SubProcess create_model() called ==================================
2024-12-10 14:00:53,901:INFO:Initializing create_model()
2024-12-10 14:00:53,901:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4003B1AD0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E478BB82D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:00:53,901:INFO:Checking exceptions
2024-12-10 14:00:53,901:INFO:Importing libraries
2024-12-10 14:00:53,901:INFO:Copying training dataset
2024-12-10 14:00:53,902:INFO:Defining folds
2024-12-10 14:00:53,902:INFO:Declaring metric variables
2024-12-10 14:00:53,904:INFO:Importing untrained model
2024-12-10 14:00:53,905:INFO:Linear Discriminant Analysis Imported successfully
2024-12-10 14:00:53,908:INFO:Starting cross validation
2024-12-10 14:00:53,909:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:00:53,945:INFO:Calculating mean and std
2024-12-10 14:00:53,945:INFO:Creating metrics dataframe
2024-12-10 14:00:53,946:INFO:Uploading results into container
2024-12-10 14:00:53,947:INFO:Uploading model into container now
2024-12-10 14:00:53,947:INFO:_master_model_container: 11
2024-12-10 14:00:53,947:INFO:_display_container: 2
2024-12-10 14:00:53,947:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-10 14:00:53,947:INFO:create_model() successfully completed......................................
2024-12-10 14:00:54,005:INFO:SubProcess create_model() end ==================================
2024-12-10 14:00:54,005:INFO:Creating metrics dataframe
2024-12-10 14:00:54,009:INFO:Initializing Extra Trees Classifier
2024-12-10 14:00:54,010:INFO:Total runtime is 0.028765475749969485 minutes
2024-12-10 14:00:54,011:INFO:SubProcess create_model() called ==================================
2024-12-10 14:00:54,011:INFO:Initializing create_model()
2024-12-10 14:00:54,011:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4003B1AD0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E478BB82D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:00:54,011:INFO:Checking exceptions
2024-12-10 14:00:54,011:INFO:Importing libraries
2024-12-10 14:00:54,011:INFO:Copying training dataset
2024-12-10 14:00:54,013:INFO:Defining folds
2024-12-10 14:00:54,013:INFO:Declaring metric variables
2024-12-10 14:00:54,014:INFO:Importing untrained model
2024-12-10 14:00:54,016:INFO:Extra Trees Classifier Imported successfully
2024-12-10 14:00:54,018:INFO:Starting cross validation
2024-12-10 14:00:54,019:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:00:54,228:INFO:Calculating mean and std
2024-12-10 14:00:54,228:INFO:Creating metrics dataframe
2024-12-10 14:00:54,229:INFO:Uploading results into container
2024-12-10 14:00:54,229:INFO:Uploading model into container now
2024-12-10 14:00:54,230:INFO:_master_model_container: 12
2024-12-10 14:00:54,230:INFO:_display_container: 2
2024-12-10 14:00:54,230:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-12-10 14:00:54,230:INFO:create_model() successfully completed......................................
2024-12-10 14:00:54,286:INFO:SubProcess create_model() end ==================================
2024-12-10 14:00:54,286:INFO:Creating metrics dataframe
2024-12-10 14:00:54,290:INFO:Initializing Extreme Gradient Boosting
2024-12-10 14:00:54,290:INFO:Total runtime is 0.033427492777506514 minutes
2024-12-10 14:00:54,292:INFO:SubProcess create_model() called ==================================
2024-12-10 14:00:54,292:INFO:Initializing create_model()
2024-12-10 14:00:54,292:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4003B1AD0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E478BB82D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:00:54,292:INFO:Checking exceptions
2024-12-10 14:00:54,292:INFO:Importing libraries
2024-12-10 14:00:54,292:INFO:Copying training dataset
2024-12-10 14:00:54,294:INFO:Defining folds
2024-12-10 14:00:54,294:INFO:Declaring metric variables
2024-12-10 14:00:54,295:INFO:Importing untrained model
2024-12-10 14:00:54,297:INFO:Extreme Gradient Boosting Imported successfully
2024-12-10 14:00:54,298:INFO:Starting cross validation
2024-12-10 14:00:54,299:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:00:54,406:INFO:Calculating mean and std
2024-12-10 14:00:54,407:INFO:Creating metrics dataframe
2024-12-10 14:00:54,408:INFO:Uploading results into container
2024-12-10 14:00:54,408:INFO:Uploading model into container now
2024-12-10 14:00:54,409:INFO:_master_model_container: 13
2024-12-10 14:00:54,409:INFO:_display_container: 2
2024-12-10 14:00:54,409:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-12-10 14:00:54,409:INFO:create_model() successfully completed......................................
2024-12-10 14:00:54,466:INFO:SubProcess create_model() end ==================================
2024-12-10 14:00:54,466:INFO:Creating metrics dataframe
2024-12-10 14:00:54,471:INFO:Initializing Light Gradient Boosting Machine
2024-12-10 14:00:54,471:INFO:Total runtime is 0.036455480257670085 minutes
2024-12-10 14:00:54,473:INFO:SubProcess create_model() called ==================================
2024-12-10 14:00:54,473:INFO:Initializing create_model()
2024-12-10 14:00:54,473:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4003B1AD0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E478BB82D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:00:54,473:INFO:Checking exceptions
2024-12-10 14:00:54,473:INFO:Importing libraries
2024-12-10 14:00:54,473:INFO:Copying training dataset
2024-12-10 14:00:54,475:INFO:Defining folds
2024-12-10 14:00:54,475:INFO:Declaring metric variables
2024-12-10 14:00:54,476:INFO:Importing untrained model
2024-12-10 14:00:54,478:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-10 14:00:54,480:INFO:Starting cross validation
2024-12-10 14:00:54,480:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:00:55,339:INFO:Calculating mean and std
2024-12-10 14:00:55,339:INFO:Creating metrics dataframe
2024-12-10 14:00:55,341:INFO:Uploading results into container
2024-12-10 14:00:55,341:INFO:Uploading model into container now
2024-12-10 14:00:55,341:INFO:_master_model_container: 14
2024-12-10 14:00:55,341:INFO:_display_container: 2
2024-12-10 14:00:55,342:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-10 14:00:55,342:INFO:create_model() successfully completed......................................
2024-12-10 14:00:55,407:INFO:SubProcess create_model() end ==================================
2024-12-10 14:00:55,407:INFO:Creating metrics dataframe
2024-12-10 14:00:55,413:INFO:Initializing CatBoost Classifier
2024-12-10 14:00:55,413:INFO:Total runtime is 0.052152995268503824 minutes
2024-12-10 14:00:55,415:INFO:SubProcess create_model() called ==================================
2024-12-10 14:00:55,415:INFO:Initializing create_model()
2024-12-10 14:00:55,415:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4003B1AD0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E478BB82D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:00:55,415:INFO:Checking exceptions
2024-12-10 14:00:55,415:INFO:Importing libraries
2024-12-10 14:00:55,415:INFO:Copying training dataset
2024-12-10 14:00:55,417:INFO:Defining folds
2024-12-10 14:00:55,417:INFO:Declaring metric variables
2024-12-10 14:00:55,419:INFO:Importing untrained model
2024-12-10 14:00:55,421:INFO:CatBoost Classifier Imported successfully
2024-12-10 14:00:55,424:INFO:Starting cross validation
2024-12-10 14:00:55,425:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:00:57,237:INFO:Calculating mean and std
2024-12-10 14:00:57,237:INFO:Creating metrics dataframe
2024-12-10 14:00:57,238:INFO:Uploading results into container
2024-12-10 14:00:57,239:INFO:Uploading model into container now
2024-12-10 14:00:57,239:INFO:_master_model_container: 15
2024-12-10 14:00:57,239:INFO:_display_container: 2
2024-12-10 14:00:57,239:INFO:<catboost.core.CatBoostClassifier object at 0x000001E4003C54D0>
2024-12-10 14:00:57,239:INFO:create_model() successfully completed......................................
2024-12-10 14:00:57,297:INFO:SubProcess create_model() end ==================================
2024-12-10 14:00:57,297:INFO:Creating metrics dataframe
2024-12-10 14:00:57,302:INFO:Initializing Dummy Classifier
2024-12-10 14:00:57,302:INFO:Total runtime is 0.08363946278889975 minutes
2024-12-10 14:00:57,304:INFO:SubProcess create_model() called ==================================
2024-12-10 14:00:57,304:INFO:Initializing create_model()
2024-12-10 14:00:57,304:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4003B1AD0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E478BB82D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:00:57,304:INFO:Checking exceptions
2024-12-10 14:00:57,304:INFO:Importing libraries
2024-12-10 14:00:57,304:INFO:Copying training dataset
2024-12-10 14:00:57,306:INFO:Defining folds
2024-12-10 14:00:57,306:INFO:Declaring metric variables
2024-12-10 14:00:57,307:INFO:Importing untrained model
2024-12-10 14:00:57,308:INFO:Dummy Classifier Imported successfully
2024-12-10 14:00:57,311:INFO:Starting cross validation
2024-12-10 14:00:57,312:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:00:57,323:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 14:00:57,324:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 14:00:57,324:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 14:00:57,332:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 14:00:57,333:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 14:00:57,334:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 14:00:57,334:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 14:00:57,335:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 14:00:57,336:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 14:00:57,338:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 14:00:57,349:INFO:Calculating mean and std
2024-12-10 14:00:57,349:INFO:Creating metrics dataframe
2024-12-10 14:00:57,350:INFO:Uploading results into container
2024-12-10 14:00:57,351:INFO:Uploading model into container now
2024-12-10 14:00:57,351:INFO:_master_model_container: 16
2024-12-10 14:00:57,351:INFO:_display_container: 2
2024-12-10 14:00:57,351:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-12-10 14:00:57,351:INFO:create_model() successfully completed......................................
2024-12-10 14:00:57,410:INFO:SubProcess create_model() end ==================================
2024-12-10 14:00:57,410:INFO:Creating metrics dataframe
2024-12-10 14:00:57,415:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-12-10 14:00:57,418:INFO:Initializing create_model()
2024-12-10 14:00:57,418:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4003B1AD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:00:57,419:INFO:Checking exceptions
2024-12-10 14:00:57,419:INFO:Importing libraries
2024-12-10 14:00:57,419:INFO:Copying training dataset
2024-12-10 14:00:57,421:INFO:Defining folds
2024-12-10 14:00:57,421:INFO:Declaring metric variables
2024-12-10 14:00:57,421:INFO:Importing untrained model
2024-12-10 14:00:57,421:INFO:Declaring custom model
2024-12-10 14:00:57,421:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-10 14:00:57,421:INFO:Cross validation set to False
2024-12-10 14:00:57,421:INFO:Fitting Model
2024-12-10 14:00:57,425:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-10 14:00:57,425:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000105 seconds.
2024-12-10 14:00:57,425:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-10 14:00:57,425:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-10 14:00:57,426:INFO:[LightGBM] [Info] Total Bins 188
2024-12-10 14:00:57,426:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 7
2024-12-10 14:00:57,426:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-10 14:00:57,426:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-10 14:00:57,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,496:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-10 14:00:57,496:INFO:create_model() successfully completed......................................
2024-12-10 14:00:57,578:INFO:_master_model_container: 16
2024-12-10 14:00:57,579:INFO:_display_container: 2
2024-12-10 14:00:57,579:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-10 14:00:57,579:INFO:compare_models() successfully completed......................................
2024-12-10 14:00:57,584:INFO:Initializing finalize_model()
2024-12-10 14:00:57,584:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4003B1AD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-12-10 14:00:57,584:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-10 14:00:57,586:INFO:Initializing create_model()
2024-12-10 14:00:57,586:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4003B1AD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:00:57,586:INFO:Checking exceptions
2024-12-10 14:00:57,587:INFO:Importing libraries
2024-12-10 14:00:57,588:INFO:Copying training dataset
2024-12-10 14:00:57,588:INFO:Defining folds
2024-12-10 14:00:57,588:INFO:Declaring metric variables
2024-12-10 14:00:57,588:INFO:Importing untrained model
2024-12-10 14:00:57,588:INFO:Declaring custom model
2024-12-10 14:00:57,588:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-10 14:00:57,589:INFO:Cross validation set to False
2024-12-10 14:00:57,589:INFO:Fitting Model
2024-12-10 14:00:57,593:INFO:[LightGBM] [Info] Number of positive: 342, number of negative: 549
2024-12-10 14:00:57,594:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000135 seconds.
2024-12-10 14:00:57,594:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-10 14:00:57,594:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-10 14:00:57,594:INFO:[LightGBM] [Info] Total Bins 221
2024-12-10 14:00:57,594:INFO:[LightGBM] [Info] Number of data points in the train set: 891, number of used features: 7
2024-12-10 14:00:57,594:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383838 -> initscore=-0.473288
2024-12-10 14:00:57,594:INFO:[LightGBM] [Info] Start training from score -0.473288
2024-12-10 14:00:57,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:00:57,665:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'SibSp',
                                             'Parch', 'Fare', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=N...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-12-10 14:00:57,665:INFO:create_model() successfully completed......................................
2024-12-10 14:00:57,744:INFO:_master_model_container: 16
2024-12-10 14:00:57,744:INFO:_display_container: 2
2024-12-10 14:00:57,747:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'SibSp',
                                             'Parch', 'Fare', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=N...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-12-10 14:00:57,747:INFO:finalize_model() successfully completed......................................
2024-12-10 14:00:57,809:INFO:Initializing predict_model()
2024-12-10 14:00:57,809:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4003B1AD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'SibSp',
                                             'Parch', 'Fare', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=N...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E4791956C0>)
2024-12-10 14:00:57,810:INFO:Checking exceptions
2024-12-10 14:00:57,810:INFO:Preloading libraries
2024-12-10 14:00:57,811:INFO:Set up data.
2024-12-10 14:00:57,812:INFO:Set up index.
2024-12-10 14:04:40,519:INFO:PyCaret ClassificationExperiment
2024-12-10 14:04:40,519:INFO:Logging name: clf-default-name
2024-12-10 14:04:40,520:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-12-10 14:04:40,520:INFO:version 3.3.2
2024-12-10 14:04:40,520:INFO:Initializing setup()
2024-12-10 14:04:40,520:INFO:self.USI: 17f4
2024-12-10 14:04:40,520:INFO:self._variable_keys: {'X', '_ml_usecase', 'data', 'exp_name_log', 'USI', 'target_param', 'exp_id', 'html_param', 'y_test', 'n_jobs_param', 'idx', 'log_plots_param', 'fold_shuffle_param', 'memory', 'pipeline', 'X_test', 'logging_param', 'fix_imbalance', '_available_plots', 'X_train', 'gpu_n_jobs_param', 'y', 'fold_generator', 'gpu_param', 'y_train', 'seed', 'fold_groups_param', 'is_multiclass'}
2024-12-10 14:04:40,520:INFO:Checking environment
2024-12-10 14:04:40,520:INFO:python_version: 3.11.10
2024-12-10 14:04:40,520:INFO:python_build: ('main', 'Oct  3 2024 07:22:26')
2024-12-10 14:04:40,520:INFO:machine: AMD64
2024-12-10 14:04:40,520:INFO:platform: Windows-10-10.0.19045-SP0
2024-12-10 14:04:40,522:INFO:Memory: svmem(total=16908595200, available=2178551808, percent=87.1, used=14730043392, free=2178551808)
2024-12-10 14:04:40,523:INFO:Physical Core: 16
2024-12-10 14:04:40,523:INFO:Logical Core: 24
2024-12-10 14:04:40,523:INFO:Checking libraries
2024-12-10 14:04:40,523:INFO:System:
2024-12-10 14:04:40,523:INFO:    python: 3.11.10 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:26) [MSC v.1929 64 bit (AMD64)]
2024-12-10 14:04:40,523:INFO:executable: c:\Users\py\.conda\envs\hw4\python.exe
2024-12-10 14:04:40,523:INFO:   machine: Windows-10-10.0.19045-SP0
2024-12-10 14:04:40,523:INFO:PyCaret required dependencies:
2024-12-10 14:04:40,523:INFO:                 pip: 24.2
2024-12-10 14:04:40,523:INFO:          setuptools: 75.1.0
2024-12-10 14:04:40,523:INFO:             pycaret: 3.3.2
2024-12-10 14:04:40,523:INFO:             IPython: 8.30.0
2024-12-10 14:04:40,523:INFO:          ipywidgets: 8.1.5
2024-12-10 14:04:40,523:INFO:                tqdm: 4.67.1
2024-12-10 14:04:40,523:INFO:               numpy: 1.26.4
2024-12-10 14:04:40,523:INFO:              pandas: 2.1.4
2024-12-10 14:04:40,523:INFO:              jinja2: 3.1.4
2024-12-10 14:04:40,523:INFO:               scipy: 1.11.4
2024-12-10 14:04:40,523:INFO:              joblib: 1.3.2
2024-12-10 14:04:40,523:INFO:             sklearn: 1.4.2
2024-12-10 14:04:40,523:INFO:                pyod: 2.0.2
2024-12-10 14:04:40,523:INFO:            imblearn: 0.12.4
2024-12-10 14:04:40,523:INFO:   category_encoders: 2.6.4
2024-12-10 14:04:40,523:INFO:            lightgbm: 4.5.0
2024-12-10 14:04:40,523:INFO:               numba: 0.60.0
2024-12-10 14:04:40,523:INFO:            requests: 2.32.3
2024-12-10 14:04:40,523:INFO:          matplotlib: 3.7.5
2024-12-10 14:04:40,523:INFO:          scikitplot: 0.3.7
2024-12-10 14:04:40,523:INFO:         yellowbrick: 1.5
2024-12-10 14:04:40,523:INFO:              plotly: 5.24.1
2024-12-10 14:04:40,523:INFO:    plotly-resampler: Not installed
2024-12-10 14:04:40,523:INFO:             kaleido: 0.2.1
2024-12-10 14:04:40,523:INFO:           schemdraw: 0.15
2024-12-10 14:04:40,523:INFO:         statsmodels: 0.14.4
2024-12-10 14:04:40,523:INFO:              sktime: 0.26.0
2024-12-10 14:04:40,523:INFO:               tbats: 1.1.3
2024-12-10 14:04:40,523:INFO:            pmdarima: 2.0.4
2024-12-10 14:04:40,523:INFO:              psutil: 6.1.0
2024-12-10 14:04:40,523:INFO:          markupsafe: 3.0.2
2024-12-10 14:04:40,523:INFO:             pickle5: Not installed
2024-12-10 14:04:40,523:INFO:         cloudpickle: 3.1.0
2024-12-10 14:04:40,523:INFO:         deprecation: 2.1.0
2024-12-10 14:04:40,523:INFO:              xxhash: 3.5.0
2024-12-10 14:04:40,523:INFO:           wurlitzer: Not installed
2024-12-10 14:04:40,523:INFO:PyCaret optional dependencies:
2024-12-10 14:04:40,523:INFO:                shap: Not installed
2024-12-10 14:04:40,523:INFO:           interpret: Not installed
2024-12-10 14:04:40,523:INFO:                umap: Not installed
2024-12-10 14:04:40,523:INFO:     ydata_profiling: Not installed
2024-12-10 14:04:40,523:INFO:  explainerdashboard: Not installed
2024-12-10 14:04:40,523:INFO:             autoviz: Not installed
2024-12-10 14:04:40,523:INFO:           fairlearn: Not installed
2024-12-10 14:04:40,523:INFO:          deepchecks: Not installed
2024-12-10 14:04:40,523:INFO:             xgboost: 2.1.3
2024-12-10 14:04:40,524:INFO:            catboost: 1.2.7
2024-12-10 14:04:40,524:INFO:              kmodes: Not installed
2024-12-10 14:04:40,524:INFO:             mlxtend: Not installed
2024-12-10 14:04:40,524:INFO:       statsforecast: Not installed
2024-12-10 14:04:40,524:INFO:        tune_sklearn: Not installed
2024-12-10 14:04:40,524:INFO:                 ray: Not installed
2024-12-10 14:04:40,524:INFO:            hyperopt: Not installed
2024-12-10 14:04:40,524:INFO:              optuna: Not installed
2024-12-10 14:04:40,524:INFO:               skopt: Not installed
2024-12-10 14:04:40,524:INFO:              mlflow: Not installed
2024-12-10 14:04:40,524:INFO:              gradio: Not installed
2024-12-10 14:04:40,524:INFO:             fastapi: Not installed
2024-12-10 14:04:40,524:INFO:             uvicorn: Not installed
2024-12-10 14:04:40,524:INFO:              m2cgen: Not installed
2024-12-10 14:04:40,524:INFO:           evidently: Not installed
2024-12-10 14:04:40,524:INFO:               fugue: Not installed
2024-12-10 14:04:40,524:INFO:           streamlit: Not installed
2024-12-10 14:04:40,524:INFO:             prophet: Not installed
2024-12-10 14:04:40,524:INFO:None
2024-12-10 14:04:40,524:INFO:Set up data.
2024-12-10 14:04:40,526:INFO:Set up folding strategy.
2024-12-10 14:04:40,526:INFO:Set up train/test split.
2024-12-10 14:04:40,528:INFO:Set up index.
2024-12-10 14:04:40,528:INFO:Assigning column types.
2024-12-10 14:04:40,529:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-10 14:04:40,550:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-10 14:04:40,551:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-10 14:04:40,564:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 14:04:40,565:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 14:04:40,586:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-10 14:04:40,586:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-10 14:04:40,599:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 14:04:40,600:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 14:04:40,600:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-10 14:04:40,621:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-10 14:04:40,633:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 14:04:40,635:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 14:04:40,656:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-10 14:04:40,668:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 14:04:40,669:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 14:04:40,670:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-12-10 14:04:40,702:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 14:04:40,704:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 14:04:40,737:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 14:04:40,738:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 14:04:40,739:INFO:Preparing preprocessing pipeline...
2024-12-10 14:04:40,740:INFO:Set up simple imputation.
2024-12-10 14:04:40,748:INFO:Finished creating preprocessing pipeline.
2024-12-10 14:04:40,750:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\py\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'SibSp',
                                             'Parch', 'Fare', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-12-10 14:04:40,750:INFO:Creating final display dataframe.
2024-12-10 14:04:40,778:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (891, 8)
4        Transformed data shape          (891, 8)
5   Transformed train set shape          (623, 8)
6    Transformed test set shape          (268, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              17f4
2024-12-10 14:04:40,824:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 14:04:40,827:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 14:04:40,865:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 14:04:40,866:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 14:04:40,867:INFO:setup() successfully completed in 0.35s...............
2024-12-10 14:04:40,868:INFO:Initializing compare_models()
2024-12-10 14:04:40,868:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E40057AA10>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E40057AA10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-12-10 14:04:40,868:INFO:Checking exceptions
2024-12-10 14:04:40,869:INFO:Preparing display monitor
2024-12-10 14:04:40,880:INFO:Initializing Logistic Regression
2024-12-10 14:04:40,880:INFO:Total runtime is 0.0 minutes
2024-12-10 14:04:40,882:INFO:SubProcess create_model() called ==================================
2024-12-10 14:04:40,882:INFO:Initializing create_model()
2024-12-10 14:04:40,882:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E40057AA10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4003B1710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:04:40,882:INFO:Checking exceptions
2024-12-10 14:04:40,882:INFO:Importing libraries
2024-12-10 14:04:40,882:INFO:Copying training dataset
2024-12-10 14:04:40,884:INFO:Defining folds
2024-12-10 14:04:40,884:INFO:Declaring metric variables
2024-12-10 14:04:40,885:INFO:Importing untrained model
2024-12-10 14:04:40,887:INFO:Logistic Regression Imported successfully
2024-12-10 14:04:40,890:INFO:Starting cross validation
2024-12-10 14:04:40,891:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:04:40,928:INFO:Calculating mean and std
2024-12-10 14:04:40,928:INFO:Creating metrics dataframe
2024-12-10 14:04:40,930:INFO:Uploading results into container
2024-12-10 14:04:40,930:INFO:Uploading model into container now
2024-12-10 14:04:40,931:INFO:_master_model_container: 1
2024-12-10 14:04:40,931:INFO:_display_container: 2
2024-12-10 14:04:40,931:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-10 14:04:40,931:INFO:create_model() successfully completed......................................
2024-12-10 14:04:41,005:INFO:SubProcess create_model() end ==================================
2024-12-10 14:04:41,005:INFO:Creating metrics dataframe
2024-12-10 14:04:41,008:INFO:Initializing K Neighbors Classifier
2024-12-10 14:04:41,008:INFO:Total runtime is 0.0021428346633911135 minutes
2024-12-10 14:04:41,010:INFO:SubProcess create_model() called ==================================
2024-12-10 14:04:41,010:INFO:Initializing create_model()
2024-12-10 14:04:41,010:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E40057AA10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4003B1710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:04:41,010:INFO:Checking exceptions
2024-12-10 14:04:41,010:INFO:Importing libraries
2024-12-10 14:04:41,010:INFO:Copying training dataset
2024-12-10 14:04:41,011:INFO:Defining folds
2024-12-10 14:04:41,011:INFO:Declaring metric variables
2024-12-10 14:04:41,013:INFO:Importing untrained model
2024-12-10 14:04:41,014:INFO:K Neighbors Classifier Imported successfully
2024-12-10 14:04:41,017:INFO:Starting cross validation
2024-12-10 14:04:41,017:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:04:41,086:INFO:Calculating mean and std
2024-12-10 14:04:41,086:INFO:Creating metrics dataframe
2024-12-10 14:04:41,087:INFO:Uploading results into container
2024-12-10 14:04:41,087:INFO:Uploading model into container now
2024-12-10 14:04:41,087:INFO:_master_model_container: 2
2024-12-10 14:04:41,087:INFO:_display_container: 2
2024-12-10 14:04:41,087:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-10 14:04:41,087:INFO:create_model() successfully completed......................................
2024-12-10 14:04:41,152:INFO:SubProcess create_model() end ==================================
2024-12-10 14:04:41,153:INFO:Creating metrics dataframe
2024-12-10 14:04:41,156:INFO:Initializing Naive Bayes
2024-12-10 14:04:41,156:INFO:Total runtime is 0.004609429836273193 minutes
2024-12-10 14:04:41,158:INFO:SubProcess create_model() called ==================================
2024-12-10 14:04:41,158:INFO:Initializing create_model()
2024-12-10 14:04:41,158:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E40057AA10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4003B1710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:04:41,158:INFO:Checking exceptions
2024-12-10 14:04:41,158:INFO:Importing libraries
2024-12-10 14:04:41,158:INFO:Copying training dataset
2024-12-10 14:04:41,159:INFO:Defining folds
2024-12-10 14:04:41,159:INFO:Declaring metric variables
2024-12-10 14:04:41,161:INFO:Importing untrained model
2024-12-10 14:04:41,162:INFO:Naive Bayes Imported successfully
2024-12-10 14:04:41,165:INFO:Starting cross validation
2024-12-10 14:04:41,165:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:04:41,191:INFO:Calculating mean and std
2024-12-10 14:04:41,191:INFO:Creating metrics dataframe
2024-12-10 14:04:41,192:INFO:Uploading results into container
2024-12-10 14:04:41,192:INFO:Uploading model into container now
2024-12-10 14:04:41,193:INFO:_master_model_container: 3
2024-12-10 14:04:41,193:INFO:_display_container: 2
2024-12-10 14:04:41,193:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-10 14:04:41,193:INFO:create_model() successfully completed......................................
2024-12-10 14:04:41,266:INFO:SubProcess create_model() end ==================================
2024-12-10 14:04:41,266:INFO:Creating metrics dataframe
2024-12-10 14:04:41,269:INFO:Initializing Decision Tree Classifier
2024-12-10 14:04:41,269:INFO:Total runtime is 0.006486483414967855 minutes
2024-12-10 14:04:41,271:INFO:SubProcess create_model() called ==================================
2024-12-10 14:04:41,271:INFO:Initializing create_model()
2024-12-10 14:04:41,271:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E40057AA10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4003B1710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:04:41,271:INFO:Checking exceptions
2024-12-10 14:04:41,271:INFO:Importing libraries
2024-12-10 14:04:41,271:INFO:Copying training dataset
2024-12-10 14:04:41,273:INFO:Defining folds
2024-12-10 14:04:41,273:INFO:Declaring metric variables
2024-12-10 14:04:41,275:INFO:Importing untrained model
2024-12-10 14:04:41,276:INFO:Decision Tree Classifier Imported successfully
2024-12-10 14:04:41,279:INFO:Starting cross validation
2024-12-10 14:04:41,280:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:04:41,317:INFO:Calculating mean and std
2024-12-10 14:04:41,317:INFO:Creating metrics dataframe
2024-12-10 14:04:41,318:INFO:Uploading results into container
2024-12-10 14:04:41,318:INFO:Uploading model into container now
2024-12-10 14:04:41,318:INFO:_master_model_container: 4
2024-12-10 14:04:41,318:INFO:_display_container: 2
2024-12-10 14:04:41,319:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-12-10 14:04:41,319:INFO:create_model() successfully completed......................................
2024-12-10 14:04:41,383:INFO:SubProcess create_model() end ==================================
2024-12-10 14:04:41,383:INFO:Creating metrics dataframe
2024-12-10 14:04:41,387:INFO:Initializing SVM - Linear Kernel
2024-12-10 14:04:41,387:INFO:Total runtime is 0.00844659407933553 minutes
2024-12-10 14:04:41,389:INFO:SubProcess create_model() called ==================================
2024-12-10 14:04:41,389:INFO:Initializing create_model()
2024-12-10 14:04:41,389:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E40057AA10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4003B1710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:04:41,389:INFO:Checking exceptions
2024-12-10 14:04:41,389:INFO:Importing libraries
2024-12-10 14:04:41,389:INFO:Copying training dataset
2024-12-10 14:04:41,390:INFO:Defining folds
2024-12-10 14:04:41,390:INFO:Declaring metric variables
2024-12-10 14:04:41,392:INFO:Importing untrained model
2024-12-10 14:04:41,393:INFO:SVM - Linear Kernel Imported successfully
2024-12-10 14:04:41,396:INFO:Starting cross validation
2024-12-10 14:04:41,396:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:04:41,416:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 14:04:41,422:INFO:Calculating mean and std
2024-12-10 14:04:41,422:INFO:Creating metrics dataframe
2024-12-10 14:04:41,423:INFO:Uploading results into container
2024-12-10 14:04:41,423:INFO:Uploading model into container now
2024-12-10 14:04:41,423:INFO:_master_model_container: 5
2024-12-10 14:04:41,423:INFO:_display_container: 2
2024-12-10 14:04:41,424:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-10 14:04:41,424:INFO:create_model() successfully completed......................................
2024-12-10 14:04:41,480:INFO:SubProcess create_model() end ==================================
2024-12-10 14:04:41,481:INFO:Creating metrics dataframe
2024-12-10 14:04:41,484:INFO:Initializing Ridge Classifier
2024-12-10 14:04:41,484:INFO:Total runtime is 0.010074484348297118 minutes
2024-12-10 14:04:41,485:INFO:SubProcess create_model() called ==================================
2024-12-10 14:04:41,486:INFO:Initializing create_model()
2024-12-10 14:04:41,486:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E40057AA10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4003B1710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:04:41,486:INFO:Checking exceptions
2024-12-10 14:04:41,486:INFO:Importing libraries
2024-12-10 14:04:41,486:INFO:Copying training dataset
2024-12-10 14:04:41,487:INFO:Defining folds
2024-12-10 14:04:41,487:INFO:Declaring metric variables
2024-12-10 14:04:41,488:INFO:Importing untrained model
2024-12-10 14:04:41,490:INFO:Ridge Classifier Imported successfully
2024-12-10 14:04:41,493:INFO:Starting cross validation
2024-12-10 14:04:41,493:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:04:41,530:INFO:Calculating mean and std
2024-12-10 14:04:41,530:INFO:Creating metrics dataframe
2024-12-10 14:04:41,531:INFO:Uploading results into container
2024-12-10 14:04:41,531:INFO:Uploading model into container now
2024-12-10 14:04:41,532:INFO:_master_model_container: 6
2024-12-10 14:04:41,532:INFO:_display_container: 2
2024-12-10 14:04:41,532:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-12-10 14:04:41,532:INFO:create_model() successfully completed......................................
2024-12-10 14:04:41,602:INFO:SubProcess create_model() end ==================================
2024-12-10 14:04:41,602:INFO:Creating metrics dataframe
2024-12-10 14:04:41,606:INFO:Initializing Random Forest Classifier
2024-12-10 14:04:41,606:INFO:Total runtime is 0.012101038297017416 minutes
2024-12-10 14:04:41,607:INFO:SubProcess create_model() called ==================================
2024-12-10 14:04:41,608:INFO:Initializing create_model()
2024-12-10 14:04:41,608:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E40057AA10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4003B1710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:04:41,608:INFO:Checking exceptions
2024-12-10 14:04:41,608:INFO:Importing libraries
2024-12-10 14:04:41,608:INFO:Copying training dataset
2024-12-10 14:04:41,609:INFO:Defining folds
2024-12-10 14:04:41,609:INFO:Declaring metric variables
2024-12-10 14:04:41,611:INFO:Importing untrained model
2024-12-10 14:04:41,612:INFO:Random Forest Classifier Imported successfully
2024-12-10 14:04:41,615:INFO:Starting cross validation
2024-12-10 14:04:41,615:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:04:41,799:INFO:Calculating mean and std
2024-12-10 14:04:41,799:INFO:Creating metrics dataframe
2024-12-10 14:04:41,800:INFO:Uploading results into container
2024-12-10 14:04:41,800:INFO:Uploading model into container now
2024-12-10 14:04:41,800:INFO:_master_model_container: 7
2024-12-10 14:04:41,800:INFO:_display_container: 2
2024-12-10 14:04:41,800:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-12-10 14:04:41,800:INFO:create_model() successfully completed......................................
2024-12-10 14:04:41,862:INFO:SubProcess create_model() end ==================================
2024-12-10 14:04:41,862:INFO:Creating metrics dataframe
2024-12-10 14:04:41,866:INFO:Initializing Quadratic Discriminant Analysis
2024-12-10 14:04:41,866:INFO:Total runtime is 0.01643814245859782 minutes
2024-12-10 14:04:41,868:INFO:SubProcess create_model() called ==================================
2024-12-10 14:04:41,868:INFO:Initializing create_model()
2024-12-10 14:04:41,868:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E40057AA10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4003B1710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:04:41,868:INFO:Checking exceptions
2024-12-10 14:04:41,868:INFO:Importing libraries
2024-12-10 14:04:41,868:INFO:Copying training dataset
2024-12-10 14:04:41,870:INFO:Defining folds
2024-12-10 14:04:41,870:INFO:Declaring metric variables
2024-12-10 14:04:41,871:INFO:Importing untrained model
2024-12-10 14:04:41,873:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-10 14:04:41,877:INFO:Starting cross validation
2024-12-10 14:04:41,877:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:04:41,915:INFO:Calculating mean and std
2024-12-10 14:04:41,915:INFO:Creating metrics dataframe
2024-12-10 14:04:41,916:INFO:Uploading results into container
2024-12-10 14:04:41,916:INFO:Uploading model into container now
2024-12-10 14:04:41,916:INFO:_master_model_container: 8
2024-12-10 14:04:41,916:INFO:_display_container: 2
2024-12-10 14:04:41,916:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-10 14:04:41,916:INFO:create_model() successfully completed......................................
2024-12-10 14:04:41,979:INFO:SubProcess create_model() end ==================================
2024-12-10 14:04:41,979:INFO:Creating metrics dataframe
2024-12-10 14:04:41,983:INFO:Initializing Ada Boost Classifier
2024-12-10 14:04:41,983:INFO:Total runtime is 0.0183816393216451 minutes
2024-12-10 14:04:41,985:INFO:SubProcess create_model() called ==================================
2024-12-10 14:04:41,985:INFO:Initializing create_model()
2024-12-10 14:04:41,985:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E40057AA10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4003B1710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:04:41,985:INFO:Checking exceptions
2024-12-10 14:04:41,985:INFO:Importing libraries
2024-12-10 14:04:41,985:INFO:Copying training dataset
2024-12-10 14:04:41,987:INFO:Defining folds
2024-12-10 14:04:41,987:INFO:Declaring metric variables
2024-12-10 14:04:41,988:INFO:Importing untrained model
2024-12-10 14:04:41,990:INFO:Ada Boost Classifier Imported successfully
2024-12-10 14:04:41,993:INFO:Starting cross validation
2024-12-10 14:04:41,994:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:04:42,002:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 14:04:42,003:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 14:04:42,003:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 14:04:42,004:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 14:04:42,004:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 14:04:42,006:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 14:04:42,007:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 14:04:42,008:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 14:04:42,008:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 14:04:42,009:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 14:04:42,084:INFO:Calculating mean and std
2024-12-10 14:04:42,084:INFO:Creating metrics dataframe
2024-12-10 14:04:42,085:INFO:Uploading results into container
2024-12-10 14:04:42,085:INFO:Uploading model into container now
2024-12-10 14:04:42,085:INFO:_master_model_container: 9
2024-12-10 14:04:42,085:INFO:_display_container: 2
2024-12-10 14:04:42,085:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-12-10 14:04:42,085:INFO:create_model() successfully completed......................................
2024-12-10 14:04:42,148:INFO:SubProcess create_model() end ==================================
2024-12-10 14:04:42,148:INFO:Creating metrics dataframe
2024-12-10 14:04:42,152:INFO:Initializing Gradient Boosting Classifier
2024-12-10 14:04:42,152:INFO:Total runtime is 0.021205532550811767 minutes
2024-12-10 14:04:42,154:INFO:SubProcess create_model() called ==================================
2024-12-10 14:04:42,154:INFO:Initializing create_model()
2024-12-10 14:04:42,154:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E40057AA10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4003B1710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:04:42,154:INFO:Checking exceptions
2024-12-10 14:04:42,154:INFO:Importing libraries
2024-12-10 14:04:42,154:INFO:Copying training dataset
2024-12-10 14:04:42,156:INFO:Defining folds
2024-12-10 14:04:42,156:INFO:Declaring metric variables
2024-12-10 14:04:42,157:INFO:Importing untrained model
2024-12-10 14:04:42,159:INFO:Gradient Boosting Classifier Imported successfully
2024-12-10 14:04:42,162:INFO:Starting cross validation
2024-12-10 14:04:42,163:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:04:42,277:INFO:Calculating mean and std
2024-12-10 14:04:42,277:INFO:Creating metrics dataframe
2024-12-10 14:04:42,278:INFO:Uploading results into container
2024-12-10 14:04:42,278:INFO:Uploading model into container now
2024-12-10 14:04:42,278:INFO:_master_model_container: 10
2024-12-10 14:04:42,278:INFO:_display_container: 2
2024-12-10 14:04:42,279:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-10 14:04:42,279:INFO:create_model() successfully completed......................................
2024-12-10 14:04:42,343:INFO:SubProcess create_model() end ==================================
2024-12-10 14:04:42,343:INFO:Creating metrics dataframe
2024-12-10 14:04:42,347:INFO:Initializing Linear Discriminant Analysis
2024-12-10 14:04:42,347:INFO:Total runtime is 0.02444469928741455 minutes
2024-12-10 14:04:42,348:INFO:SubProcess create_model() called ==================================
2024-12-10 14:04:42,348:INFO:Initializing create_model()
2024-12-10 14:04:42,348:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E40057AA10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4003B1710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:04:42,348:INFO:Checking exceptions
2024-12-10 14:04:42,348:INFO:Importing libraries
2024-12-10 14:04:42,348:INFO:Copying training dataset
2024-12-10 14:04:42,350:INFO:Defining folds
2024-12-10 14:04:42,350:INFO:Declaring metric variables
2024-12-10 14:04:42,352:INFO:Importing untrained model
2024-12-10 14:04:42,353:INFO:Linear Discriminant Analysis Imported successfully
2024-12-10 14:04:42,356:INFO:Starting cross validation
2024-12-10 14:04:42,357:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:04:42,393:INFO:Calculating mean and std
2024-12-10 14:04:42,394:INFO:Creating metrics dataframe
2024-12-10 14:04:42,395:INFO:Uploading results into container
2024-12-10 14:04:42,395:INFO:Uploading model into container now
2024-12-10 14:04:42,395:INFO:_master_model_container: 11
2024-12-10 14:04:42,395:INFO:_display_container: 2
2024-12-10 14:04:42,395:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-10 14:04:42,395:INFO:create_model() successfully completed......................................
2024-12-10 14:04:42,463:INFO:SubProcess create_model() end ==================================
2024-12-10 14:04:42,464:INFO:Creating metrics dataframe
2024-12-10 14:04:42,468:INFO:Initializing Extra Trees Classifier
2024-12-10 14:04:42,468:INFO:Total runtime is 0.02646776835123698 minutes
2024-12-10 14:04:42,469:INFO:SubProcess create_model() called ==================================
2024-12-10 14:04:42,470:INFO:Initializing create_model()
2024-12-10 14:04:42,470:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E40057AA10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4003B1710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:04:42,470:INFO:Checking exceptions
2024-12-10 14:04:42,470:INFO:Importing libraries
2024-12-10 14:04:42,470:INFO:Copying training dataset
2024-12-10 14:04:42,472:INFO:Defining folds
2024-12-10 14:04:42,472:INFO:Declaring metric variables
2024-12-10 14:04:42,473:INFO:Importing untrained model
2024-12-10 14:04:42,475:INFO:Extra Trees Classifier Imported successfully
2024-12-10 14:04:42,478:INFO:Starting cross validation
2024-12-10 14:04:42,479:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:04:42,620:INFO:Calculating mean and std
2024-12-10 14:04:42,620:INFO:Creating metrics dataframe
2024-12-10 14:04:42,621:INFO:Uploading results into container
2024-12-10 14:04:42,621:INFO:Uploading model into container now
2024-12-10 14:04:42,622:INFO:_master_model_container: 12
2024-12-10 14:04:42,622:INFO:_display_container: 2
2024-12-10 14:04:42,622:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-12-10 14:04:42,622:INFO:create_model() successfully completed......................................
2024-12-10 14:04:42,681:INFO:SubProcess create_model() end ==================================
2024-12-10 14:04:42,681:INFO:Creating metrics dataframe
2024-12-10 14:04:42,686:INFO:Initializing Extreme Gradient Boosting
2024-12-10 14:04:42,686:INFO:Total runtime is 0.03009788990020752 minutes
2024-12-10 14:04:42,687:INFO:SubProcess create_model() called ==================================
2024-12-10 14:04:42,688:INFO:Initializing create_model()
2024-12-10 14:04:42,688:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E40057AA10>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4003B1710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:04:42,688:INFO:Checking exceptions
2024-12-10 14:04:42,688:INFO:Importing libraries
2024-12-10 14:04:42,688:INFO:Copying training dataset
2024-12-10 14:04:42,689:INFO:Defining folds
2024-12-10 14:04:42,689:INFO:Declaring metric variables
2024-12-10 14:04:42,691:INFO:Importing untrained model
2024-12-10 14:04:42,692:INFO:Extreme Gradient Boosting Imported successfully
2024-12-10 14:04:42,695:INFO:Starting cross validation
2024-12-10 14:04:42,695:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:04:42,754:INFO:Calculating mean and std
2024-12-10 14:04:42,754:INFO:Creating metrics dataframe
2024-12-10 14:04:42,755:INFO:Uploading results into container
2024-12-10 14:04:42,756:INFO:Uploading model into container now
2024-12-10 14:04:42,756:INFO:_master_model_container: 13
2024-12-10 14:04:42,756:INFO:_display_container: 2
2024-12-10 14:04:42,756:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-12-10 14:04:42,756:INFO:create_model() successfully completed......................................
2024-12-10 14:04:42,813:INFO:SubProcess create_model() end ==================================
2024-12-10 14:04:42,813:INFO:Creating metrics dataframe
2024-12-10 14:04:42,818:INFO:Initializing Light Gradient Boosting Machine
2024-12-10 14:04:42,818:INFO:Total runtime is 0.03230886061986287 minutes
2024-12-10 14:04:42,819:INFO:SubProcess create_model() called ==================================
2024-12-10 14:04:42,820:INFO:Initializing create_model()
2024-12-10 14:04:42,820:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E40057AA10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4003B1710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:04:42,820:INFO:Checking exceptions
2024-12-10 14:04:42,820:INFO:Importing libraries
2024-12-10 14:04:42,820:INFO:Copying training dataset
2024-12-10 14:04:42,821:INFO:Defining folds
2024-12-10 14:04:42,821:INFO:Declaring metric variables
2024-12-10 14:04:42,823:INFO:Importing untrained model
2024-12-10 14:04:42,825:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-10 14:04:42,827:INFO:Starting cross validation
2024-12-10 14:04:42,828:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:04:43,576:INFO:Calculating mean and std
2024-12-10 14:04:43,576:INFO:Creating metrics dataframe
2024-12-10 14:04:43,578:INFO:Uploading results into container
2024-12-10 14:04:43,578:INFO:Uploading model into container now
2024-12-10 14:04:43,578:INFO:_master_model_container: 14
2024-12-10 14:04:43,578:INFO:_display_container: 2
2024-12-10 14:04:43,579:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-10 14:04:43,579:INFO:create_model() successfully completed......................................
2024-12-10 14:04:43,647:INFO:SubProcess create_model() end ==================================
2024-12-10 14:04:43,647:INFO:Creating metrics dataframe
2024-12-10 14:04:43,653:INFO:Initializing CatBoost Classifier
2024-12-10 14:04:43,653:INFO:Total runtime is 0.04621236324310302 minutes
2024-12-10 14:04:43,655:INFO:SubProcess create_model() called ==================================
2024-12-10 14:04:43,655:INFO:Initializing create_model()
2024-12-10 14:04:43,655:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E40057AA10>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4003B1710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:04:43,655:INFO:Checking exceptions
2024-12-10 14:04:43,655:INFO:Importing libraries
2024-12-10 14:04:43,655:INFO:Copying training dataset
2024-12-10 14:04:43,658:INFO:Defining folds
2024-12-10 14:04:43,658:INFO:Declaring metric variables
2024-12-10 14:04:43,659:INFO:Importing untrained model
2024-12-10 14:04:43,661:INFO:CatBoost Classifier Imported successfully
2024-12-10 14:04:43,664:INFO:Starting cross validation
2024-12-10 14:04:43,665:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:04:45,500:INFO:Calculating mean and std
2024-12-10 14:04:45,500:INFO:Creating metrics dataframe
2024-12-10 14:04:45,501:INFO:Uploading results into container
2024-12-10 14:04:45,501:INFO:Uploading model into container now
2024-12-10 14:04:45,502:INFO:_master_model_container: 15
2024-12-10 14:04:45,502:INFO:_display_container: 2
2024-12-10 14:04:45,502:INFO:<catboost.core.CatBoostClassifier object at 0x000001E478889950>
2024-12-10 14:04:45,502:INFO:create_model() successfully completed......................................
2024-12-10 14:04:45,560:INFO:SubProcess create_model() end ==================================
2024-12-10 14:04:45,560:INFO:Creating metrics dataframe
2024-12-10 14:04:45,564:INFO:Initializing Dummy Classifier
2024-12-10 14:04:45,564:INFO:Total runtime is 0.07807765007019044 minutes
2024-12-10 14:04:45,565:INFO:SubProcess create_model() called ==================================
2024-12-10 14:04:45,565:INFO:Initializing create_model()
2024-12-10 14:04:45,566:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E40057AA10>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4003B1710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:04:45,566:INFO:Checking exceptions
2024-12-10 14:04:45,566:INFO:Importing libraries
2024-12-10 14:04:45,566:INFO:Copying training dataset
2024-12-10 14:04:45,567:INFO:Defining folds
2024-12-10 14:04:45,567:INFO:Declaring metric variables
2024-12-10 14:04:45,568:INFO:Importing untrained model
2024-12-10 14:04:45,570:INFO:Dummy Classifier Imported successfully
2024-12-10 14:04:45,572:INFO:Starting cross validation
2024-12-10 14:04:45,573:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:04:45,585:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 14:04:45,586:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 14:04:45,586:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 14:04:45,586:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 14:04:45,587:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 14:04:45,588:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 14:04:45,589:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 14:04:45,592:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 14:04:45,592:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 14:04:45,592:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 14:04:45,598:INFO:Calculating mean and std
2024-12-10 14:04:45,598:INFO:Creating metrics dataframe
2024-12-10 14:04:45,599:INFO:Uploading results into container
2024-12-10 14:04:45,599:INFO:Uploading model into container now
2024-12-10 14:04:45,599:INFO:_master_model_container: 16
2024-12-10 14:04:45,599:INFO:_display_container: 2
2024-12-10 14:04:45,599:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-12-10 14:04:45,599:INFO:create_model() successfully completed......................................
2024-12-10 14:04:45,662:INFO:SubProcess create_model() end ==================================
2024-12-10 14:04:45,662:INFO:Creating metrics dataframe
2024-12-10 14:04:45,667:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-12-10 14:04:45,671:INFO:Initializing create_model()
2024-12-10 14:04:45,671:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E40057AA10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:04:45,671:INFO:Checking exceptions
2024-12-10 14:04:45,671:INFO:Importing libraries
2024-12-10 14:04:45,672:INFO:Copying training dataset
2024-12-10 14:04:45,673:INFO:Defining folds
2024-12-10 14:04:45,673:INFO:Declaring metric variables
2024-12-10 14:04:45,673:INFO:Importing untrained model
2024-12-10 14:04:45,673:INFO:Declaring custom model
2024-12-10 14:04:45,673:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-10 14:04:45,674:INFO:Cross validation set to False
2024-12-10 14:04:45,674:INFO:Fitting Model
2024-12-10 14:04:45,678:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-10 14:04:45,678:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000157 seconds.
2024-12-10 14:04:45,678:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-10 14:04:45,678:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-10 14:04:45,678:INFO:[LightGBM] [Info] Total Bins 188
2024-12-10 14:04:45,678:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 7
2024-12-10 14:04:45,678:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-10 14:04:45,678:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-10 14:04:45,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,728:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-10 14:04:45,729:INFO:create_model() successfully completed......................................
2024-12-10 14:04:45,807:INFO:_master_model_container: 16
2024-12-10 14:04:45,807:INFO:_display_container: 2
2024-12-10 14:04:45,808:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-10 14:04:45,808:INFO:compare_models() successfully completed......................................
2024-12-10 14:04:45,812:INFO:Initializing finalize_model()
2024-12-10 14:04:45,812:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E40057AA10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-12-10 14:04:45,812:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-10 14:04:45,813:INFO:Initializing create_model()
2024-12-10 14:04:45,814:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E40057AA10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:04:45,814:INFO:Checking exceptions
2024-12-10 14:04:45,815:INFO:Importing libraries
2024-12-10 14:04:45,815:INFO:Copying training dataset
2024-12-10 14:04:45,815:INFO:Defining folds
2024-12-10 14:04:45,815:INFO:Declaring metric variables
2024-12-10 14:04:45,815:INFO:Importing untrained model
2024-12-10 14:04:45,815:INFO:Declaring custom model
2024-12-10 14:04:45,815:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-10 14:04:45,816:INFO:Cross validation set to False
2024-12-10 14:04:45,816:INFO:Fitting Model
2024-12-10 14:04:45,820:INFO:[LightGBM] [Info] Number of positive: 342, number of negative: 549
2024-12-10 14:04:45,820:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000115 seconds.
2024-12-10 14:04:45,820:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-12-10 14:04:45,820:INFO:[LightGBM] [Info] Total Bins 221
2024-12-10 14:04:45,821:INFO:[LightGBM] [Info] Number of data points in the train set: 891, number of used features: 7
2024-12-10 14:04:45,821:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383838 -> initscore=-0.473288
2024-12-10 14:04:45,821:INFO:[LightGBM] [Info] Start training from score -0.473288
2024-12-10 14:04:45,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:04:45,870:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'SibSp',
                                             'Parch', 'Fare', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=N...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-12-10 14:04:45,870:INFO:create_model() successfully completed......................................
2024-12-10 14:04:45,934:INFO:_master_model_container: 16
2024-12-10 14:04:45,934:INFO:_display_container: 2
2024-12-10 14:04:45,937:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'SibSp',
                                             'Parch', 'Fare', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=N...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-12-10 14:04:45,937:INFO:finalize_model() successfully completed......................................
2024-12-10 14:04:45,998:INFO:Initializing predict_model()
2024-12-10 14:04:45,998:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E40057AA10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'SibSp',
                                             'Parch', 'Fare', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=N...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E4791949A0>)
2024-12-10 14:04:45,998:INFO:Checking exceptions
2024-12-10 14:04:45,998:INFO:Preloading libraries
2024-12-10 14:04:45,999:INFO:Set up data.
2024-12-10 14:04:46,001:INFO:Set up index.
2024-12-10 14:07:45,177:INFO:PyCaret ClassificationExperiment
2024-12-10 14:07:45,177:INFO:Logging name: clf-default-name
2024-12-10 14:07:45,177:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-12-10 14:07:45,177:INFO:version 3.3.2
2024-12-10 14:07:45,177:INFO:Initializing setup()
2024-12-10 14:07:45,178:INFO:self.USI: 00e1
2024-12-10 14:07:45,178:INFO:self._variable_keys: {'X', '_ml_usecase', 'data', 'exp_name_log', 'USI', 'target_param', 'exp_id', 'html_param', 'y_test', 'n_jobs_param', 'idx', 'log_plots_param', 'fold_shuffle_param', 'memory', 'pipeline', 'X_test', 'logging_param', 'fix_imbalance', '_available_plots', 'X_train', 'gpu_n_jobs_param', 'y', 'fold_generator', 'gpu_param', 'y_train', 'seed', 'fold_groups_param', 'is_multiclass'}
2024-12-10 14:07:45,178:INFO:Checking environment
2024-12-10 14:07:45,178:INFO:python_version: 3.11.10
2024-12-10 14:07:45,178:INFO:python_build: ('main', 'Oct  3 2024 07:22:26')
2024-12-10 14:07:45,178:INFO:machine: AMD64
2024-12-10 14:07:45,178:INFO:platform: Windows-10-10.0.19045-SP0
2024-12-10 14:07:45,181:INFO:Memory: svmem(total=16908595200, available=2585288704, percent=84.7, used=14323306496, free=2585288704)
2024-12-10 14:07:45,181:INFO:Physical Core: 16
2024-12-10 14:07:45,181:INFO:Logical Core: 24
2024-12-10 14:07:45,181:INFO:Checking libraries
2024-12-10 14:07:45,181:INFO:System:
2024-12-10 14:07:45,181:INFO:    python: 3.11.10 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:26) [MSC v.1929 64 bit (AMD64)]
2024-12-10 14:07:45,181:INFO:executable: c:\Users\py\.conda\envs\hw4\python.exe
2024-12-10 14:07:45,181:INFO:   machine: Windows-10-10.0.19045-SP0
2024-12-10 14:07:45,181:INFO:PyCaret required dependencies:
2024-12-10 14:07:45,181:INFO:                 pip: 24.2
2024-12-10 14:07:45,181:INFO:          setuptools: 75.1.0
2024-12-10 14:07:45,181:INFO:             pycaret: 3.3.2
2024-12-10 14:07:45,181:INFO:             IPython: 8.30.0
2024-12-10 14:07:45,181:INFO:          ipywidgets: 8.1.5
2024-12-10 14:07:45,181:INFO:                tqdm: 4.67.1
2024-12-10 14:07:45,181:INFO:               numpy: 1.26.4
2024-12-10 14:07:45,181:INFO:              pandas: 2.1.4
2024-12-10 14:07:45,181:INFO:              jinja2: 3.1.4
2024-12-10 14:07:45,181:INFO:               scipy: 1.11.4
2024-12-10 14:07:45,182:INFO:              joblib: 1.3.2
2024-12-10 14:07:45,182:INFO:             sklearn: 1.4.2
2024-12-10 14:07:45,182:INFO:                pyod: 2.0.2
2024-12-10 14:07:45,182:INFO:            imblearn: 0.12.4
2024-12-10 14:07:45,182:INFO:   category_encoders: 2.6.4
2024-12-10 14:07:45,182:INFO:            lightgbm: 4.5.0
2024-12-10 14:07:45,182:INFO:               numba: 0.60.0
2024-12-10 14:07:45,182:INFO:            requests: 2.32.3
2024-12-10 14:07:45,182:INFO:          matplotlib: 3.7.5
2024-12-10 14:07:45,182:INFO:          scikitplot: 0.3.7
2024-12-10 14:07:45,182:INFO:         yellowbrick: 1.5
2024-12-10 14:07:45,182:INFO:              plotly: 5.24.1
2024-12-10 14:07:45,182:INFO:    plotly-resampler: Not installed
2024-12-10 14:07:45,182:INFO:             kaleido: 0.2.1
2024-12-10 14:07:45,182:INFO:           schemdraw: 0.15
2024-12-10 14:07:45,182:INFO:         statsmodels: 0.14.4
2024-12-10 14:07:45,182:INFO:              sktime: 0.26.0
2024-12-10 14:07:45,182:INFO:               tbats: 1.1.3
2024-12-10 14:07:45,182:INFO:            pmdarima: 2.0.4
2024-12-10 14:07:45,182:INFO:              psutil: 6.1.0
2024-12-10 14:07:45,182:INFO:          markupsafe: 3.0.2
2024-12-10 14:07:45,182:INFO:             pickle5: Not installed
2024-12-10 14:07:45,182:INFO:         cloudpickle: 3.1.0
2024-12-10 14:07:45,182:INFO:         deprecation: 2.1.0
2024-12-10 14:07:45,182:INFO:              xxhash: 3.5.0
2024-12-10 14:07:45,182:INFO:           wurlitzer: Not installed
2024-12-10 14:07:45,182:INFO:PyCaret optional dependencies:
2024-12-10 14:07:45,182:INFO:                shap: Not installed
2024-12-10 14:07:45,182:INFO:           interpret: Not installed
2024-12-10 14:07:45,182:INFO:                umap: Not installed
2024-12-10 14:07:45,182:INFO:     ydata_profiling: Not installed
2024-12-10 14:07:45,182:INFO:  explainerdashboard: Not installed
2024-12-10 14:07:45,182:INFO:             autoviz: Not installed
2024-12-10 14:07:45,182:INFO:           fairlearn: Not installed
2024-12-10 14:07:45,182:INFO:          deepchecks: Not installed
2024-12-10 14:07:45,182:INFO:             xgboost: 2.1.3
2024-12-10 14:07:45,182:INFO:            catboost: 1.2.7
2024-12-10 14:07:45,182:INFO:              kmodes: Not installed
2024-12-10 14:07:45,182:INFO:             mlxtend: Not installed
2024-12-10 14:07:45,182:INFO:       statsforecast: Not installed
2024-12-10 14:07:45,182:INFO:        tune_sklearn: Not installed
2024-12-10 14:07:45,182:INFO:                 ray: Not installed
2024-12-10 14:07:45,182:INFO:            hyperopt: Not installed
2024-12-10 14:07:45,182:INFO:              optuna: Not installed
2024-12-10 14:07:45,182:INFO:               skopt: Not installed
2024-12-10 14:07:45,182:INFO:              mlflow: Not installed
2024-12-10 14:07:45,182:INFO:              gradio: Not installed
2024-12-10 14:07:45,182:INFO:             fastapi: Not installed
2024-12-10 14:07:45,182:INFO:             uvicorn: Not installed
2024-12-10 14:07:45,182:INFO:              m2cgen: Not installed
2024-12-10 14:07:45,182:INFO:           evidently: Not installed
2024-12-10 14:07:45,182:INFO:               fugue: Not installed
2024-12-10 14:07:45,182:INFO:           streamlit: Not installed
2024-12-10 14:07:45,182:INFO:             prophet: Not installed
2024-12-10 14:07:45,182:INFO:None
2024-12-10 14:07:45,182:INFO:Set up data.
2024-12-10 14:07:45,184:INFO:Set up folding strategy.
2024-12-10 14:07:45,184:INFO:Set up train/test split.
2024-12-10 14:07:45,186:INFO:Set up index.
2024-12-10 14:07:45,186:INFO:Assigning column types.
2024-12-10 14:07:45,187:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-10 14:07:45,207:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-10 14:07:45,207:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-10 14:07:45,220:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 14:07:45,221:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 14:07:45,242:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-10 14:07:45,243:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-10 14:07:45,256:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 14:07:45,257:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 14:07:45,257:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-10 14:07:45,278:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-10 14:07:45,291:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 14:07:45,292:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 14:07:45,314:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-10 14:07:45,326:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 14:07:45,328:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 14:07:45,328:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-12-10 14:07:45,360:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 14:07:45,361:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 14:07:45,395:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 14:07:45,396:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 14:07:45,397:INFO:Preparing preprocessing pipeline...
2024-12-10 14:07:45,397:INFO:Set up simple imputation.
2024-12-10 14:07:45,406:INFO:Finished creating preprocessing pipeline.
2024-12-10 14:07:45,407:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\py\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'SibSp',
                                             'Parch', 'Fare', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-12-10 14:07:45,407:INFO:Creating final display dataframe.
2024-12-10 14:07:45,435:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (891, 8)
4        Transformed data shape          (891, 8)
5   Transformed train set shape          (623, 8)
6    Transformed test set shape          (268, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              00e1
2024-12-10 14:07:45,475:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 14:07:45,476:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 14:07:45,510:INFO:Soft dependency imported: xgboost: 2.1.3
2024-12-10 14:07:45,511:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-10 14:07:45,512:INFO:setup() successfully completed in 0.33s...............
2024-12-10 14:07:45,512:INFO:Initializing compare_models()
2024-12-10 14:07:45,513:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4790101D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E4790101D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-12-10 14:07:45,513:INFO:Checking exceptions
2024-12-10 14:07:45,514:INFO:Preparing display monitor
2024-12-10 14:07:45,524:INFO:Initializing Logistic Regression
2024-12-10 14:07:45,524:INFO:Total runtime is 0.0 minutes
2024-12-10 14:07:45,526:INFO:SubProcess create_model() called ==================================
2024-12-10 14:07:45,526:INFO:Initializing create_model()
2024-12-10 14:07:45,526:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4790101D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4003849D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:07:45,526:INFO:Checking exceptions
2024-12-10 14:07:45,526:INFO:Importing libraries
2024-12-10 14:07:45,526:INFO:Copying training dataset
2024-12-10 14:07:45,528:INFO:Defining folds
2024-12-10 14:07:45,528:INFO:Declaring metric variables
2024-12-10 14:07:45,529:INFO:Importing untrained model
2024-12-10 14:07:45,531:INFO:Logistic Regression Imported successfully
2024-12-10 14:07:45,534:INFO:Starting cross validation
2024-12-10 14:07:45,534:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:07:45,571:INFO:Calculating mean and std
2024-12-10 14:07:45,571:INFO:Creating metrics dataframe
2024-12-10 14:07:45,572:INFO:Uploading results into container
2024-12-10 14:07:45,572:INFO:Uploading model into container now
2024-12-10 14:07:45,572:INFO:_master_model_container: 1
2024-12-10 14:07:45,572:INFO:_display_container: 2
2024-12-10 14:07:45,572:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-10 14:07:45,572:INFO:create_model() successfully completed......................................
2024-12-10 14:07:45,641:INFO:SubProcess create_model() end ==================================
2024-12-10 14:07:45,641:INFO:Creating metrics dataframe
2024-12-10 14:07:45,644:INFO:Initializing K Neighbors Classifier
2024-12-10 14:07:45,644:INFO:Total runtime is 0.002009936173756917 minutes
2024-12-10 14:07:45,646:INFO:SubProcess create_model() called ==================================
2024-12-10 14:07:45,646:INFO:Initializing create_model()
2024-12-10 14:07:45,646:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4790101D0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4003849D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:07:45,646:INFO:Checking exceptions
2024-12-10 14:07:45,646:INFO:Importing libraries
2024-12-10 14:07:45,646:INFO:Copying training dataset
2024-12-10 14:07:45,647:INFO:Defining folds
2024-12-10 14:07:45,647:INFO:Declaring metric variables
2024-12-10 14:07:45,649:INFO:Importing untrained model
2024-12-10 14:07:45,650:INFO:K Neighbors Classifier Imported successfully
2024-12-10 14:07:45,653:INFO:Starting cross validation
2024-12-10 14:07:45,653:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:07:45,733:INFO:Calculating mean and std
2024-12-10 14:07:45,733:INFO:Creating metrics dataframe
2024-12-10 14:07:45,734:INFO:Uploading results into container
2024-12-10 14:07:45,734:INFO:Uploading model into container now
2024-12-10 14:07:45,734:INFO:_master_model_container: 2
2024-12-10 14:07:45,734:INFO:_display_container: 2
2024-12-10 14:07:45,734:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-10 14:07:45,734:INFO:create_model() successfully completed......................................
2024-12-10 14:07:45,801:INFO:SubProcess create_model() end ==================================
2024-12-10 14:07:45,801:INFO:Creating metrics dataframe
2024-12-10 14:07:45,805:INFO:Initializing Naive Bayes
2024-12-10 14:07:45,805:INFO:Total runtime is 0.004686081409454345 minutes
2024-12-10 14:07:45,806:INFO:SubProcess create_model() called ==================================
2024-12-10 14:07:45,806:INFO:Initializing create_model()
2024-12-10 14:07:45,807:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4790101D0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4003849D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:07:45,807:INFO:Checking exceptions
2024-12-10 14:07:45,807:INFO:Importing libraries
2024-12-10 14:07:45,807:INFO:Copying training dataset
2024-12-10 14:07:45,809:INFO:Defining folds
2024-12-10 14:07:45,809:INFO:Declaring metric variables
2024-12-10 14:07:45,810:INFO:Importing untrained model
2024-12-10 14:07:45,812:INFO:Naive Bayes Imported successfully
2024-12-10 14:07:45,814:INFO:Starting cross validation
2024-12-10 14:07:45,815:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:07:45,841:INFO:Calculating mean and std
2024-12-10 14:07:45,841:INFO:Creating metrics dataframe
2024-12-10 14:07:45,843:INFO:Uploading results into container
2024-12-10 14:07:45,843:INFO:Uploading model into container now
2024-12-10 14:07:45,843:INFO:_master_model_container: 3
2024-12-10 14:07:45,843:INFO:_display_container: 2
2024-12-10 14:07:45,844:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-10 14:07:45,844:INFO:create_model() successfully completed......................................
2024-12-10 14:07:45,904:INFO:SubProcess create_model() end ==================================
2024-12-10 14:07:45,904:INFO:Creating metrics dataframe
2024-12-10 14:07:45,908:INFO:Initializing Decision Tree Classifier
2024-12-10 14:07:45,908:INFO:Total runtime is 0.006397028764088948 minutes
2024-12-10 14:07:45,909:INFO:SubProcess create_model() called ==================================
2024-12-10 14:07:45,909:INFO:Initializing create_model()
2024-12-10 14:07:45,909:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4790101D0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4003849D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:07:45,909:INFO:Checking exceptions
2024-12-10 14:07:45,909:INFO:Importing libraries
2024-12-10 14:07:45,909:INFO:Copying training dataset
2024-12-10 14:07:45,911:INFO:Defining folds
2024-12-10 14:07:45,911:INFO:Declaring metric variables
2024-12-10 14:07:45,912:INFO:Importing untrained model
2024-12-10 14:07:45,913:INFO:Decision Tree Classifier Imported successfully
2024-12-10 14:07:45,916:INFO:Starting cross validation
2024-12-10 14:07:45,916:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:07:45,942:INFO:Calculating mean and std
2024-12-10 14:07:45,942:INFO:Creating metrics dataframe
2024-12-10 14:07:45,943:INFO:Uploading results into container
2024-12-10 14:07:45,943:INFO:Uploading model into container now
2024-12-10 14:07:45,944:INFO:_master_model_container: 4
2024-12-10 14:07:45,944:INFO:_display_container: 2
2024-12-10 14:07:45,944:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-12-10 14:07:45,944:INFO:create_model() successfully completed......................................
2024-12-10 14:07:46,003:INFO:SubProcess create_model() end ==================================
2024-12-10 14:07:46,003:INFO:Creating metrics dataframe
2024-12-10 14:07:46,007:INFO:Initializing SVM - Linear Kernel
2024-12-10 14:07:46,007:INFO:Total runtime is 0.00805217425028483 minutes
2024-12-10 14:07:46,008:INFO:SubProcess create_model() called ==================================
2024-12-10 14:07:46,008:INFO:Initializing create_model()
2024-12-10 14:07:46,008:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4790101D0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4003849D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:07:46,009:INFO:Checking exceptions
2024-12-10 14:07:46,009:INFO:Importing libraries
2024-12-10 14:07:46,009:INFO:Copying training dataset
2024-12-10 14:07:46,010:INFO:Defining folds
2024-12-10 14:07:46,010:INFO:Declaring metric variables
2024-12-10 14:07:46,012:INFO:Importing untrained model
2024-12-10 14:07:46,013:INFO:SVM - Linear Kernel Imported successfully
2024-12-10 14:07:46,016:INFO:Starting cross validation
2024-12-10 14:07:46,016:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:07:46,039:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 14:07:46,042:INFO:Calculating mean and std
2024-12-10 14:07:46,042:INFO:Creating metrics dataframe
2024-12-10 14:07:46,043:INFO:Uploading results into container
2024-12-10 14:07:46,043:INFO:Uploading model into container now
2024-12-10 14:07:46,043:INFO:_master_model_container: 5
2024-12-10 14:07:46,043:INFO:_display_container: 2
2024-12-10 14:07:46,044:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-10 14:07:46,044:INFO:create_model() successfully completed......................................
2024-12-10 14:07:46,104:INFO:SubProcess create_model() end ==================================
2024-12-10 14:07:46,104:INFO:Creating metrics dataframe
2024-12-10 14:07:46,108:INFO:Initializing Ridge Classifier
2024-12-10 14:07:46,108:INFO:Total runtime is 0.00972989797592163 minutes
2024-12-10 14:07:46,109:INFO:SubProcess create_model() called ==================================
2024-12-10 14:07:46,110:INFO:Initializing create_model()
2024-12-10 14:07:46,110:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4790101D0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4003849D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:07:46,110:INFO:Checking exceptions
2024-12-10 14:07:46,110:INFO:Importing libraries
2024-12-10 14:07:46,110:INFO:Copying training dataset
2024-12-10 14:07:46,111:INFO:Defining folds
2024-12-10 14:07:46,111:INFO:Declaring metric variables
2024-12-10 14:07:46,113:INFO:Importing untrained model
2024-12-10 14:07:46,114:INFO:Ridge Classifier Imported successfully
2024-12-10 14:07:46,117:INFO:Starting cross validation
2024-12-10 14:07:46,117:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:07:46,154:INFO:Calculating mean and std
2024-12-10 14:07:46,154:INFO:Creating metrics dataframe
2024-12-10 14:07:46,155:INFO:Uploading results into container
2024-12-10 14:07:46,155:INFO:Uploading model into container now
2024-12-10 14:07:46,155:INFO:_master_model_container: 6
2024-12-10 14:07:46,155:INFO:_display_container: 2
2024-12-10 14:07:46,155:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-12-10 14:07:46,155:INFO:create_model() successfully completed......................................
2024-12-10 14:07:46,217:INFO:SubProcess create_model() end ==================================
2024-12-10 14:07:46,217:INFO:Creating metrics dataframe
2024-12-10 14:07:46,221:INFO:Initializing Random Forest Classifier
2024-12-10 14:07:46,221:INFO:Total runtime is 0.01162588596343994 minutes
2024-12-10 14:07:46,223:INFO:SubProcess create_model() called ==================================
2024-12-10 14:07:46,224:INFO:Initializing create_model()
2024-12-10 14:07:46,224:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4790101D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4003849D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:07:46,224:INFO:Checking exceptions
2024-12-10 14:07:46,224:INFO:Importing libraries
2024-12-10 14:07:46,224:INFO:Copying training dataset
2024-12-10 14:07:46,226:INFO:Defining folds
2024-12-10 14:07:46,226:INFO:Declaring metric variables
2024-12-10 14:07:46,227:INFO:Importing untrained model
2024-12-10 14:07:46,229:INFO:Random Forest Classifier Imported successfully
2024-12-10 14:07:46,231:INFO:Starting cross validation
2024-12-10 14:07:46,231:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:07:46,404:INFO:Calculating mean and std
2024-12-10 14:07:46,404:INFO:Creating metrics dataframe
2024-12-10 14:07:46,405:INFO:Uploading results into container
2024-12-10 14:07:46,405:INFO:Uploading model into container now
2024-12-10 14:07:46,405:INFO:_master_model_container: 7
2024-12-10 14:07:46,405:INFO:_display_container: 2
2024-12-10 14:07:46,405:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-12-10 14:07:46,405:INFO:create_model() successfully completed......................................
2024-12-10 14:07:46,461:INFO:SubProcess create_model() end ==================================
2024-12-10 14:07:46,461:INFO:Creating metrics dataframe
2024-12-10 14:07:46,464:INFO:Initializing Quadratic Discriminant Analysis
2024-12-10 14:07:46,465:INFO:Total runtime is 0.015665769577026367 minutes
2024-12-10 14:07:46,466:INFO:SubProcess create_model() called ==================================
2024-12-10 14:07:46,466:INFO:Initializing create_model()
2024-12-10 14:07:46,466:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4790101D0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4003849D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:07:46,466:INFO:Checking exceptions
2024-12-10 14:07:46,466:INFO:Importing libraries
2024-12-10 14:07:46,466:INFO:Copying training dataset
2024-12-10 14:07:46,468:INFO:Defining folds
2024-12-10 14:07:46,468:INFO:Declaring metric variables
2024-12-10 14:07:46,469:INFO:Importing untrained model
2024-12-10 14:07:46,471:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-10 14:07:46,473:INFO:Starting cross validation
2024-12-10 14:07:46,473:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:07:46,509:INFO:Calculating mean and std
2024-12-10 14:07:46,509:INFO:Creating metrics dataframe
2024-12-10 14:07:46,510:INFO:Uploading results into container
2024-12-10 14:07:46,510:INFO:Uploading model into container now
2024-12-10 14:07:46,510:INFO:_master_model_container: 8
2024-12-10 14:07:46,510:INFO:_display_container: 2
2024-12-10 14:07:46,510:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-10 14:07:46,510:INFO:create_model() successfully completed......................................
2024-12-10 14:07:46,570:INFO:SubProcess create_model() end ==================================
2024-12-10 14:07:46,570:INFO:Creating metrics dataframe
2024-12-10 14:07:46,573:INFO:Initializing Ada Boost Classifier
2024-12-10 14:07:46,573:INFO:Total runtime is 0.017493720849355063 minutes
2024-12-10 14:07:46,575:INFO:SubProcess create_model() called ==================================
2024-12-10 14:07:46,575:INFO:Initializing create_model()
2024-12-10 14:07:46,575:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4790101D0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4003849D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:07:46,575:INFO:Checking exceptions
2024-12-10 14:07:46,575:INFO:Importing libraries
2024-12-10 14:07:46,575:INFO:Copying training dataset
2024-12-10 14:07:46,577:INFO:Defining folds
2024-12-10 14:07:46,577:INFO:Declaring metric variables
2024-12-10 14:07:46,579:INFO:Importing untrained model
2024-12-10 14:07:46,580:INFO:Ada Boost Classifier Imported successfully
2024-12-10 14:07:46,583:INFO:Starting cross validation
2024-12-10 14:07:46,583:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:07:46,592:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 14:07:46,592:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 14:07:46,593:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 14:07:46,593:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 14:07:46,594:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 14:07:46,595:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 14:07:46,596:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 14:07:46,597:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 14:07:46,598:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 14:07:46,599:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-10 14:07:46,675:INFO:Calculating mean and std
2024-12-10 14:07:46,676:INFO:Creating metrics dataframe
2024-12-10 14:07:46,676:INFO:Uploading results into container
2024-12-10 14:07:46,677:INFO:Uploading model into container now
2024-12-10 14:07:46,677:INFO:_master_model_container: 9
2024-12-10 14:07:46,677:INFO:_display_container: 2
2024-12-10 14:07:46,677:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-12-10 14:07:46,677:INFO:create_model() successfully completed......................................
2024-12-10 14:07:46,739:INFO:SubProcess create_model() end ==================================
2024-12-10 14:07:46,739:INFO:Creating metrics dataframe
2024-12-10 14:07:46,744:INFO:Initializing Gradient Boosting Classifier
2024-12-10 14:07:46,744:INFO:Total runtime is 0.02033130725224813 minutes
2024-12-10 14:07:46,746:INFO:SubProcess create_model() called ==================================
2024-12-10 14:07:46,746:INFO:Initializing create_model()
2024-12-10 14:07:46,746:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4790101D0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4003849D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:07:46,746:INFO:Checking exceptions
2024-12-10 14:07:46,746:INFO:Importing libraries
2024-12-10 14:07:46,746:INFO:Copying training dataset
2024-12-10 14:07:46,748:INFO:Defining folds
2024-12-10 14:07:46,748:INFO:Declaring metric variables
2024-12-10 14:07:46,749:INFO:Importing untrained model
2024-12-10 14:07:46,751:INFO:Gradient Boosting Classifier Imported successfully
2024-12-10 14:07:46,753:INFO:Starting cross validation
2024-12-10 14:07:46,754:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:07:46,860:INFO:Calculating mean and std
2024-12-10 14:07:46,860:INFO:Creating metrics dataframe
2024-12-10 14:07:46,862:INFO:Uploading results into container
2024-12-10 14:07:46,862:INFO:Uploading model into container now
2024-12-10 14:07:46,862:INFO:_master_model_container: 10
2024-12-10 14:07:46,862:INFO:_display_container: 2
2024-12-10 14:07:46,862:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-10 14:07:46,862:INFO:create_model() successfully completed......................................
2024-12-10 14:07:46,921:INFO:SubProcess create_model() end ==================================
2024-12-10 14:07:46,921:INFO:Creating metrics dataframe
2024-12-10 14:07:46,925:INFO:Initializing Linear Discriminant Analysis
2024-12-10 14:07:46,925:INFO:Total runtime is 0.02335635821024577 minutes
2024-12-10 14:07:46,927:INFO:SubProcess create_model() called ==================================
2024-12-10 14:07:46,927:INFO:Initializing create_model()
2024-12-10 14:07:46,927:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4790101D0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4003849D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:07:46,927:INFO:Checking exceptions
2024-12-10 14:07:46,927:INFO:Importing libraries
2024-12-10 14:07:46,927:INFO:Copying training dataset
2024-12-10 14:07:46,929:INFO:Defining folds
2024-12-10 14:07:46,929:INFO:Declaring metric variables
2024-12-10 14:07:46,930:INFO:Importing untrained model
2024-12-10 14:07:46,931:INFO:Linear Discriminant Analysis Imported successfully
2024-12-10 14:07:46,934:INFO:Starting cross validation
2024-12-10 14:07:46,934:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:07:46,972:INFO:Calculating mean and std
2024-12-10 14:07:46,972:INFO:Creating metrics dataframe
2024-12-10 14:07:46,974:INFO:Uploading results into container
2024-12-10 14:07:46,974:INFO:Uploading model into container now
2024-12-10 14:07:46,974:INFO:_master_model_container: 11
2024-12-10 14:07:46,974:INFO:_display_container: 2
2024-12-10 14:07:46,974:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-10 14:07:46,974:INFO:create_model() successfully completed......................................
2024-12-10 14:07:47,034:INFO:SubProcess create_model() end ==================================
2024-12-10 14:07:47,034:INFO:Creating metrics dataframe
2024-12-10 14:07:47,038:INFO:Initializing Extra Trees Classifier
2024-12-10 14:07:47,038:INFO:Total runtime is 0.025235029061635335 minutes
2024-12-10 14:07:47,040:INFO:SubProcess create_model() called ==================================
2024-12-10 14:07:47,040:INFO:Initializing create_model()
2024-12-10 14:07:47,040:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4790101D0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4003849D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:07:47,040:INFO:Checking exceptions
2024-12-10 14:07:47,040:INFO:Importing libraries
2024-12-10 14:07:47,040:INFO:Copying training dataset
2024-12-10 14:07:47,042:INFO:Defining folds
2024-12-10 14:07:47,042:INFO:Declaring metric variables
2024-12-10 14:07:47,043:INFO:Importing untrained model
2024-12-10 14:07:47,044:INFO:Extra Trees Classifier Imported successfully
2024-12-10 14:07:47,047:INFO:Starting cross validation
2024-12-10 14:07:47,048:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:07:47,202:INFO:Calculating mean and std
2024-12-10 14:07:47,202:INFO:Creating metrics dataframe
2024-12-10 14:07:47,203:INFO:Uploading results into container
2024-12-10 14:07:47,204:INFO:Uploading model into container now
2024-12-10 14:07:47,204:INFO:_master_model_container: 12
2024-12-10 14:07:47,204:INFO:_display_container: 2
2024-12-10 14:07:47,204:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-12-10 14:07:47,204:INFO:create_model() successfully completed......................................
2024-12-10 14:07:47,264:INFO:SubProcess create_model() end ==================================
2024-12-10 14:07:47,265:INFO:Creating metrics dataframe
2024-12-10 14:07:47,269:INFO:Initializing Extreme Gradient Boosting
2024-12-10 14:07:47,269:INFO:Total runtime is 0.029090511798858642 minutes
2024-12-10 14:07:47,270:INFO:SubProcess create_model() called ==================================
2024-12-10 14:07:47,271:INFO:Initializing create_model()
2024-12-10 14:07:47,271:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4790101D0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4003849D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:07:47,271:INFO:Checking exceptions
2024-12-10 14:07:47,271:INFO:Importing libraries
2024-12-10 14:07:47,271:INFO:Copying training dataset
2024-12-10 14:07:47,272:INFO:Defining folds
2024-12-10 14:07:47,272:INFO:Declaring metric variables
2024-12-10 14:07:47,274:INFO:Importing untrained model
2024-12-10 14:07:47,276:INFO:Extreme Gradient Boosting Imported successfully
2024-12-10 14:07:47,278:INFO:Starting cross validation
2024-12-10 14:07:47,278:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:07:47,338:INFO:Calculating mean and std
2024-12-10 14:07:47,338:INFO:Creating metrics dataframe
2024-12-10 14:07:47,339:INFO:Uploading results into container
2024-12-10 14:07:47,340:INFO:Uploading model into container now
2024-12-10 14:07:47,340:INFO:_master_model_container: 13
2024-12-10 14:07:47,340:INFO:_display_container: 2
2024-12-10 14:07:47,341:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-12-10 14:07:47,341:INFO:create_model() successfully completed......................................
2024-12-10 14:07:47,404:INFO:SubProcess create_model() end ==================================
2024-12-10 14:07:47,405:INFO:Creating metrics dataframe
2024-12-10 14:07:47,410:INFO:Initializing Light Gradient Boosting Machine
2024-12-10 14:07:47,411:INFO:Total runtime is 0.031449544429779056 minutes
2024-12-10 14:07:47,412:INFO:SubProcess create_model() called ==================================
2024-12-10 14:07:47,412:INFO:Initializing create_model()
2024-12-10 14:07:47,412:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4790101D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4003849D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:07:47,412:INFO:Checking exceptions
2024-12-10 14:07:47,412:INFO:Importing libraries
2024-12-10 14:07:47,413:INFO:Copying training dataset
2024-12-10 14:07:47,414:INFO:Defining folds
2024-12-10 14:07:47,414:INFO:Declaring metric variables
2024-12-10 14:07:47,415:INFO:Importing untrained model
2024-12-10 14:07:47,417:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-10 14:07:47,419:INFO:Starting cross validation
2024-12-10 14:07:47,420:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:07:48,175:INFO:Calculating mean and std
2024-12-10 14:07:48,175:INFO:Creating metrics dataframe
2024-12-10 14:07:48,177:INFO:Uploading results into container
2024-12-10 14:07:48,177:INFO:Uploading model into container now
2024-12-10 14:07:48,177:INFO:_master_model_container: 14
2024-12-10 14:07:48,177:INFO:_display_container: 2
2024-12-10 14:07:48,178:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-10 14:07:48,178:INFO:create_model() successfully completed......................................
2024-12-10 14:07:48,244:INFO:SubProcess create_model() end ==================================
2024-12-10 14:07:48,244:INFO:Creating metrics dataframe
2024-12-10 14:07:48,250:INFO:Initializing CatBoost Classifier
2024-12-10 14:07:48,250:INFO:Total runtime is 0.04543610413869222 minutes
2024-12-10 14:07:48,252:INFO:SubProcess create_model() called ==================================
2024-12-10 14:07:48,252:INFO:Initializing create_model()
2024-12-10 14:07:48,252:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4790101D0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4003849D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:07:48,252:INFO:Checking exceptions
2024-12-10 14:07:48,252:INFO:Importing libraries
2024-12-10 14:07:48,253:INFO:Copying training dataset
2024-12-10 14:07:48,254:INFO:Defining folds
2024-12-10 14:07:48,255:INFO:Declaring metric variables
2024-12-10 14:07:48,256:INFO:Importing untrained model
2024-12-10 14:07:48,258:INFO:CatBoost Classifier Imported successfully
2024-12-10 14:07:48,262:INFO:Starting cross validation
2024-12-10 14:07:48,262:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:07:50,021:INFO:Calculating mean and std
2024-12-10 14:07:50,021:INFO:Creating metrics dataframe
2024-12-10 14:07:50,022:INFO:Uploading results into container
2024-12-10 14:07:50,023:INFO:Uploading model into container now
2024-12-10 14:07:50,023:INFO:_master_model_container: 15
2024-12-10 14:07:50,023:INFO:_display_container: 2
2024-12-10 14:07:50,023:INFO:<catboost.core.CatBoostClassifier object at 0x000001E40037AFD0>
2024-12-10 14:07:50,023:INFO:create_model() successfully completed......................................
2024-12-10 14:07:50,080:INFO:SubProcess create_model() end ==================================
2024-12-10 14:07:50,080:INFO:Creating metrics dataframe
2024-12-10 14:07:50,085:INFO:Initializing Dummy Classifier
2024-12-10 14:07:50,085:INFO:Total runtime is 0.07601913611094158 minutes
2024-12-10 14:07:50,086:INFO:SubProcess create_model() called ==================================
2024-12-10 14:07:50,087:INFO:Initializing create_model()
2024-12-10 14:07:50,087:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4790101D0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4003849D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:07:50,087:INFO:Checking exceptions
2024-12-10 14:07:50,087:INFO:Importing libraries
2024-12-10 14:07:50,087:INFO:Copying training dataset
2024-12-10 14:07:50,088:INFO:Defining folds
2024-12-10 14:07:50,088:INFO:Declaring metric variables
2024-12-10 14:07:50,089:INFO:Importing untrained model
2024-12-10 14:07:50,091:INFO:Dummy Classifier Imported successfully
2024-12-10 14:07:50,094:INFO:Starting cross validation
2024-12-10 14:07:50,094:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:07:50,106:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 14:07:50,107:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 14:07:50,108:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 14:07:50,108:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 14:07:50,108:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 14:07:50,109:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 14:07:50,109:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 14:07:50,110:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 14:07:50,114:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 14:07:50,114:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-10 14:07:50,119:INFO:Calculating mean and std
2024-12-10 14:07:50,119:INFO:Creating metrics dataframe
2024-12-10 14:07:50,120:INFO:Uploading results into container
2024-12-10 14:07:50,120:INFO:Uploading model into container now
2024-12-10 14:07:50,120:INFO:_master_model_container: 16
2024-12-10 14:07:50,120:INFO:_display_container: 2
2024-12-10 14:07:50,120:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-12-10 14:07:50,120:INFO:create_model() successfully completed......................................
2024-12-10 14:07:50,180:INFO:SubProcess create_model() end ==================================
2024-12-10 14:07:50,180:INFO:Creating metrics dataframe
2024-12-10 14:07:50,185:WARNING:c:\Users\py\.conda\envs\hw4\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-12-10 14:07:50,191:INFO:Initializing create_model()
2024-12-10 14:07:50,191:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4790101D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:07:50,191:INFO:Checking exceptions
2024-12-10 14:07:50,192:INFO:Importing libraries
2024-12-10 14:07:50,193:INFO:Copying training dataset
2024-12-10 14:07:50,194:INFO:Defining folds
2024-12-10 14:07:50,194:INFO:Declaring metric variables
2024-12-10 14:07:50,194:INFO:Importing untrained model
2024-12-10 14:07:50,194:INFO:Declaring custom model
2024-12-10 14:07:50,194:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-10 14:07:50,195:INFO:Cross validation set to False
2024-12-10 14:07:50,195:INFO:Fitting Model
2024-12-10 14:07:50,198:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-10 14:07:50,199:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000224 seconds.
2024-12-10 14:07:50,199:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-10 14:07:50,199:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-10 14:07:50,199:INFO:[LightGBM] [Info] Total Bins 188
2024-12-10 14:07:50,199:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 7
2024-12-10 14:07:50,199:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-10 14:07:50,199:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-10 14:07:50,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:07:50,280:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-10 14:07:50,280:INFO:create_model() successfully completed......................................
2024-12-10 14:07:50,357:INFO:_master_model_container: 16
2024-12-10 14:07:50,357:INFO:_display_container: 2
2024-12-10 14:07:50,357:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-10 14:07:50,357:INFO:compare_models() successfully completed......................................
2024-12-10 14:07:50,358:INFO:Initializing create_model()
2024-12-10 14:07:50,358:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4790101D0>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:07:50,358:INFO:Checking exceptions
2024-12-10 14:07:50,365:INFO:Importing libraries
2024-12-10 14:07:50,365:INFO:Copying training dataset
2024-12-10 14:07:50,368:INFO:Defining folds
2024-12-10 14:07:50,368:INFO:Declaring metric variables
2024-12-10 14:07:50,369:INFO:Importing untrained model
2024-12-10 14:07:50,371:INFO:Random Forest Classifier Imported successfully
2024-12-10 14:07:50,374:INFO:Starting cross validation
2024-12-10 14:07:50,375:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:07:50,518:INFO:Calculating mean and std
2024-12-10 14:07:50,518:INFO:Creating metrics dataframe
2024-12-10 14:07:50,520:INFO:Finalizing model
2024-12-10 14:07:50,602:INFO:Uploading results into container
2024-12-10 14:07:50,603:INFO:Uploading model into container now
2024-12-10 14:07:50,606:INFO:_master_model_container: 17
2024-12-10 14:07:50,606:INFO:_display_container: 3
2024-12-10 14:07:50,607:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-12-10 14:07:50,607:INFO:create_model() successfully completed......................................
2024-12-10 14:07:50,668:INFO:Initializing plot_model()
2024-12-10 14:07:50,669:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4790101D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-12-10 14:07:50,669:INFO:Checking exceptions
2024-12-10 14:07:50,687:INFO:Preloading libraries
2024-12-10 14:07:50,692:INFO:Copying training dataset
2024-12-10 14:07:50,692:INFO:Plot type: feature
2024-12-10 14:07:50,692:WARNING:No coef_ found. Trying feature_importances_
2024-12-10 14:07:50,804:INFO:Visual Rendered Successfully
2024-12-10 14:07:50,861:INFO:plot_model() successfully completed......................................
2024-12-10 14:07:50,862:INFO:Initializing create_model()
2024-12-10 14:07:50,862:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4790101D0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:07:50,862:INFO:Checking exceptions
2024-12-10 14:07:50,868:INFO:Importing libraries
2024-12-10 14:07:50,868:INFO:Copying training dataset
2024-12-10 14:07:50,870:INFO:Defining folds
2024-12-10 14:07:50,870:INFO:Declaring metric variables
2024-12-10 14:07:50,871:INFO:Importing untrained model
2024-12-10 14:07:50,873:INFO:Logistic Regression Imported successfully
2024-12-10 14:07:50,876:INFO:Starting cross validation
2024-12-10 14:07:50,877:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:07:50,926:INFO:Calculating mean and std
2024-12-10 14:07:50,926:INFO:Creating metrics dataframe
2024-12-10 14:07:50,928:INFO:Finalizing model
2024-12-10 14:07:50,939:INFO:Uploading results into container
2024-12-10 14:07:50,940:INFO:Uploading model into container now
2024-12-10 14:07:50,944:INFO:_master_model_container: 18
2024-12-10 14:07:50,944:INFO:_display_container: 4
2024-12-10 14:07:50,944:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-10 14:07:50,944:INFO:create_model() successfully completed......................................
2024-12-10 14:07:51,009:INFO:Initializing stack_models()
2024-12-10 14:07:51,009:INFO:stack_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4790101D0>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)], meta_model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), meta_model_fold=5, fold=None, round=4, method=auto, restack=False, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-12-10 14:07:51,009:INFO:Checking exceptions
2024-12-10 14:07:51,010:INFO:Defining meta model
2024-12-10 14:07:51,018:INFO:Getting model names
2024-12-10 14:07:51,018:INFO:[('Light Gradient Boosting Machine', LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0))]
2024-12-10 14:07:51,019:INFO:SubProcess create_model() called ==================================
2024-12-10 14:07:51,021:INFO:Initializing create_model()
2024-12-10 14:07:51,021:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4790101D0>, estimator=StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=123, reg_alpha=0.0,
                                               re...
                                               subsample_for_bin=200000,
                                               subsample_freq=0))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=123,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E40057BB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:07:51,021:INFO:Checking exceptions
2024-12-10 14:07:51,021:INFO:Importing libraries
2024-12-10 14:07:51,021:INFO:Copying training dataset
2024-12-10 14:07:51,022:INFO:Defining folds
2024-12-10 14:07:51,022:INFO:Declaring metric variables
2024-12-10 14:07:51,024:INFO:Importing untrained model
2024-12-10 14:07:51,024:INFO:Declaring custom model
2024-12-10 14:07:51,031:INFO:Stacking Classifier Imported successfully
2024-12-10 14:07:51,042:INFO:Starting cross validation
2024-12-10 14:07:51,043:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:07:54,363:INFO:Calculating mean and std
2024-12-10 14:07:54,364:INFO:Creating metrics dataframe
2024-12-10 14:07:54,367:INFO:Finalizing model
2024-12-10 14:07:54,902:INFO:Uploading results into container
2024-12-10 14:07:54,903:INFO:Uploading model into container now
2024-12-10 14:07:54,903:INFO:_master_model_container: 19
2024-12-10 14:07:54,903:INFO:_display_container: 5
2024-12-10 14:07:54,905:INFO:StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=123, reg_alpha=0.0,
                                               re...
                                               subsample_for_bin=200000,
                                               subsample_freq=0))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=123,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0)
2024-12-10 14:07:54,905:INFO:create_model() successfully completed......................................
2024-12-10 14:07:54,979:INFO:SubProcess create_model() end ==================================
2024-12-10 14:07:54,985:INFO:_master_model_container: 19
2024-12-10 14:07:54,985:INFO:_display_container: 5
2024-12-10 14:07:54,987:INFO:StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=123, reg_alpha=0.0,
                                               re...
                                               subsample_for_bin=200000,
                                               subsample_freq=0))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=123,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0)
2024-12-10 14:07:54,987:INFO:stack_models() successfully completed......................................
2024-12-10 14:07:55,052:INFO:Initializing tune_model()
2024-12-10 14:07:55,052:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4790101D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=50, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-12-10 14:07:55,052:INFO:Checking exceptions
2024-12-10 14:07:55,059:INFO:Copying training dataset
2024-12-10 14:07:55,061:INFO:Checking base model
2024-12-10 14:07:55,061:INFO:Base model : Light Gradient Boosting Machine
2024-12-10 14:07:55,062:INFO:Declaring metric variables
2024-12-10 14:07:55,064:INFO:Defining Hyperparameters
2024-12-10 14:07:55,132:INFO:Tuning with n_jobs=-1
2024-12-10 14:07:55,132:INFO:Initializing RandomizedSearchCV
2024-12-10 14:08:05,100:INFO:best_params: {'actual_estimator__reg_lambda': 0.0001, 'actual_estimator__reg_alpha': 0.1, 'actual_estimator__num_leaves': 2, 'actual_estimator__n_estimators': 120, 'actual_estimator__min_split_gain': 0.5, 'actual_estimator__min_child_samples': 36, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 4, 'actual_estimator__bagging_fraction': 1.0}
2024-12-10 14:08:05,101:INFO:Hyperparameter search completed
2024-12-10 14:08:05,101:INFO:SubProcess create_model() called ==================================
2024-12-10 14:08:05,101:INFO:Initializing create_model()
2024-12-10 14:08:05,102:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4790101D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E41501F190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.0001, 'reg_alpha': 0.1, 'num_leaves': 2, 'n_estimators': 120, 'min_split_gain': 0.5, 'min_child_samples': 36, 'learning_rate': 0.5, 'feature_fraction': 0.5, 'bagging_freq': 4, 'bagging_fraction': 1.0})
2024-12-10 14:08:05,102:INFO:Checking exceptions
2024-12-10 14:08:05,102:INFO:Importing libraries
2024-12-10 14:08:05,102:INFO:Copying training dataset
2024-12-10 14:08:05,103:INFO:Defining folds
2024-12-10 14:08:05,103:INFO:Declaring metric variables
2024-12-10 14:08:05,105:INFO:Importing untrained model
2024-12-10 14:08:05,105:INFO:Declaring custom model
2024-12-10 14:08:05,109:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-10 14:08:05,112:INFO:Starting cross validation
2024-12-10 14:08:05,113:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:08:05,241:INFO:Calculating mean and std
2024-12-10 14:08:05,242:INFO:Creating metrics dataframe
2024-12-10 14:08:05,245:INFO:Finalizing model
2024-12-10 14:08:05,249:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-12-10 14:08:05,249:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2024-12-10 14:08:05,249:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-12-10 14:08:05,253:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-12-10 14:08:05,253:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2024-12-10 14:08:05,253:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-12-10 14:08:05,253:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-10 14:08:05,254:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000748 seconds.
2024-12-10 14:08:05,254:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-10 14:08:05,254:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-10 14:08:05,254:INFO:[LightGBM] [Info] Total Bins 188
2024-12-10 14:08:05,254:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 7
2024-12-10 14:08:05,255:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-10 14:08:05,255:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-10 14:08:05,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,279:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,279:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,280:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,280:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,281:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,283:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,283:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,283:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,284:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,284:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,284:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,285:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,285:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,285:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,286:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,286:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,286:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,287:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,287:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,288:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,288:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,289:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,289:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,290:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,290:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,291:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,291:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,292:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,292:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,293:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,293:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,293:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,294:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,294:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,295:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,295:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,296:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,296:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,296:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,297:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,297:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,297:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,298:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,298:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,299:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,300:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,300:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,300:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,301:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,301:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,301:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,302:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,302:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,303:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,303:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,303:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,304:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,304:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,305:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,305:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,305:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,306:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,306:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,307:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,307:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,308:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,308:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,309:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,309:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,309:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,310:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,311:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,311:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,311:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:05,312:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:05,315:INFO:Uploading results into container
2024-12-10 14:08:05,316:INFO:Uploading model into container now
2024-12-10 14:08:05,316:INFO:_master_model_container: 20
2024-12-10 14:08:05,316:INFO:_display_container: 6
2024-12-10 14:08:05,317:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=120, n_jobs=-1, num_leaves=2, objective=None,
               random_state=123, reg_alpha=0.1, reg_lambda=0.0001,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-12-10 14:08:05,317:INFO:create_model() successfully completed......................................
2024-12-10 14:08:05,401:INFO:SubProcess create_model() end ==================================
2024-12-10 14:08:05,401:INFO:choose_better activated
2024-12-10 14:08:05,402:INFO:SubProcess create_model() called ==================================
2024-12-10 14:08:05,402:INFO:Initializing create_model()
2024-12-10 14:08:05,402:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4790101D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:08:05,402:INFO:Checking exceptions
2024-12-10 14:08:05,404:INFO:Importing libraries
2024-12-10 14:08:05,404:INFO:Copying training dataset
2024-12-10 14:08:05,406:INFO:Defining folds
2024-12-10 14:08:05,406:INFO:Declaring metric variables
2024-12-10 14:08:05,406:INFO:Importing untrained model
2024-12-10 14:08:05,406:INFO:Declaring custom model
2024-12-10 14:08:05,407:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-10 14:08:05,407:INFO:Starting cross validation
2024-12-10 14:08:05,407:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-10 14:08:06,116:INFO:Calculating mean and std
2024-12-10 14:08:06,116:INFO:Creating metrics dataframe
2024-12-10 14:08:06,117:INFO:Finalizing model
2024-12-10 14:08:06,122:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-10 14:08:06,122:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000487 seconds.
2024-12-10 14:08:06,122:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-10 14:08:06,122:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-10 14:08:06,123:INFO:[LightGBM] [Info] Total Bins 188
2024-12-10 14:08:06,123:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 7
2024-12-10 14:08:06,123:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-10 14:08:06,123:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-10 14:08:06,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,221:INFO:Uploading results into container
2024-12-10 14:08:06,221:INFO:Uploading model into container now
2024-12-10 14:08:06,222:INFO:_master_model_container: 21
2024-12-10 14:08:06,222:INFO:_display_container: 7
2024-12-10 14:08:06,222:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-10 14:08:06,222:INFO:create_model() successfully completed......................................
2024-12-10 14:08:06,284:INFO:SubProcess create_model() end ==================================
2024-12-10 14:08:06,284:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.8444
2024-12-10 14:08:06,285:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=120, n_jobs=-1, num_leaves=2, objective=None,
               random_state=123, reg_alpha=0.1, reg_lambda=0.0001,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.859
2024-12-10 14:08:06,285:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=120, n_jobs=-1, num_leaves=2, objective=None,
               random_state=123, reg_alpha=0.1, reg_lambda=0.0001,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2024-12-10 14:08:06,285:INFO:choose_better completed
2024-12-10 14:08:06,291:INFO:_master_model_container: 21
2024-12-10 14:08:06,291:INFO:_display_container: 6
2024-12-10 14:08:06,291:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=120, n_jobs=-1, num_leaves=2, objective=None,
               random_state=123, reg_alpha=0.1, reg_lambda=0.0001,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-12-10 14:08:06,291:INFO:tune_model() successfully completed......................................
2024-12-10 14:08:06,355:INFO:Initializing finalize_model()
2024-12-10 14:08:06,356:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4790101D0>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=120, n_jobs=-1, num_leaves=2, objective=None,
               random_state=123, reg_alpha=0.1, reg_lambda=0.0001,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-12-10 14:08:06,356:INFO:Finalizing LGBMClassifier(bagging_fraction=1.0, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=120, n_jobs=-1, num_leaves=2, objective=None,
               random_state=123, reg_alpha=0.1, reg_lambda=0.0001,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-12-10 14:08:06,358:INFO:Initializing create_model()
2024-12-10 14:08:06,358:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4790101D0>, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=120, n_jobs=-1, num_leaves=2, objective=None,
               random_state=123, reg_alpha=0.1, reg_lambda=0.0001,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-12-10 14:08:06,358:INFO:Checking exceptions
2024-12-10 14:08:06,359:INFO:Importing libraries
2024-12-10 14:08:06,359:INFO:Copying training dataset
2024-12-10 14:08:06,359:INFO:Defining folds
2024-12-10 14:08:06,359:INFO:Declaring metric variables
2024-12-10 14:08:06,359:INFO:Importing untrained model
2024-12-10 14:08:06,359:INFO:Declaring custom model
2024-12-10 14:08:06,359:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-10 14:08:06,360:INFO:Cross validation set to False
2024-12-10 14:08:06,360:INFO:Fitting Model
2024-12-10 14:08:06,363:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-12-10 14:08:06,363:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2024-12-10 14:08:06,363:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-12-10 14:08:06,363:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-12-10 14:08:06,363:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2024-12-10 14:08:06,363:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-12-10 14:08:06,363:INFO:[LightGBM] [Info] Number of positive: 342, number of negative: 549
2024-12-10 14:08:06,364:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000107 seconds.
2024-12-10 14:08:06,364:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-12-10 14:08:06,364:INFO:[LightGBM] [Info] Total Bins 221
2024-12-10 14:08:06,364:INFO:[LightGBM] [Info] Number of data points in the train set: 891, number of used features: 7
2024-12-10 14:08:06,364:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383838 -> initscore=-0.473288
2024-12-10 14:08:06,364:INFO:[LightGBM] [Info] Start training from score -0.473288
2024-12-10 14:08:06,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,366:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,366:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,366:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,366:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,366:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,366:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,367:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,367:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,367:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,367:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,367:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,367:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,367:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,367:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,367:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,367:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,367:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,367:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,368:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,368:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,368:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,368:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,368:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,368:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,368:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,368:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,368:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,368:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,368:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,368:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,368:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,369:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,369:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,369:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,369:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,369:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,369:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,369:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,369:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,369:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,369:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,369:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,369:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,369:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,370:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,370:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,370:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,370:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,370:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,370:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,370:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,370:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,370:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,370:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,370:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,370:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,370:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,370:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,371:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,371:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,371:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,371:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,371:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,371:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-10 14:08:06,371:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-10 14:08:06,376:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'SibSp',
                                             'Parch', 'Fare', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=N...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.5,
                                max_depth=-1, min_child_samples=36,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=120, n_jobs=-1, num_leaves=2,
                                objective=None, random_state=123, reg_alpha=0.1,
                                reg_lambda=0.0001, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-12-10 14:08:06,376:INFO:create_model() successfully completed......................................
2024-12-10 14:08:06,438:INFO:_master_model_container: 21
2024-12-10 14:08:06,438:INFO:_display_container: 6
2024-12-10 14:08:06,441:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'SibSp',
                                             'Parch', 'Fare', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=N...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.5,
                                max_depth=-1, min_child_samples=36,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=120, n_jobs=-1, num_leaves=2,
                                objective=None, random_state=123, reg_alpha=0.1,
                                reg_lambda=0.0001, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-12-10 14:08:06,441:INFO:finalize_model() successfully completed......................................
2024-12-10 14:08:06,517:INFO:Initializing predict_model()
2024-12-10 14:08:06,517:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4790101D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Sex', 'Age', 'SibSp',
                                             'Parch', 'Fare', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=N...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.5,
                                max_depth=-1, min_child_samples=36,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=120, n_jobs=-1, num_leaves=2,
                                objective=None, random_state=123, reg_alpha=0.1,
                                reg_lambda=0.0001, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E4008209A0>)
2024-12-10 14:08:06,517:INFO:Checking exceptions
2024-12-10 14:08:06,517:INFO:Preloading libraries
2024-12-10 14:08:06,518:INFO:Set up data.
2024-12-10 14:08:06,520:INFO:Set up index.
